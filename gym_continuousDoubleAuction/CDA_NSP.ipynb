{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with naive competitive self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"‚ùå No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 09:25:31,216\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-24 09:25:33,057\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_0', 'agent_1', 'agent_3', 'agent_2']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 09:25:35,551\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.76gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-12-24 09:25:36,703\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"43cab689-c598-4e6c-9bcb-92ccf082cd5f\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 4\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x7b7821abfac0>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x7b7821abfaf0>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x7b7821abfa90>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x7b7821abfc70>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=2,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ‚Üê ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 09:25:37,032\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2025-12-24 09:25:37,033\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 4096\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-12-24 09:25:37,294\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-24 09:25:37,304\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2025-12-24 09:25:37,313\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-24 09:25:37,335\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2025-12-24 09:25:37,345\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2025-12-24 09:25:37,355\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2025-12-24 09:25:37,357\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-12-24 09:25:37,374\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,374\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,375\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,375\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,376\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,391\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,391\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2025-12-24 09:25:37,392\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32)), Dict('agent_0': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_1': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_2': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_3': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))), 'policy_0': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_1': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_2': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_3': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))}\n",
      "2025-12-24 09:25:37,436\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:37,437\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:37,446\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:37,455\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:37,464\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:37,474\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:37,483\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:39,023\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2025-12-24 09:25:39,061\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 4096\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode ff0d2e13fa3343ea85c712c62808dd22 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -30193305.905769266, 'agent_1': -96054378.12876558, 'agent_2': -331649696.4493354, 'agent_3': -389971390.3059976} id_=ff0d2e13fa3343ea85c712c62808dd22)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ff0d2e13fa3343ea85c712c62808dd22 NAV Verification ====================\n",
      "  agent_0 NAV: 998,214.00\n",
      "  agent_1 NAV: 1,003,344.00\n",
      "  agent_2 NAV: 986,123.00\n",
      "  agent_3 NAV: 1,012,319.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 4d837f2dfe9f40b5a7d7119fbf704ebb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -39793468.96248575, 'agent_1': -145997948.5361084, 'agent_2': -157175148.13510013, 'agent_3': -40018050.377040416} id_=4d837f2dfe9f40b5a7d7119fbf704ebb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4d837f2dfe9f40b5a7d7119fbf704ebb NAV Verification ====================\n",
      "  agent_0 NAV: 999,002.00\n",
      "  agent_1 NAV: 1,012,327.00\n",
      "  agent_2 NAV: 989,425.00\n",
      "  agent_3 NAV: 999,246.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode a7e81e527a264c1fa3e392a7983081bb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -63282830.73975926, 'agent_1': -66968898.39292709, 'agent_2': -43236964.090829164, 'agent_3': -76897693.4338581} id_=a7e81e527a264c1fa3e392a7983081bb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a7e81e527a264c1fa3e392a7983081bb NAV Verification ====================\n",
      "  agent_0 NAV: 1,008,408.00\n",
      "  agent_1 NAV: 997,189.00\n",
      "  agent_2 NAV: 996,060.00\n",
      "  agent_3 NAV: 998,343.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 975cb9af2dbe478ba3b25292c13af058 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -123436647.79 | Std: 53944782.39 | Threshold: -118042169.55\n",
      "Policy Returns: {'policy_3': -168962378.03896537, 'policy_2': -177353936.22508824, 'policy_1': -103007075.01926702, 'policy_0': -44423201.869338095}\n",
      "Best Trainable: policy_0 (-44423201.87)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -44423201.87\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_1 created successfully!\n",
      "‚úì League size now: 3 (2 trainable + 1 champions)\n",
      "‚úì Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': -57299.46981627297, 'agent_1': -3105028.7381546134, 'agent_2': -1613235.8241758242, 'agent_3': -1215902.1657142858} id_=975cb9af2dbe478ba3b25292c13af058)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 975cb9af2dbe478ba3b25292c13af058 NAV Verification ====================\n",
      "  agent_0 NAV: 997,178.00\n",
      "  agent_1 NAV: 989,330.00\n",
      "  agent_2 NAV: 1,010,374.00\n",
      "  agent_3 NAV: 1,003,118.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode c8430777fdfb4917baf091f22733baef Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -180865538.58699524, 'agent_1': -203764195.50866836, 'agent_2': -66923790.284374595, 'agent_3': -30330548.035444032} id_=c8430777fdfb4917baf091f22733baef)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c8430777fdfb4917baf091f22733baef NAV Verification ====================\n",
      "  agent_0 NAV: 997,290.00\n",
      "  agent_1 NAV: 1,007,455.00\n",
      "  agent_2 NAV: 1,005,907.00\n",
      "  agent_3 NAV: 989,348.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode ba82550dec024326bf2aa34b93f61b2a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -207842200.73386094, 'agent_1': -35457268.10273528, 'agent_2': -73605512.50201744, 'agent_3': -131652771.45460728} id_=ba82550dec024326bf2aa34b93f61b2a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ba82550dec024326bf2aa34b93f61b2a NAV Verification ====================\n",
      "  agent_0 NAV: 981,971.00\n",
      "  agent_1 NAV: 1,000,563.00\n",
      "  agent_2 NAV: 1,001,030.00\n",
      "  agent_3 NAV: 1,016,436.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode abd48a5959fe47df9009ff8802b14c01 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -42331839.864946164, 'agent_1': -43143531.72334721, 'agent_2': -23096346.335717414, 'agent_3': -89004998.75694333} id_=abd48a5959fe47df9009ff8802b14c01)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode abd48a5959fe47df9009ff8802b14c01 NAV Verification ====================\n",
      "  agent_0 NAV: 993,271.00\n",
      "  agent_1 NAV: 998,505.00\n",
      "  agent_2 NAV: 998,086.00\n",
      "  agent_3 NAV: 1,010,138.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 62df59d0d7414e7a894bb1e94b5303a0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -108200045.53 | Std: 13647390.98 | Threshold: -106835306.43\n",
      "Policy Returns: {'policy_3': -119666997.65437444, 'policy_2': -115362576.94063695, 'policy_1': -112825953.80405252, 'policy_0': -84944653.7216548}\n",
      "Best Trainable: policy_0 (-84944653.72)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -1699721.477841093, 'agent_1': -1768190.8198989343, 'agent_2': -4377432.308209407, 'agent_3': -1241279.6389684814} id_=62df59d0d7414e7a894bb1e94b5303a0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 62df59d0d7414e7a894bb1e94b5303a0 NAV Verification ====================\n",
      "  agent_0 NAV: 998,387.00\n",
      "  agent_1 NAV: 1,008,447.00\n",
      "  agent_2 NAV: 999,868.00\n",
      "  agent_3 NAV: 993,298.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode cb3e45b486a84a2ba0bef1a5481316a6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -54911139.75013471, 'agent_1': -135455391.33434856, 'agent_2': -36261426.13954666, 'agent_3': -206131530.23107687} id_=cb3e45b486a84a2ba0bef1a5481316a6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode cb3e45b486a84a2ba0bef1a5481316a6 NAV Verification ====================\n",
      "  agent_0 NAV: 997,734.00\n",
      "  agent_1 NAV: 995,342.00\n",
      "  agent_2 NAV: 996,968.00\n",
      "  agent_3 NAV: 1,009,956.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode e6069915258946f5bbd3860c01d58059 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -81287655.28968264, 'agent_1': -142466041.98665082, 'agent_2': -39027645.627551325, 'agent_3': -74074032.49285702} id_=e6069915258946f5bbd3860c01d58059)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e6069915258946f5bbd3860c01d58059 NAV Verification ====================\n",
      "  agent_0 NAV: 994,155.00\n",
      "  agent_1 NAV: 997,564.00\n",
      "  agent_2 NAV: 1,004,339.00\n",
      "  agent_3 NAV: 1,003,942.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 06c738ee7b65483fa58d3ed2fd4e2479 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -7080721.23266497, 'agent_1': -89344359.8557399, 'agent_2': -22809857.880833186, 'agent_3': -86942845.68509015} id_=06c738ee7b65483fa58d3ed2fd4e2479)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 06c738ee7b65483fa58d3ed2fd4e2479 NAV Verification ====================\n",
      "  agent_0 NAV: 999,336.00\n",
      "  agent_1 NAV: 995,345.00\n",
      "  agent_2 NAV: 1,002,444.00\n",
      "  agent_3 NAV: 1,002,875.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 675eaea928c546c4b427d7d9f49c180b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -98342550.29 | Std: 15905540.39 | Threshold: -96751996.25\n",
      "Policy Returns: {'policy_3': -113777345.82233614, 'policy_2': -92727357.17767428, 'policy_1': -112060272.49583688, 'policy_0': -74805225.66081384}\n",
      "Best Trainable: policy_0 (-74805225.66)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_0\n",
      "Return: -74805225.66\n",
      "Iteration: 3\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_2 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -9597212.136818878, 'agent_1': -6993838.253360987, 'agent_2': -3018374.6082456037, 'agent_3': -4973674.832271347} id_=675eaea928c546c4b427d7d9f49c180b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 675eaea928c546c4b427d7d9f49c180b NAV Verification ====================\n",
      "  agent_0 NAV: 996,897.00\n",
      "  agent_1 NAV: 997,109.00\n",
      "  agent_2 NAV: 1,001,358.00\n",
      "  agent_3 NAV: 1,004,636.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode cf178f1bcb4e402dbee069273ea60f6f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -225687128.12982872, 'agent_1': -161603428.39486438, 'agent_2': -82937917.31426534, 'agent_3': -110552567.12690319} id_=cf178f1bcb4e402dbee069273ea60f6f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode cf178f1bcb4e402dbee069273ea60f6f NAV Verification ====================\n",
      "  agent_0 NAV: 968,430.00\n",
      "  agent_1 NAV: 1,012,480.00\n",
      "  agent_2 NAV: 996,289.00\n",
      "  agent_3 NAV: 1,022,801.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 528222a07eaa4cfe84aa5d2e0002e4ea Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -33923316.69141497, 'agent_1': -546176735.8261787, 'agent_2': -166723391.7979504, 'agent_3': -365236860.90445596} id_=528222a07eaa4cfe84aa5d2e0002e4ea)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 528222a07eaa4cfe84aa5d2e0002e4ea NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,509.00\n",
      "  agent_1 NAV: 1,022,331.00\n",
      "  agent_2 NAV: 986,056.00\n",
      "  agent_3 NAV: 985,104.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 5cb341098a004535b5fe718baf40987f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -135344334.8871743, 'agent_1': -203017586.52316132, 'agent_2': -43928798.78329146, 'agent_3': -53550164.280072756} id_=5cb341098a004535b5fe718baf40987f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5cb341098a004535b5fe718baf40987f NAV Verification ====================\n",
      "  agent_0 NAV: 990,622.00\n",
      "  agent_1 NAV: 1,015,832.00\n",
      "  agent_2 NAV: 999,339.00\n",
      "  agent_3 NAV: 994,207.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode a83fc302599c4c80b6bd89692affd7fc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -116759159.32 | Std: 25878945.08 | Threshold: -114171264.81\n",
      "Policy Returns: {'policy_3': -132697143.88262127, 'policy_2': -92017068.01298532, 'policy_1': -150943192.2417928, 'policy_0': -91379233.14655939}\n",
      "Best Trainable: policy_0 (-91379233.15)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -952837.3149390356, 'agent_1': -13507560.038641332, 'agent_2': -7776991.317997008, 'agent_3': -5376855.417215793} id_=a83fc302599c4c80b6bd89692affd7fc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a83fc302599c4c80b6bd89692affd7fc NAV Verification ====================\n",
      "  agent_0 NAV: 999,851.00\n",
      "  agent_1 NAV: 999,722.00\n",
      "  agent_2 NAV: 999,523.00\n",
      "  agent_3 NAV: 1,000,904.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 16b7568fed7e46849fc0b3f3074149a6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -24841365.15707459, 'agent_1': -97182071.42058732, 'agent_2': -116739062.86429363, 'agent_3': -24785909.74286385} id_=16b7568fed7e46849fc0b3f3074149a6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 16b7568fed7e46849fc0b3f3074149a6 NAV Verification ====================\n",
      "  agent_0 NAV: 995,722.00\n",
      "  agent_1 NAV: 1,000,453.00\n",
      "  agent_2 NAV: 1,001,063.00\n",
      "  agent_3 NAV: 1,002,762.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 78abed0e382e466a978008df98a2f26b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -131293930.04279834, 'agent_1': -141173209.76335403, 'agent_2': -54702604.16447678, 'agent_3': -309344795.86492825} id_=78abed0e382e466a978008df98a2f26b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 78abed0e382e466a978008df98a2f26b NAV Verification ====================\n",
      "  agent_0 NAV: 998,085.00\n",
      "  agent_1 NAV: 999,607.00\n",
      "  agent_2 NAV: 1,004,923.00\n",
      "  agent_3 NAV: 997,385.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 370f9bcb1a0742d99e91bd1196ef942a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -78596922.73961517, 'agent_1': -164348164.68122506, 'agent_2': -112307372.29778796, 'agent_3': -51291846.66011378} id_=370f9bcb1a0742d99e91bd1196ef942a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 370f9bcb1a0742d99e91bd1196ef942a NAV Verification ====================\n",
      "  agent_0 NAV: 1,008,092.00\n",
      "  agent_1 NAV: 999,931.00\n",
      "  agent_2 NAV: 1,002,847.00\n",
      "  agent_3 NAV: 989,130.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode f350d212f5a449189028fdc96d366a5d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -115903114.15 | Std: 27108453.76 | Threshold: -113192268.77\n",
      "Policy Returns: {'policy_3': -130950441.06801154, 'policy_2': -94325321.567345, 'policy_1': -152530948.72245654, 'policy_0': -85805745.22594297}\n",
      "Best Trainable: policy_0 (-85805745.23)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_1 (from iteration 1, return=-44423201.87)\n",
      "‚úì Champion removed. Active champions: ['champion_2']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -85805745.23\n",
      "Iteration: 5\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_3 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -138171.84408475834, 'agent_1': -5335442.488507074, 'agent_2': -2243270.2913141055, 'agent_3': -2131741.5091884937} id_=f350d212f5a449189028fdc96d366a5d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f350d212f5a449189028fdc96d366a5d NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,721.00\n",
      "  agent_1 NAV: 1,001,540.00\n",
      "  agent_2 NAV: 1,001,192.00\n",
      "  agent_3 NAV: 993,547.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 2144fcc070b945cf9fcaaee913229835 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -138109734.1915423, 'agent_1': -230710759.80232552, 'agent_2': -53327822.62391267, 'agent_3': -18244566.222396787} id_=2144fcc070b945cf9fcaaee913229835)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 2144fcc070b945cf9fcaaee913229835 NAV Verification ====================\n",
      "  agent_0 NAV: 992,117.00\n",
      "  agent_1 NAV: 1,009,387.00\n",
      "  agent_2 NAV: 997,255.00\n",
      "  agent_3 NAV: 1,001,241.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode ba285665b7dd403d9c26d25bac14baef Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -144932720.34917793, 'agent_1': -294612910.3175668, 'agent_2': -192246904.2067275, 'agent_3': -246828691.2020784} id_=ba285665b7dd403d9c26d25bac14baef)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ba285665b7dd403d9c26d25bac14baef NAV Verification ====================\n",
      "  agent_0 NAV: 990,908.00\n",
      "  agent_1 NAV: 991,779.00\n",
      "  agent_2 NAV: 1,007,815.00\n",
      "  agent_3 NAV: 1,009,498.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode bd22f9ee67624a65bf50834b395065f2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -254504200.6312595, 'agent_1': -298479249.54467267, 'agent_2': -135775333.7919337, 'agent_3': -154852214.35618302} id_=bd22f9ee67624a65bf50834b395065f2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bd22f9ee67624a65bf50834b395065f2 NAV Verification ====================\n",
      "  agent_0 NAV: 987,368.00\n",
      "  agent_1 NAV: 1,013,485.00\n",
      "  agent_2 NAV: 1,007,613.00\n",
      "  agent_3 NAV: 991,534.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 500109ceb9de4ad484c178791382b7ac Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -130097111.64 | Std: 34764497.19 | Threshold: -126620661.92\n",
      "Policy Returns: {'policy_3': -135848974.04627234, 'policy_2': -102729690.40637866, 'policy_1': -184600458.34598014, 'policy_0': -97209323.77501461}\n",
      "Best Trainable: policy_0 (-97209323.78)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -20926986.72314591, 'agent_1': -17431027.746018667, 'agent_2': -18297814.65324053, 'agent_3': -12280012.219101725} id_=500109ceb9de4ad484c178791382b7ac)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 500109ceb9de4ad484c178791382b7ac NAV Verification ====================\n",
      "  agent_0 NAV: 1,010,299.00\n",
      "  agent_1 NAV: 1,007,169.00\n",
      "  agent_2 NAV: 988,503.00\n",
      "  agent_3 NAV: 994,029.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 454d22ea2ecf41f8a467526fcbf8d8f0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -144025427.58134264, 'agent_1': -61960375.23502953, 'agent_2': -35693575.821756765, 'agent_3': -159618971.8985347} id_=454d22ea2ecf41f8a467526fcbf8d8f0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 454d22ea2ecf41f8a467526fcbf8d8f0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,015,010.00\n",
      "  agent_1 NAV: 1,012,033.00\n",
      "  agent_2 NAV: 992,594.00\n",
      "  agent_3 NAV: 980,363.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode f675e6d8e2c7425a953c532f695e5845 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -91716407.18530095, 'agent_1': -170436821.50716004, 'agent_2': -41137122.93542606, 'agent_3': -26261441.33648581} id_=f675e6d8e2c7425a953c532f695e5845)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f675e6d8e2c7425a953c532f695e5845 NAV Verification ====================\n",
      "  agent_0 NAV: 1,014,352.00\n",
      "  agent_1 NAV: 975,666.00\n",
      "  agent_2 NAV: 1,005,838.00\n",
      "  agent_3 NAV: 1,004,144.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 1dd61b85c90f45bca58e09c75c0834c4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -22924321.23269461, 'agent_1': -25255855.13911092, 'agent_2': -27828484.874694355, 'agent_3': -51942632.33607254} id_=1dd61b85c90f45bca58e09c75c0834c4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 1dd61b85c90f45bca58e09c75c0834c4 NAV Verification ====================\n",
      "  agent_0 NAV: 994,236.00\n",
      "  agent_1 NAV: 994,690.00\n",
      "  agent_2 NAV: 1,008,106.00\n",
      "  agent_3 NAV: 1,002,968.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 2c70dbc3af2b45f5922181e4fa6b9d0b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -128512509.55 | Std: 30310466.54 | Threshold: -125481462.90\n",
      "Policy Returns: {'policy_3': -132063484.1999188, 'policy_2': -101889764.84764965, 'policy_1': -176704664.7350784, 'policy_0': -103392124.42901033}\n",
      "Best Trainable: policy_0 (-103392124.43)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_2 (from iteration 3, return=-74805225.66)\n",
      "‚úì Champion removed. Active champions: ['champion_3']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -103392124.43\n",
      "Iteration: 7\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_4 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -1680440.4844496108, 'agent_1': -2395353.186150738, 'agent_2': -752073.2951745137, 'agent_3': -1588166.1944159023} id_=2c70dbc3af2b45f5922181e4fa6b9d0b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 2c70dbc3af2b45f5922181e4fa6b9d0b NAV Verification ====================\n",
      "  agent_0 NAV: 994,553.00\n",
      "  agent_1 NAV: 1,010,069.00\n",
      "  agent_2 NAV: 996,072.00\n",
      "  agent_3 NAV: 999,306.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode a38d031390d44a04b4d126a0a36b0497 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -19864487.110484786, 'agent_1': -136412346.96508688, 'agent_2': -122663761.78591679, 'agent_3': -21221513.781893644} id_=a38d031390d44a04b4d126a0a36b0497)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a38d031390d44a04b4d126a0a36b0497 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,822.00\n",
      "  agent_1 NAV: 1,004,559.00\n",
      "  agent_2 NAV: 991,201.00\n",
      "  agent_3 NAV: 1,003,418.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode ad276e6d35954098824eee94081a312e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -26986812.77647362, 'agent_1': -322517308.3511926, 'agent_2': -59276870.13215172, 'agent_3': -233855857.45474482} id_=ad276e6d35954098824eee94081a312e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ad276e6d35954098824eee94081a312e NAV Verification ====================\n",
      "  agent_0 NAV: 994,378.00\n",
      "  agent_1 NAV: 1,015,456.00\n",
      "  agent_2 NAV: 991,954.00\n",
      "  agent_3 NAV: 998,212.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 2c3dfa24533b480c98ea67d1378d46af Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -69317859.45380147, 'agent_1': -357153986.38917255, 'agent_2': -156372459.05200666, 'agent_3': -65383698.28325342} id_=2c3dfa24533b480c98ea67d1378d46af)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 2c3dfa24533b480c98ea67d1378d46af NAV Verification ====================\n",
      "  agent_0 NAV: 988,974.00\n",
      "  agent_1 NAV: 1,036,563.00\n",
      "  agent_2 NAV: 977,592.00\n",
      "  agent_3 NAV: 996,871.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode bef53e116bbb48049764333bc0ac724f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -125644984.14 | Std: 34478155.43 | Threshold: -122197168.60\n",
      "Policy Returns: {'policy_3': -125891679.33409606, 'policy_2': -100243878.67823486, 'policy_1': -181772870.17227572, 'policy_0': -94671508.38536823}\n",
      "Best Trainable: policy_0 (-94671508.39)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -1478269.216227806, 'agent_1': -2551996.7926403666, 'agent_2': -346178.25680126, 'agent_3': -206909.63213726907} id_=bef53e116bbb48049764333bc0ac724f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bef53e116bbb48049764333bc0ac724f NAV Verification ====================\n",
      "  agent_0 NAV: 995,241.00\n",
      "  agent_1 NAV: 1,002,863.00\n",
      "  agent_2 NAV: 1,003,621.00\n",
      "  agent_3 NAV: 998,275.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 516bd5b08e9540dcb45260ef3e73995e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -54724528.175994515, 'agent_1': -147288340.98855156, 'agent_2': -67495874.82304068, 'agent_3': -44029069.71767719} id_=516bd5b08e9540dcb45260ef3e73995e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 516bd5b08e9540dcb45260ef3e73995e NAV Verification ====================\n",
      "  agent_0 NAV: 993,412.00\n",
      "  agent_1 NAV: 997,546.00\n",
      "  agent_2 NAV: 1,001,655.00\n",
      "  agent_3 NAV: 1,007,387.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 8cf0254c95e24ca1b915510645de4a77 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -33902339.96673719, 'agent_1': -219671592.38858062, 'agent_2': -96149398.3382151, 'agent_3': -106161597.31027633} id_=8cf0254c95e24ca1b915510645de4a77)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8cf0254c95e24ca1b915510645de4a77 NAV Verification ====================\n",
      "  agent_0 NAV: 999,640.00\n",
      "  agent_1 NAV: 1,027,223.00\n",
      "  agent_2 NAV: 988,882.00\n",
      "  agent_3 NAV: 984,255.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 236706e1f315429c932482390387a9a9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -141030386.07048848, 'agent_1': -408414355.94619966, 'agent_2': -169765225.181568, 'agent_3': -57439721.35057379} id_=236706e1f315429c932482390387a9a9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 236706e1f315429c932482390387a9a9 NAV Verification ====================\n",
      "  agent_0 NAV: 990,543.00\n",
      "  agent_1 NAV: 1,025,744.00\n",
      "  agent_2 NAV: 991,332.00\n",
      "  agent_3 NAV: 992,381.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode ee54ab0bc6d04338adae2143e3b20651 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -123957445.94 | Std: 36836630.03 | Threshold: -120273782.93\n",
      "Policy Returns: {'policy_3': -118251152.23384877, 'policy_2': -98991804.3369313, 'policy_1': -185669702.74967045, 'policy_0': -92917124.42575099}\n",
      "Best Trainable: policy_0 (-92917124.43)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_3 (from iteration 5, return=-85805745.23)\n",
      "‚úì Champion removed. Active champions: ['champion_4']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -92917124.43\n",
      "Iteration: 9\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_5 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -4419080.977230958, 'agent_1': -3557494.428014644, 'agent_2': -1798327.3132800653, 'agent_3': -255380.66259725913} id_=ee54ab0bc6d04338adae2143e3b20651)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ee54ab0bc6d04338adae2143e3b20651 NAV Verification ====================\n",
      "  agent_0 NAV: 1,002,268.00\n",
      "  agent_1 NAV: 998,980.00\n",
      "  agent_2 NAV: 1,002,828.00\n",
      "  agent_3 NAV: 995,924.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode c0de9cc26a934879b1c56038e6dd165b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -49811322.98588895, 'agent_1': -151555313.32398435, 'agent_2': -28339389.95326673, 'agent_3': -130636715.06492311} id_=c0de9cc26a934879b1c56038e6dd165b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c0de9cc26a934879b1c56038e6dd165b NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,073.00\n",
      "  agent_1 NAV: 1,002,673.00\n",
      "  agent_2 NAV: 1,000,076.00\n",
      "  agent_3 NAV: 991,178.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 6b4fb9cbf5434b65a7579114de6b99e4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -53419513.03554571, 'agent_1': -108239921.12832808, 'agent_2': -15332403.013226138, 'agent_3': -62067440.34493284} id_=6b4fb9cbf5434b65a7579114de6b99e4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6b4fb9cbf5434b65a7579114de6b99e4 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,814.00\n",
      "  agent_1 NAV: 1,004,715.00\n",
      "  agent_2 NAV: 998,908.00\n",
      "  agent_3 NAV: 995,563.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode ecbaab48f21540acaed6acdb44540cd5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -46220078.22474345, 'agent_1': -97090904.55911052, 'agent_2': -28026258.45876711, 'agent_3': -30500858.876447443} id_=ecbaab48f21540acaed6acdb44540cd5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ecbaab48f21540acaed6acdb44540cd5 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,275.00\n",
      "  agent_1 NAV: 997,659.00\n",
      "  agent_2 NAV: 1,000,293.00\n",
      "  agent_3 NAV: 1,001,773.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 4243d1c35ed34413aa93235a075be616 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -118434403.75 | Std: 35468589.04 | Threshold: -114887544.85\n",
      "Policy Returns: {'policy_3': -112841082.66068459, 'policy_2': -92932281.4727123, 'policy_1': -177953573.30392677, 'policy_0': -90010677.58144557}\n",
      "Best Trainable: policy_0 (-90010677.58)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -5376835.122876392, 'agent_1': -5175977.8438087115, 'agent_2': -2111721.3644932313, 'agent_3': -1078334.5415937444} id_=4243d1c35ed34413aa93235a075be616)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4243d1c35ed34413aa93235a075be616 NAV Verification ====================\n",
      "  agent_0 NAV: 987,853.00\n",
      "  agent_1 NAV: 1,011,166.00\n",
      "  agent_2 NAV: 999,589.00\n",
      "  agent_3 NAV: 1,001,392.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 5bd7426718374ac98b04c96201985b26 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -24555379.33592397, 'agent_1': -265274765.84673524, 'agent_2': -63006563.310969785, 'agent_3': -149977666.09969792} id_=5bd7426718374ac98b04c96201985b26)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5bd7426718374ac98b04c96201985b26 NAV Verification ====================\n",
      "  agent_0 NAV: 991,664.00\n",
      "  agent_1 NAV: 1,034,277.00\n",
      "  agent_2 NAV: 1,000,478.00\n",
      "  agent_3 NAV: 973,581.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode e7727123607543e4a33a851a832956df Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -86094393.9931637, 'agent_1': -390855584.95185953, 'agent_2': -144714802.30978826, 'agent_3': -60913982.25851555} id_=e7727123607543e4a33a851a832956df)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e7727123607543e4a33a851a832956df NAV Verification ====================\n",
      "  agent_0 NAV: 990,276.00\n",
      "  agent_1 NAV: 1,012,401.00\n",
      "  agent_2 NAV: 1,000,747.00\n",
      "  agent_3 NAV: 996,576.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 4caad69d8c67450bbe5f4e345c14bc37 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -31110900.91771068, 'agent_1': -143956650.29646292, 'agent_2': -26351714.605979864, 'agent_3': -113147445.49406089} id_=4caad69d8c67450bbe5f4e345c14bc37)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4caad69d8c67450bbe5f4e345c14bc37 NAV Verification ====================\n",
      "  agent_0 NAV: 995,834.00\n",
      "  agent_1 NAV: 1,017,458.00\n",
      "  agent_2 NAV: 1,005,174.00\n",
      "  agent_3 NAV: 981,534.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode f7d5d0f31d9c4869aa8483f3e2de2731 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -117858678.17 | Std: 38493989.48 | Threshold: -114009279.22\n",
      "Policy Returns: {'policy_3': -110208561.7115526, 'policy_2': -90963171.5760478, 'policy_1': -182820882.17713857, 'policy_0': -87442097.2207127}\n",
      "Best Trainable: policy_0 (-87442097.22)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_4 (from iteration 7, return=-103392124.43)\n",
      "‚úì Champion removed. Active champions: ['champion_5']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -87442097.22\n",
      "Iteration: 11\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_6 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -5757404.049351538, 'agent_1': -27616974.61486606, 'agent_2': -225230.20028114828, 'agent_3': -14302268.803463852} id_=f7d5d0f31d9c4869aa8483f3e2de2731)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f7d5d0f31d9c4869aa8483f3e2de2731 NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,875.00\n",
      "  agent_1 NAV: 967,689.00\n",
      "  agent_2 NAV: 998,449.00\n",
      "  agent_3 NAV: 1,027,987.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 47179503849b43b7806e315f12a3a497 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -33115344.842686027, 'agent_1': -74736537.39034668, 'agent_2': -69080325.05766577, 'agent_3': -90595511.25502896} id_=47179503849b43b7806e315f12a3a497)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 47179503849b43b7806e315f12a3a497 NAV Verification ====================\n",
      "  agent_0 NAV: 997,314.00\n",
      "  agent_1 NAV: 1,011,383.00\n",
      "  agent_2 NAV: 999,232.00\n",
      "  agent_3 NAV: 992,071.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 6476666354504db69fe8b9156ec52288 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -64219040.6021448, 'agent_1': -98893373.87289381, 'agent_2': -90549678.93653762, 'agent_3': -39686678.20928293} id_=6476666354504db69fe8b9156ec52288)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6476666354504db69fe8b9156ec52288 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,318.00\n",
      "  agent_1 NAV: 1,003,631.00\n",
      "  agent_2 NAV: 999,045.00\n",
      "  agent_3 NAV: 997,006.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 19477c6b434049d1890ecf27831583cb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -54950878.34884701, 'agent_1': -224158099.0204831, 'agent_2': -155844622.028776, 'agent_3': -14928480.784755427} id_=19477c6b434049d1890ecf27831583cb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 19477c6b434049d1890ecf27831583cb NAV Verification ====================\n",
      "  agent_0 NAV: 992,833.00\n",
      "  agent_1 NAV: 1,016,595.00\n",
      "  agent_2 NAV: 989,784.00\n",
      "  agent_3 NAV: 1,000,788.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 867e4975783943659284416dd42a244b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -118391939.67 | Std: 40311753.31 | Threshold: -114360764.34\n",
      "Policy Returns: {'policy_3': -110993480.56198217, 'policy_2': -90779451.97868286, 'policy_1': -186246593.52953336, 'policy_0': -85548232.59643674}\n",
      "Best Trainable: policy_0 (-85548232.60)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -3004471.4853250263, 'agent_1': -9261952.626832686, 'agent_2': -6717515.643914394, 'agent_3': -4056735.276107545} id_=867e4975783943659284416dd42a244b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 867e4975783943659284416dd42a244b NAV Verification ====================\n",
      "  agent_0 NAV: 996,666.00\n",
      "  agent_1 NAV: 1,010,550.00\n",
      "  agent_2 NAV: 998,268.00\n",
      "  agent_3 NAV: 994,516.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode a3d581093b9848fca891a7dd02c5d600 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -28036390.241500646, 'agent_1': -41546055.3172117, 'agent_2': -80254918.97999586, 'agent_3': -73135775.84541832} id_=a3d581093b9848fca891a7dd02c5d600)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a3d581093b9848fca891a7dd02c5d600 NAV Verification ====================\n",
      "  agent_0 NAV: 994,384.00\n",
      "  agent_1 NAV: 1,008,384.00\n",
      "  agent_2 NAV: 991,727.00\n",
      "  agent_3 NAV: 1,005,505.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 15bc3db340ff441db41cf82e9526f41f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -20920361.67004409, 'agent_1': -59561494.87099968, 'agent_2': -24742425.050807234, 'agent_3': -56976152.30252601} id_=15bc3db340ff441db41cf82e9526f41f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 15bc3db340ff441db41cf82e9526f41f NAV Verification ====================\n",
      "  agent_0 NAV: 1,002,820.00\n",
      "  agent_1 NAV: 1,002,009.00\n",
      "  agent_2 NAV: 997,382.00\n",
      "  agent_3 NAV: 997,789.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 334381985a984d608c05de3e5141adbf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -62316376.56098185, 'agent_1': -62963199.24066274, 'agent_2': -59172494.90769503, 'agent_3': -47020575.031025305} id_=334381985a984d608c05de3e5141adbf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 334381985a984d608c05de3e5141adbf NAV Verification ====================\n",
      "  agent_0 NAV: 998,120.00\n",
      "  agent_1 NAV: 1,004,318.00\n",
      "  agent_2 NAV: 998,606.00\n",
      "  agent_3 NAV: 998,956.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 1a80896db32541eba4bc8ff3656ba5bd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -113524917.38 | Std: 38098819.08 | Threshold: -109715035.47\n",
      "Policy Returns: {'policy_3': -107286881.56235611, 'policy_2': -88057759.72148997, 'policy_1': -177419064.9059371, 'policy_0': -81335963.31196105}\n",
      "Best Trainable: policy_0 (-81335963.31)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_5 (from iteration 9, return=-92917124.43)\n",
      "‚úì Champion removed. Active champions: ['champion_6']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -81335963.31\n",
      "Iteration: 13\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_7 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -4899004.06339014, 'agent_1': -79668984.29525974, 'agent_2': -40394459.0910882, 'agent_3': -28995509.087989323} id_=1a80896db32541eba4bc8ff3656ba5bd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 1a80896db32541eba4bc8ff3656ba5bd NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,450.00\n",
      "  agent_1 NAV: 1,017,902.00\n",
      "  agent_2 NAV: 988,663.00\n",
      "  agent_3 NAV: 989,985.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode d096b9a21fbd4e4483dd98541bf12be3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -82161440.25018112, 'agent_1': -111041533.4912991, 'agent_2': -20677790.747858666, 'agent_3': -10644771.623759868} id_=d096b9a21fbd4e4483dd98541bf12be3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d096b9a21fbd4e4483dd98541bf12be3 NAV Verification ====================\n",
      "  agent_0 NAV: 988,567.00\n",
      "  agent_1 NAV: 1,011,821.00\n",
      "  agent_2 NAV: 1,001,290.00\n",
      "  agent_3 NAV: 998,322.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 32121618d37c4bc2826062fbe31d9bb3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -73889813.78736985, 'agent_1': -185450068.0037713, 'agent_2': -30502289.869794186, 'agent_3': -67121092.2675057} id_=32121618d37c4bc2826062fbe31d9bb3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 32121618d37c4bc2826062fbe31d9bb3 NAV Verification ====================\n",
      "  agent_0 NAV: 998,497.00\n",
      "  agent_1 NAV: 1,002,935.00\n",
      "  agent_2 NAV: 994,331.00\n",
      "  agent_3 NAV: 1,004,237.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode f578d40ca4404fbdbb2bea863d50b432 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -52332149.4765211, 'agent_1': -209817669.21000978, 'agent_2': -37407305.1084533, 'agent_3': -192721914.53279012} id_=f578d40ca4404fbdbb2bea863d50b432)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f578d40ca4404fbdbb2bea863d50b432 NAV Verification ====================\n",
      "  agent_0 NAV: 995,063.00\n",
      "  agent_1 NAV: 996,858.00\n",
      "  agent_2 NAV: 1,001,916.00\n",
      "  agent_3 NAV: 1,006,163.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 88712c003b4a4b16abcb4b23c787020f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -112934673.93 | Std: 39723439.80 | Threshold: -108962329.95\n",
      "Policy Returns: {'policy_3': -107330535.1327196, 'policy_2': -85317429.45680787, 'policy_1': -179374362.94677272, 'policy_0': -79716368.16748299}\n",
      "Best Trainable: policy_0 (-79716368.17)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -3026618.679981865, 'agent_1': -8611884.080440512, 'agent_2': -1073022.1669342397, 'agent_3': -2133949.80535187} id_=88712c003b4a4b16abcb4b23c787020f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 88712c003b4a4b16abcb4b23c787020f NAV Verification ====================\n",
      "  agent_0 NAV: 997,632.00\n",
      "  agent_1 NAV: 1,003,892.00\n",
      "  agent_2 NAV: 1,001,373.00\n",
      "  agent_3 NAV: 997,103.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode ecbf7596985b48528b31ddd1637c64d1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -53502315.6940642, 'agent_1': -286587915.16031045, 'agent_2': -48337248.61506818, 'agent_3': -107417209.1367213} id_=ecbf7596985b48528b31ddd1637c64d1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ecbf7596985b48528b31ddd1637c64d1 NAV Verification ====================\n",
      "  agent_0 NAV: 995,672.00\n",
      "  agent_1 NAV: 1,015,896.00\n",
      "  agent_2 NAV: 995,074.00\n",
      "  agent_3 NAV: 993,358.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode b795fd9fee2f493fbf53d7192ae8b6c0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -113992115.24585268, 'agent_1': -76998844.67084792, 'agent_2': -134434089.27534318, 'agent_3': -60422752.15762963} id_=b795fd9fee2f493fbf53d7192ae8b6c0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode b795fd9fee2f493fbf53d7192ae8b6c0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,153.00\n",
      "  agent_1 NAV: 1,008,931.00\n",
      "  agent_2 NAV: 989,357.00\n",
      "  agent_3 NAV: 990,559.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 015f9f5bb6194bedaf568da34406e003 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -78616924.49070409, 'agent_1': -142449896.31350037, 'agent_2': -77436626.53519876, 'agent_3': -102580832.00025055} id_=015f9f5bb6194bedaf568da34406e003)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 015f9f5bb6194bedaf568da34406e003 NAV Verification ====================\n",
      "  agent_0 NAV: 995,666.00\n",
      "  agent_1 NAV: 1,008,028.00\n",
      "  agent_2 NAV: 1,006,257.00\n",
      "  agent_3 NAV: 990,049.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 12428bf90a6647a192cdffa551fb4465 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -111596758.60 | Std: 39382593.41 | Threshold: -107658499.26\n",
      "Policy Returns: {'policy_3': -105219982.41021636, 'policy_2': -84202065.00551862, 'policy_1': -177689027.8896321, 'policy_0': -79275959.07857655}\n",
      "Best Trainable: policy_0 (-79275959.08)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_6 (from iteration 11, return=-87442097.22)\n",
      "‚úì Champion removed. Active champions: ['champion_7']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -79275959.08\n",
      "Iteration: 15\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_8 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_7', 'champion_8']\n",
      "\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -4832670.702467929, 'agent_1': -5718076.988027277, 'agent_2': -2455747.6287631053, 'agent_3': -1241308.624688258} id_=12428bf90a6647a192cdffa551fb4465)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 12428bf90a6647a192cdffa551fb4465 NAV Verification ====================\n",
      "  agent_0 NAV: 993,512.00\n",
      "  agent_1 NAV: 1,010,602.00\n",
      "  agent_2 NAV: 1,000,627.00\n",
      "  agent_3 NAV: 995,259.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 6d8e92c4f9ce414cba42766f9b2ca42a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -38829721.816030666, 'agent_1': -304746824.3223271, 'agent_2': -170043918.78544062, 'agent_3': -67194121.92050563} id_=6d8e92c4f9ce414cba42766f9b2ca42a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6d8e92c4f9ce414cba42766f9b2ca42a NAV Verification ====================\n",
      "  agent_0 NAV: 989,634.00\n",
      "  agent_1 NAV: 1,030,843.00\n",
      "  agent_2 NAV: 992,665.00\n",
      "  agent_3 NAV: 986,858.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode d9120d3a656244c4a7b82c38c59275c5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -49797748.751439385, 'agent_1': -285669101.1046604, 'agent_2': -109638394.62731802, 'agent_3': -79613123.05082437} id_=d9120d3a656244c4a7b82c38c59275c5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d9120d3a656244c4a7b82c38c59275c5 NAV Verification ====================\n",
      "  agent_0 NAV: 997,820.00\n",
      "  agent_1 NAV: 1,018,249.00\n",
      "  agent_2 NAV: 991,856.00\n",
      "  agent_3 NAV: 992,075.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode f5887d99e77f47b6ab7bb55ef30bfada Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -24973267.76226561, 'agent_1': -61789808.9649244, 'agent_2': -85770251.87537515, 'agent_3': -36650911.82823883} id_=f5887d99e77f47b6ab7bb55ef30bfada)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f5887d99e77f47b6ab7bb55ef30bfada NAV Verification ====================\n",
      "  agent_0 NAV: 999,823.00\n",
      "  agent_1 NAV: 998,893.00\n",
      "  agent_2 NAV: 1,007,082.00\n",
      "  agent_3 NAV: 994,202.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 1449ba5c2d3f44a991c405337c77c5d4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_8\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -110177230.06 | Std: 39875160.52 | Threshold: -106189714.01\n",
      "Policy Returns: {'policy_3': -101652608.53986515, 'policy_2': -85013456.8426878, 'policy_1': -177453436.5129126, 'policy_0': -76589418.35205139}\n",
      "Best Trainable: policy_0 (-76589418.35)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ‚Üê KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-24 09:30:28\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
