{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with naive competitive self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"‚ùå No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 04:46:23,358\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-24 04:46:24,582\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_2', 'agent_1', 'agent_3', 'agent_0']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 04:46:26,553\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.76gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-12-24 04:46:27,598\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"f9f798b3-fcfb-4efe-a42f-6a89e4c4ef99\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 4\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x7e0a4688b970>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x7e0a4688b910>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x7e0a4688b940>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x7e0a4688bb20>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=2,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ‚Üê ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 04:46:27,987\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2025-12-24 04:46:27,988\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 4096\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-12-24 04:46:28,235\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-24 04:46:28,261\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2025-12-24 04:46:28,294\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-24 04:46:28,320\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2025-12-24 04:46:28,331\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2025-12-24 04:46:28,341\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2025-12-24 04:46:28,343\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-12-24 04:46:28,355\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,355\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,355\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,356\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,356\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,370\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,371\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2025-12-24 04:46:28,372\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32)), Dict('agent_0': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_1': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_2': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_3': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)))), 'policy_0': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_1': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_2': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_3': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)))}\n",
      "2025-12-24 04:46:28,405\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:28,405\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:28,415\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:28,424\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:28,433\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:28,443\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:28,452\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:29,318\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2025-12-24 04:46:29,349\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 4096\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 943df866ee5b425c816ef5b01cd5ffeb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -29963189.035379674, 'agent_1': -121259362.6955838, 'agent_2': -31590847.086735368, 'agent_3': -51419389.86954945} id_=943df866ee5b425c816ef5b01cd5ffeb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 943df866ee5b425c816ef5b01cd5ffeb NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,731.00\n",
      "  agent_1 NAV: 968,856.00\n",
      "  agent_2 NAV: 1,010,106.00\n",
      "  agent_3 NAV: 1,014,307.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 677e1daefde24534843461f2d68aa081 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -30099032.458365303, 'agent_1': -87074968.37088469, 'agent_2': -156859771.56153825, 'agent_3': -27255947.269767992} id_=677e1daefde24534843461f2d68aa081)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 677e1daefde24534843461f2d68aa081 NAV Verification ====================\n",
      "  agent_0 NAV: 989,003.00\n",
      "  agent_1 NAV: 1,005,292.00\n",
      "  agent_2 NAV: 1,007,901.00\n",
      "  agent_3 NAV: 997,804.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 64b4c4c3f47b45839f21093515b19cce Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -71371882.83151996, 'agent_1': -106741528.83349729, 'agent_2': -123269798.36473848, 'agent_3': -65951002.36930639} id_=64b4c4c3f47b45839f21093515b19cce)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 64b4c4c3f47b45839f21093515b19cce NAV Verification ====================\n",
      "  agent_0 NAV: 963,604.00\n",
      "  agent_1 NAV: 938,558.00\n",
      "  agent_2 NAV: 1,061,403.00\n",
      "  agent_3 NAV: 1,036,435.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode e995e5aba7fe4296a2d8a5aaa09cc88c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -75238060.06 | Std: 29271978.06 | Threshold: -72310862.26\n",
      "Policy Returns: {'policy_1': -105025286.63332193, 'policy_0': -43811368.108421646, 'policy_2': -103906805.67100404, 'policy_3': -48208779.83620795}\n",
      "Best Trainable: policy_0 (-43811368.11)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -43811368.11\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_1 created successfully!\n",
      "‚úì League size now: 3 (2 trainable + 1 champions)\n",
      "‚úì Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': 0.0, 'agent_1': 0.0, 'agent_2': 0.0, 'agent_3': 0.0} id_=e995e5aba7fe4296a2d8a5aaa09cc88c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e995e5aba7fe4296a2d8a5aaa09cc88c NAV Verification ====================\n",
      "  agent_0 NAV: 987,276.00\n",
      "  agent_1 NAV: 1,022,934.00\n",
      "  agent_2 NAV: 1,018,404.00\n",
      "  agent_3 NAV: 971,386.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode ba6a2fb7f12942b38b859fdd421e7d26 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -43186060.16337374, 'agent_1': -129342803.42631839, 'agent_2': -26053357.191673353, 'agent_3': -125303146.66199929} id_=ba6a2fb7f12942b38b859fdd421e7d26)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ba6a2fb7f12942b38b859fdd421e7d26 NAV Verification ====================\n",
      "  agent_0 NAV: 993,225.00\n",
      "  agent_1 NAV: 1,015,560.00\n",
      "  agent_2 NAV: 1,007,221.00\n",
      "  agent_3 NAV: 983,994.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 83c18fcc94e94ceb8b92c519cef66b15 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -42710310.13461255, 'agent_1': -87748288.09957346, 'agent_2': -24630922.57960668, 'agent_3': -38872258.29456928} id_=83c18fcc94e94ceb8b92c519cef66b15)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 83c18fcc94e94ceb8b92c519cef66b15 NAV Verification ====================\n",
      "  agent_0 NAV: 1,015,516.00\n",
      "  agent_1 NAV: 980,370.00\n",
      "  agent_2 NAV: 991,332.00\n",
      "  agent_3 NAV: 1,012,782.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode c762d67b943d48ca8c2afe8c807ab86e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -39805006.75460093, 'agent_1': -27410546.358863458, 'agent_2': -32075971.49973687, 'agent_3': -17755920.931208402} id_=c762d67b943d48ca8c2afe8c807ab86e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c762d67b943d48ca8c2afe8c807ab86e NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,430.00\n",
      "  agent_1 NAV: 1,006,163.00\n",
      "  agent_2 NAV: 982,941.00\n",
      "  agent_3 NAV: 997,466.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 68200d72a68548ef8baccd0db20433f7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -63948809.40 | Std: 16875014.37 | Threshold: -62261307.96\n",
      "Policy Returns: {'policy_1': -92009710.00524703, 'policy_0': -47817936.015037246, 'policy_2': -61168324.47033667, 'policy_3': -54799267.099567756}\n",
      "Best Trainable: policy_0 (-47817936.02)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -1256757.9198606273, 'agent_1': -453987.0325732899, 'agent_2': -1354650.418128655, 'agent_3': -301099.94505494507} id_=68200d72a68548ef8baccd0db20433f7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 68200d72a68548ef8baccd0db20433f7 NAV Verification ====================\n",
      "  agent_0 NAV: 1,039,897.00\n",
      "  agent_1 NAV: 1,008,587.00\n",
      "  agent_2 NAV: 953,087.00\n",
      "  agent_3 NAV: 998,429.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode f50a698cd703441fa45f118c45b1f303 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -11269836.267531581, 'agent_1': -43824247.147586495, 'agent_2': -46863413.645401515, 'agent_3': -9659334.848919274} id_=f50a698cd703441fa45f118c45b1f303)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f50a698cd703441fa45f118c45b1f303 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,544.00\n",
      "  agent_1 NAV: 982,717.00\n",
      "  agent_2 NAV: 1,012,382.00\n",
      "  agent_3 NAV: 1,000,357.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 52b6a022a4e44063925e9fcbaf722df0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -98359776.88113067, 'agent_1': -33682995.74065968, 'agent_2': -73888080.43909271, 'agent_3': -67230044.73006086} id_=52b6a022a4e44063925e9fcbaf722df0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 52b6a022a4e44063925e9fcbaf722df0 NAV Verification ====================\n",
      "  agent_0 NAV: 994,964.00\n",
      "  agent_1 NAV: 987,339.00\n",
      "  agent_2 NAV: 1,001,473.00\n",
      "  agent_3 NAV: 1,016,224.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 885e1cbdbcfc40a095239b44f1858f5b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -21502335.681191828, 'agent_1': -99160602.2855607, 'agent_2': -72311686.16342632, 'agent_3': -60484198.07649509} id_=885e1cbdbcfc40a095239b44f1858f5b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 885e1cbdbcfc40a095239b44f1858f5b NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,216.00\n",
      "  agent_1 NAV: 994,271.00\n",
      "  agent_2 NAV: 998,253.00\n",
      "  agent_3 NAV: 1,004,260.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 1736b2c596bd4b79a787906ab8d6b97c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -59010321.81 | Std: 12073664.52 | Threshold: -57802955.35\n",
      "Policy Returns: {'policy_1': -76939681.25375572, 'policy_0': -47384658.36661146, 'policy_2': -63159406.1907728, 'policy_3': -48557541.415681034}\n",
      "Best Trainable: policy_0 (-47384658.37)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_0\n",
      "Return: -47384658.37\n",
      "Iteration: 3\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_2 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -5006863.235076476, 'agent_1': -2515866.6706305086, 'agent_2': -136340.623431515, 'agent_3': -2948326.555391989} id_=1736b2c596bd4b79a787906ab8d6b97c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 1736b2c596bd4b79a787906ab8d6b97c NAV Verification ====================\n",
      "  agent_0 NAV: 993,864.00\n",
      "  agent_1 NAV: 1,003,515.00\n",
      "  agent_2 NAV: 999,194.00\n",
      "  agent_3 NAV: 1,003,427.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 9bb5c193a44e49d2ad32ffeb54bb08c6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -8918627.768637037, 'agent_1': -21925464.05618838, 'agent_2': -13525666.080376228, 'agent_3': -38051048.99684924} id_=9bb5c193a44e49d2ad32ffeb54bb08c6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9bb5c193a44e49d2ad32ffeb54bb08c6 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,802.00\n",
      "  agent_1 NAV: 996,167.00\n",
      "  agent_2 NAV: 1,001,285.00\n",
      "  agent_3 NAV: 997,746.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 3c919799d3ae441d94a1995b787717c0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -31681583.168059163, 'agent_1': -19378755.507108573, 'agent_2': -33904486.50434961, 'agent_3': -23888514.524848502} id_=3c919799d3ae441d94a1995b787717c0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3c919799d3ae441d94a1995b787717c0 NAV Verification ====================\n",
      "  agent_0 NAV: 996,116.00\n",
      "  agent_1 NAV: 1,001,911.00\n",
      "  agent_2 NAV: 1,008,593.00\n",
      "  agent_3 NAV: 993,380.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 9193ae367e5249959e124593e4539b61 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -39788431.80285062, 'agent_1': -13579453.534906114, 'agent_2': -110242890.26789454, 'agent_3': -134101632.15713961} id_=9193ae367e5249959e124593e4539b61)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9193ae367e5249959e124593e4539b61 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,244.00\n",
      "  agent_1 NAV: 1,000,420.00\n",
      "  agent_2 NAV: 974,011.00\n",
      "  agent_3 NAV: 1,024,325.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 6018af94f9ef46acab322662046cd136 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -53542300.98 | Std: 7217989.12 | Threshold: -52820502.07\n",
      "Policy Returns: {'policy_1': -62024862.1678571, 'policy_0': -43075971.276039645, 'policy_2': -58064900.24246938, 'policy_3': -51003470.2219904}\n",
      "Best Trainable: policy_0 (-43075971.28)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -4194209.9548502564, 'agent_1': -2337668.440918224, 'agent_2': -3477775.8396927016, 'agent_3': -1058582.4076819406} id_=6018af94f9ef46acab322662046cd136)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6018af94f9ef46acab322662046cd136 NAV Verification ====================\n",
      "  agent_0 NAV: 956,030.00\n",
      "  agent_1 NAV: 1,034,462.00\n",
      "  agent_2 NAV: 1,036,084.00\n",
      "  agent_3 NAV: 973,424.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 23054383328e4bc1af2b58ef4d403c53 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -8719485.62172613, 'agent_1': -39289434.54574336, 'agent_2': -11607723.041118128, 'agent_3': -32179017.53540957} id_=23054383328e4bc1af2b58ef4d403c53)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 23054383328e4bc1af2b58ef4d403c53 NAV Verification ====================\n",
      "  agent_0 NAV: 1,007,596.00\n",
      "  agent_1 NAV: 985,948.00\n",
      "  agent_2 NAV: 995,670.00\n",
      "  agent_3 NAV: 1,010,786.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 0658fe7298fd4ebbbe6a3cacd0058289 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -7026012.831815392, 'agent_1': -133626594.14938262, 'agent_2': -13007019.97406367, 'agent_3': -128654339.07331027} id_=0658fe7298fd4ebbbe6a3cacd0058289)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 0658fe7298fd4ebbbe6a3cacd0058289 NAV Verification ====================\n",
      "  agent_0 NAV: 999,799.00\n",
      "  agent_1 NAV: 1,034,471.00\n",
      "  agent_2 NAV: 996,306.00\n",
      "  agent_3 NAV: 969,424.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode c860c52c7bbf4d4e8de6eaf29d64fb8f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -72976383.25500509, 'agent_1': -52941421.72492109, 'agent_2': -128268180.67930332, 'agent_3': -26437152.22645948} id_=c860c52c7bbf4d4e8de6eaf29d64fb8f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c860c52c7bbf4d4e8de6eaf29d64fb8f NAV Verification ====================\n",
      "  agent_0 NAV: 1,012,007.00\n",
      "  agent_1 NAV: 999,422.00\n",
      "  agent_2 NAV: 994,440.00\n",
      "  agent_3 NAV: 994,131.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode be2bf16f2aa44637a691e9dd83654855 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -55754809.69 | Std: 7670747.47 | Threshold: -54987734.95\n",
      "Policy Returns: {'policy_1': -65605598.31871915, 'policy_0': -44441321.773129955, 'policy_2': -58637749.10556557, 'policy_3': -54334569.57891409}\n",
      "Best Trainable: policy_0 (-44441321.77)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_1 (from iteration 1, return=-43811368.11)\n",
      "‚úì Champion removed. Active champions: ['champion_2']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -44441321.77\n",
      "Iteration: 5\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_3 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -278972.1989761422, 'agent_1': -4918657.293756232, 'agent_2': -6252151.140868649, 'agent_3': -1006944.5251717838} id_=be2bf16f2aa44637a691e9dd83654855)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode be2bf16f2aa44637a691e9dd83654855 NAV Verification ====================\n",
      "  agent_0 NAV: 996,351.00\n",
      "  agent_1 NAV: 1,039,959.00\n",
      "  agent_2 NAV: 947,883.00\n",
      "  agent_3 NAV: 1,015,807.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode ec1f903443f74476b28f518759369d28 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -8702068.665426997, 'agent_1': -42788817.78544967, 'agent_2': -21565561.54440754, 'agent_3': -24753786.157101635} id_=ec1f903443f74476b28f518759369d28)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ec1f903443f74476b28f518759369d28 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,281.00\n",
      "  agent_1 NAV: 1,020,227.00\n",
      "  agent_2 NAV: 986,385.00\n",
      "  agent_3 NAV: 990,107.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 82c0372296ee4bb4b0e737157ec65f4f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -61945098.77810015, 'agent_1': -76353474.89606614, 'agent_2': -43557260.36611109, 'agent_3': -35901981.65600291} id_=82c0372296ee4bb4b0e737157ec65f4f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 82c0372296ee4bb4b0e737157ec65f4f NAV Verification ====================\n",
      "  agent_0 NAV: 991,422.00\n",
      "  agent_1 NAV: 1,016,180.00\n",
      "  agent_2 NAV: 985,518.00\n",
      "  agent_3 NAV: 1,006,880.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 526fedd2167a44a5a3347e22d910ffca Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -15032086.860040894, 'agent_1': -82772470.70540617, 'agent_2': -23413914.666271497, 'agent_3': -89985321.66760652} id_=526fedd2167a44a5a3347e22d910ffca)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 526fedd2167a44a5a3347e22d910ffca NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,832.00\n",
      "  agent_1 NAV: 986,835.00\n",
      "  agent_2 NAV: 999,322.00\n",
      "  agent_3 NAV: 1,009,011.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 575f10ebbc494198a7f3a91f60e7a006 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -53578613.95 | Std: 8606409.52 | Threshold: -52717973.00\n",
      "Policy Returns: {'policy_1': -65236205.69993243, 'policy_0': -41117071.12506499, 'policy_2': -55524687.27265258, 'policy_3': -52436491.720719144}\n",
      "Best Trainable: policy_0 (-41117071.13)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -1668476.1730901399, 'agent_1': -1327818.484560531, 'agent_2': -1459226.9874643872, 'agent_3': -2632244.760646374} id_=575f10ebbc494198a7f3a91f60e7a006)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 575f10ebbc494198a7f3a91f60e7a006 NAV Verification ====================\n",
      "  agent_0 NAV: 995,450.00\n",
      "  agent_1 NAV: 1,004,045.00\n",
      "  agent_2 NAV: 1,002,975.00\n",
      "  agent_3 NAV: 997,530.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 16725bcabf714f9aa062b6a1de149791 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -49348899.619196415, 'agent_1': -97854309.76961003, 'agent_2': -113862051.24552736, 'agent_3': -40576660.89933306} id_=16725bcabf714f9aa062b6a1de149791)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 16725bcabf714f9aa062b6a1de149791 NAV Verification ====================\n",
      "  agent_0 NAV: 1,014,487.00\n",
      "  agent_1 NAV: 1,032,286.00\n",
      "  agent_2 NAV: 969,215.00\n",
      "  agent_3 NAV: 984,012.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 5e7abebf8eab4e0990dc4467c48b2a08 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -31206898.748326026, 'agent_1': -25469972.481488984, 'agent_2': -61599915.0606768, 'agent_3': -19586477.801853724} id_=5e7abebf8eab4e0990dc4467c48b2a08)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5e7abebf8eab4e0990dc4467c48b2a08 NAV Verification ====================\n",
      "  agent_0 NAV: 991,731.00\n",
      "  agent_1 NAV: 994,354.00\n",
      "  agent_2 NAV: 1,013,434.00\n",
      "  agent_3 NAV: 1,000,481.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode ad0928e7ab8e4d2d929d5c0e62f220d4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -8345590.259396893, 'agent_1': -29721392.625923537, 'agent_2': -43805606.763343714, 'agent_3': -11907002.479914948} id_=ad0928e7ab8e4d2d929d5c0e62f220d4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ad0928e7ab8e4d2d929d5c0e62f220d4 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,699.00\n",
      "  agent_1 NAV: 1,042,849.00\n",
      "  agent_2 NAV: 944,407.00\n",
      "  agent_3 NAV: 1,009,045.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 817a2ef00f174844a3efa46e31b8d038 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -51444412.39 | Std: 8662534.63 | Threshold: -50578158.93\n",
      "Policy Returns: {'policy_1': -61921956.18744641, 'policy_0': -38997739.77750228, 'policy_2': -56522917.902874134, 'policy_3': -48335035.6968239}\n",
      "Best Trainable: policy_0 (-38997739.78)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_2 (from iteration 3, return=-47384658.37)\n",
      "‚úì Champion removed. Active champions: ['champion_3']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -38997739.78\n",
      "Iteration: 7\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_4 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -603368.8725395381, 'agent_1': -2324277.02006006, 'agent_2': -847004.2328722823, 'agent_3': -134088.88675542673} id_=817a2ef00f174844a3efa46e31b8d038)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 817a2ef00f174844a3efa46e31b8d038 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,023.00\n",
      "  agent_1 NAV: 986,024.00\n",
      "  agent_2 NAV: 1,008,566.00\n",
      "  agent_3 NAV: 1,002,387.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode e82e4921ef50479d8d08258f8f197689 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -16901048.163877673, 'agent_1': -129410546.62837341, 'agent_2': -120039480.8099311, 'agent_3': -19122751.629467722} id_=e82e4921ef50479d8d08258f8f197689)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e82e4921ef50479d8d08258f8f197689 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,706.00\n",
      "  agent_1 NAV: 1,046,553.00\n",
      "  agent_2 NAV: 958,701.00\n",
      "  agent_3 NAV: 990,040.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode ba410626dc7648f98856b0b97478c6ca Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -21746737.144536007, 'agent_1': -10736593.686858254, 'agent_2': -25285144.755887855, 'agent_3': -42892329.26409284} id_=ba410626dc7648f98856b0b97478c6ca)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ba410626dc7648f98856b0b97478c6ca NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,162.00\n",
      "  agent_1 NAV: 1,004,405.00\n",
      "  agent_2 NAV: 987,782.00\n",
      "  agent_3 NAV: 1,003,651.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 3671586b01314a42b688ebc65c206d40 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -19106313.190875545, 'agent_1': -139051815.0529625, 'agent_2': -36506204.35399046, 'agent_3': -61848397.435251355} id_=3671586b01314a42b688ebc65c206d40)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3671586b01314a42b688ebc65c206d40 NAV Verification ====================\n",
      "  agent_0 NAV: 997,825.00\n",
      "  agent_1 NAV: 1,017,114.00\n",
      "  agent_2 NAV: 984,512.00\n",
      "  agent_3 NAV: 1,000,549.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode a13637a2589e41e587a0c29f6c1522d5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -50496915.27 | Std: 10423596.03 | Threshold: -49454555.66\n",
      "Policy Returns: {'policy_1': -63989354.98981237, 'policy_0': -36088412.47159817, 'policy_2': -55673789.25701931, 'policy_3': -46236104.35186655}\n",
      "Best Trainable: policy_0 (-36088412.47)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -3223809.711068853, 'agent_1': -26450209.53692697, 'agent_2': -25474596.801697094, 'agent_3': -3380566.883074066} id_=a13637a2589e41e587a0c29f6c1522d5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a13637a2589e41e587a0c29f6c1522d5 NAV Verification ====================\n",
      "  agent_0 NAV: 1,010,399.00\n",
      "  agent_1 NAV: 929,082.00\n",
      "  agent_2 NAV: 1,037,207.00\n",
      "  agent_3 NAV: 1,023,312.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 29b49e88ce3848e6871fcdb909a6e14b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -44697587.258560084, 'agent_1': -77405927.04818103, 'agent_2': -80332967.05294612, 'agent_3': -60528342.58792274} id_=29b49e88ce3848e6871fcdb909a6e14b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 29b49e88ce3848e6871fcdb909a6e14b NAV Verification ====================\n",
      "  agent_0 NAV: 1,020,168.00\n",
      "  agent_1 NAV: 1,013,838.00\n",
      "  agent_2 NAV: 971,409.00\n",
      "  agent_3 NAV: 994,585.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 60b561b763f94643a248bd747d843fb6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -49933631.282134965, 'agent_1': -107619145.10559738, 'agent_2': -101895666.29341225, 'agent_3': -76312231.1982217} id_=60b561b763f94643a248bd747d843fb6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 60b561b763f94643a248bd747d843fb6 NAV Verification ====================\n",
      "  agent_0 NAV: 987,407.00\n",
      "  agent_1 NAV: 960,961.00\n",
      "  agent_2 NAV: 1,020,606.00\n",
      "  agent_3 NAV: 1,031,026.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode c0eb5c1102d94e7982e61eb59d37bb46 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -97256618.55615318, 'agent_1': -83725396.25658199, 'agent_2': -28174220.230825048, 'agent_3': -24427727.85739558} id_=c0eb5c1102d94e7982e61eb59d37bb46)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c0eb5c1102d94e7982e61eb59d37bb46 NAV Verification ====================\n",
      "  agent_0 NAV: 1,025,899.00\n",
      "  agent_1 NAV: 987,254.00\n",
      "  agent_2 NAV: 1,003,587.00\n",
      "  agent_3 NAV: 983,260.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 31738b1a1591497889760780fa564a8c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -53787137.69 | Std: 12384769.82 | Threshold: -52548660.70\n",
      "Policy Returns: {'policy_1': -70854532.48273358, 'policy_0': -38093507.259621456, 'policy_2': -59223999.403268315, 'policy_3': -46976511.6006689}\n",
      "Best Trainable: policy_0 (-38093507.26)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_3 (from iteration 5, return=-44441321.77)\n",
      "‚úì Champion removed. Active champions: ['champion_4']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -38093507.26\n",
      "Iteration: 9\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_5 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -356748.72712325695, 'agent_1': -9100344.767077561, 'agent_2': -514081.4329440604, 'agent_3': -3177937.818431576} id_=31738b1a1591497889760780fa564a8c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 31738b1a1591497889760780fa564a8c NAV Verification ====================\n",
      "  agent_0 NAV: 1,041,251.00\n",
      "  agent_1 NAV: 932,087.00\n",
      "  agent_2 NAV: 988,908.00\n",
      "  agent_3 NAV: 1,037,754.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 59d0d9d623fb472783907b4296949c01 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -8584877.817691792, 'agent_1': -108636148.40799004, 'agent_2': -74324318.32908392, 'agent_3': -84550134.14478423} id_=59d0d9d623fb472783907b4296949c01)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 59d0d9d623fb472783907b4296949c01 NAV Verification ====================\n",
      "  agent_0 NAV: 999,926.00\n",
      "  agent_1 NAV: 1,036,525.00\n",
      "  agent_2 NAV: 978,933.00\n",
      "  agent_3 NAV: 984,616.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode b0868e785687444b8ffcc0fc2c6056de Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -16398792.041676385, 'agent_1': -112481885.77830549, 'agent_2': -24691689.893149137, 'agent_3': -128467219.22968571} id_=b0868e785687444b8ffcc0fc2c6056de)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode b0868e785687444b8ffcc0fc2c6056de NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,728.00\n",
      "  agent_1 NAV: 956,839.00\n",
      "  agent_2 NAV: 1,000,672.00\n",
      "  agent_3 NAV: 1,041,761.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode fac7e3894c434c2c9368f5b07ec134a1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -14705224.395087222, 'agent_1': -79315239.19613376, 'agent_2': -50204099.70558788, 'agent_3': -38047824.99812395} id_=fac7e3894c434c2c9368f5b07ec134a1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fac7e3894c434c2c9368f5b07ec134a1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,071.00\n",
      "  agent_1 NAV: 1,000,234.00\n",
      "  agent_2 NAV: 1,001,933.00\n",
      "  agent_3 NAV: 996,762.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 1cf0b72990c44f428c47793c01f85682 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -54483608.55 | Std: 13768214.27 | Threshold: -53106787.13\n",
      "Policy Returns: {'policy_1': -74105000.66170037, 'policy_0': -35824274.698906474, 'policy_2': -57511307.85323213, 'policy_3': -50493850.99711697}\n",
      "Best Trainable: policy_0 (-35824274.70)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -2379747.885749271, 'agent_1': -6991850.421479405, 'agent_2': -5163622.265900454, 'agent_3': -1012199.3572926149} id_=1cf0b72990c44f428c47793c01f85682)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 1cf0b72990c44f428c47793c01f85682 NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,807.00\n",
      "  agent_1 NAV: 1,035,651.00\n",
      "  agent_2 NAV: 966,748.00\n",
      "  agent_3 NAV: 991,794.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode ee09190455934154ae6955a514a1ccea Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -25848445.259229194, 'agent_1': -109062520.01022752, 'agent_2': -11565035.685211891, 'agent_3': -98081682.86587735} id_=ee09190455934154ae6955a514a1ccea)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ee09190455934154ae6955a514a1ccea NAV Verification ====================\n",
      "  agent_0 NAV: 988,397.00\n",
      "  agent_1 NAV: 1,028,741.00\n",
      "  agent_2 NAV: 1,000,577.00\n",
      "  agent_3 NAV: 982,285.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 95ba55f2f90a4c9fac255a140decd118 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -8197217.492967406, 'agent_1': -64626754.511011854, 'agent_2': -42973631.50668083, 'agent_3': -20594647.40590213} id_=95ba55f2f90a4c9fac255a140decd118)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 95ba55f2f90a4c9fac255a140decd118 NAV Verification ====================\n",
      "  agent_0 NAV: 1,012,028.00\n",
      "  agent_1 NAV: 1,012,599.00\n",
      "  agent_2 NAV: 977,359.00\n",
      "  agent_3 NAV: 998,014.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 10b0f789dccc49119574bc1a4bb7f81a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -15610731.331055205, 'agent_1': -32186848.010056186, 'agent_2': -14250233.66658565, 'agent_3': -21589331.31124235} id_=10b0f789dccc49119574bc1a4bb7f81a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 10b0f789dccc49119574bc1a4bb7f81a NAV Verification ====================\n",
      "  agent_0 NAV: 997,236.00\n",
      "  agent_1 NAV: 995,987.00\n",
      "  agent_2 NAV: 1,005,669.00\n",
      "  agent_3 NAV: 1,001,108.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 5c1d95bd36fc44ef91b143220f460163 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -54049050.97 | Std: 14787966.48 | Threshold: -52570254.32\n",
      "Policy Returns: {'policy_1': -75498642.21517672, 'policy_0': -34369768.625417925, 'policy_2': -56756228.349532634, 'policy_3': -49571564.701402016}\n",
      "Best Trainable: policy_0 (-34369768.63)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_4 (from iteration 7, return=-38997739.78)\n",
      "‚úì Champion removed. Active champions: ['champion_5']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -34369768.63\n",
      "Iteration: 11\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_6 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -1911467.5462307092, 'agent_1': -566289.1721695283, 'agent_2': -3654206.239036284, 'agent_3': -968755.8952735659} id_=5c1d95bd36fc44ef91b143220f460163)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5c1d95bd36fc44ef91b143220f460163 NAV Verification ====================\n",
      "  agent_0 NAV: 1,030,918.00\n",
      "  agent_1 NAV: 972,573.00\n",
      "  agent_2 NAV: 982,137.00\n",
      "  agent_3 NAV: 1,014,372.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 449b95e4fc504567859a9d839259aba7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -55563369.32043791, 'agent_1': -88362442.90340742, 'agent_2': -47624976.4590695, 'agent_3': -126339092.93533815} id_=449b95e4fc504567859a9d839259aba7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 449b95e4fc504567859a9d839259aba7 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,567.00\n",
      "  agent_1 NAV: 1,009,737.00\n",
      "  agent_2 NAV: 988,727.00\n",
      "  agent_3 NAV: 996,969.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode bc7627ee85b4413f8c9ced2735af6ab7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -9891092.10538061, 'agent_1': -25274460.409687363, 'agent_2': -36817100.90426436, 'agent_3': -61799864.74083281} id_=bc7627ee85b4413f8c9ced2735af6ab7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bc7627ee85b4413f8c9ced2735af6ab7 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,205.00\n",
      "  agent_1 NAV: 995,892.00\n",
      "  agent_2 NAV: 1,006,103.00\n",
      "  agent_3 NAV: 996,800.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode ef175b91511a447e9071fe45ac657ca3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -25377716.86612214, 'agent_1': -83766135.87853472, 'agent_2': -16792798.752764218, 'agent_3': -20500991.621860657} id_=ef175b91511a447e9071fe45ac657ca3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ef175b91511a447e9071fe45ac657ca3 NAV Verification ====================\n",
      "  agent_0 NAV: 992,775.00\n",
      "  agent_1 NAV: 1,022,970.00\n",
      "  agent_2 NAV: 996,536.00\n",
      "  agent_3 NAV: 987,719.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode cb5e91be756b4a72b2fbd846670a586b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -53242397.41 | Std: 14200611.68 | Threshold: -51822336.24\n",
      "Policy Returns: {'policy_1': -73997759.66233173, 'policy_0': -34196476.13634122, 'policy_2': -54799752.251323454, 'policy_3': -49975601.57628947}\n",
      "Best Trainable: policy_0 (-34196476.14)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -2433738.1502520386, 'agent_1': -3878968.563631191, 'agent_2': -1712893.541337768, 'agent_3': -8546650.286292326} id_=cb5e91be756b4a72b2fbd846670a586b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode cb5e91be756b4a72b2fbd846670a586b NAV Verification ====================\n",
      "  agent_0 NAV: 997,329.00\n",
      "  agent_1 NAV: 988,402.00\n",
      "  agent_2 NAV: 1,003,115.00\n",
      "  agent_3 NAV: 1,011,154.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode c590d398ab7142c0b6294e261b96b23e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -10505503.242752329, 'agent_1': -91204614.14033332, 'agent_2': -88689730.81883126, 'agent_3': -12293207.290861234} id_=c590d398ab7142c0b6294e261b96b23e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c590d398ab7142c0b6294e261b96b23e NAV Verification ====================\n",
      "  agent_0 NAV: 997,866.00\n",
      "  agent_1 NAV: 983,835.00\n",
      "  agent_2 NAV: 1,012,875.00\n",
      "  agent_3 NAV: 1,005,424.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 044ced79f6c2435bac0b1a431a948a34 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -36578726.34871246, 'agent_1': -24867942.710334793, 'agent_2': -17203114.13426124, 'agent_3': -12889305.329674901} id_=044ced79f6c2435bac0b1a431a948a34)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 044ced79f6c2435bac0b1a431a948a34 NAV Verification ====================\n",
      "  agent_0 NAV: 999,746.00\n",
      "  agent_1 NAV: 1,015,513.00\n",
      "  agent_2 NAV: 1,003,440.00\n",
      "  agent_3 NAV: 981,301.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 8208c391a69f4fd7aa9f28860754d308 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -15551606.197764564, 'agent_1': -112071274.10077842, 'agent_2': -52757124.4973954, 'agent_3': -37784934.412870795} id_=8208c391a69f4fd7aa9f28860754d308)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8208c391a69f4fd7aa9f28860754d308 NAV Verification ====================\n",
      "  agent_0 NAV: 999,215.00\n",
      "  agent_1 NAV: 1,027,638.00\n",
      "  agent_2 NAV: 988,298.00\n",
      "  agent_3 NAV: 984,849.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode f7441ac707fe47509097d5019126518d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -52226829.14 | Std: 14331334.30 | Threshold: -50793695.71\n",
      "Policy Returns: {'policy_1': -73325470.21633145, 'policy_0': -33317691.06002124, 'policy_2': -53999432.77001995, 'policy_3': -48264722.49859572}\n",
      "Best Trainable: policy_0 (-33317691.06)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_5 (from iteration 9, return=-38093507.26)\n",
      "‚úì Champion removed. Active champions: ['champion_6']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -33317691.06\n",
      "Iteration: 13\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_7 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -1389097.2155509174, 'agent_1': -2560176.6804307727, 'agent_2': -1016949.3527455945, 'agent_3': -1354178.4166062465} id_=f7441ac707fe47509097d5019126518d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f7441ac707fe47509097d5019126518d NAV Verification ====================\n",
      "  agent_0 NAV: 993,561.00\n",
      "  agent_1 NAV: 1,011,478.00\n",
      "  agent_2 NAV: 996,078.00\n",
      "  agent_3 NAV: 998,883.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode a9f09c6d649148279b0717002e954150 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -110426130.13192275, 'agent_1': -95246744.11445111, 'agent_2': -76135640.73438211, 'agent_3': -49827220.162102975} id_=a9f09c6d649148279b0717002e954150)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a9f09c6d649148279b0717002e954150 NAV Verification ====================\n",
      "  agent_0 NAV: 951,144.00\n",
      "  agent_1 NAV: 1,042,165.00\n",
      "  agent_2 NAV: 1,030,732.00\n",
      "  agent_3 NAV: 975,959.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 34bb8c3bec7349f2817e2b71c2cf477e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -74912162.13071603, 'agent_1': -16591077.470429456, 'agent_2': -17012631.60272954, 'agent_3': -63177537.087815486} id_=34bb8c3bec7349f2817e2b71c2cf477e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 34bb8c3bec7349f2817e2b71c2cf477e NAV Verification ====================\n",
      "  agent_0 NAV: 1,049,045.00\n",
      "  agent_1 NAV: 998,840.00\n",
      "  agent_2 NAV: 988,745.00\n",
      "  agent_3 NAV: 963,370.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 6fdef2602bd34960a01c1180831de9a1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -29648226.749343988, 'agent_1': -73027241.9687836, 'agent_2': -36882642.57693802, 'agent_3': -31603290.10486477} id_=6fdef2602bd34960a01c1180831de9a1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6fdef2602bd34960a01c1180831de9a1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,233.00\n",
      "  agent_1 NAV: 1,004,453.00\n",
      "  agent_2 NAV: 990,504.00\n",
      "  agent_3 NAV: 1,001,810.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 6e70b3beaee94f3eb39d4a5d472d30c7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -52017840.64 | Std: 13200400.65 | Threshold: -50697800.58\n",
      "Policy Returns: {'policy_1': -71915549.99505742, 'policy_0': -35213758.246169746, 'policy_2': -53109305.28123679, 'policy_3': -47832749.04836793}\n",
      "Best Trainable: policy_0 (-35213758.25)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -2432475.0893358025, 'agent_1': -2226383.4920076905, 'agent_2': -1754550.645248651, 'agent_3': -2161746.925695817} id_=6e70b3beaee94f3eb39d4a5d472d30c7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6e70b3beaee94f3eb39d4a5d472d30c7 NAV Verification ====================\n",
      "  agent_0 NAV: 990,630.00\n",
      "  agent_1 NAV: 992,004.00\n",
      "  agent_2 NAV: 1,007,114.00\n",
      "  agent_3 NAV: 1,010,252.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode eac00b9ad6174787b7771e5c808d34c9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -36789236.946353234, 'agent_1': -75605492.02112485, 'agent_2': -86661868.53079106, 'agent_3': -28082488.520105343} id_=eac00b9ad6174787b7771e5c808d34c9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode eac00b9ad6174787b7771e5c808d34c9 NAV Verification ====================\n",
      "  agent_0 NAV: 998,194.00\n",
      "  agent_1 NAV: 1,002,718.00\n",
      "  agent_2 NAV: 1,001,673.00\n",
      "  agent_3 NAV: 997,415.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 0b76a10592ca4b5a9effaa959ee9bdad Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -33648434.49983865, 'agent_1': -155389027.6513994, 'agent_2': -92625234.8420879, 'agent_3': -13191050.857354457} id_=0b76a10592ca4b5a9effaa959ee9bdad)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 0b76a10592ca4b5a9effaa959ee9bdad NAV Verification ====================\n",
      "  agent_0 NAV: 1,041,039.00\n",
      "  agent_1 NAV: 876,055.00\n",
      "  agent_2 NAV: 1,073,821.00\n",
      "  agent_3 NAV: 1,009,085.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 3188e2e08a634523ac618bc8bf3862cb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -9863248.928824447, 'agent_1': -33455876.802831177, 'agent_2': -30350136.98865828, 'agent_3': -38145618.165749386} id_=3188e2e08a634523ac618bc8bf3862cb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3188e2e08a634523ac618bc8bf3862cb NAV Verification ====================\n",
      "  agent_0 NAV: 997,536.00\n",
      "  agent_1 NAV: 997,052.00\n",
      "  agent_2 NAV: 1,003,676.00\n",
      "  agent_3 NAV: 1,001,736.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 96f7672126d440768d76556fb63db4b0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -51359096.70 | Std: 13549418.94 | Threshold: -50004154.81\n",
      "Policy Returns: {'policy_1': -71732210.16297597, 'policy_0': -34360783.344753675, 'policy_2': -53182107.40234539, 'policy_3': -46161285.88996258}\n",
      "Best Trainable: policy_0 (-34360783.34)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_6 (from iteration 11, return=-34369768.63)\n",
      "‚úì Champion removed. Active champions: ['champion_7']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -34360783.34\n",
      "Iteration: 15\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_8 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_7', 'champion_8']\n",
      "\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -4999890.249833721, 'agent_1': -1148149.1275196096, 'agent_2': -1385823.2921410892, 'agent_3': -6054979.776961238} id_=96f7672126d440768d76556fb63db4b0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 96f7672126d440768d76556fb63db4b0 NAV Verification ====================\n",
      "  agent_0 NAV: 998,469.00\n",
      "  agent_1 NAV: 998,939.00\n",
      "  agent_2 NAV: 1,007,343.00\n",
      "  agent_3 NAV: 995,249.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode bf97a6b8b0334a28a90e2f8f8f03c814 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_8\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -37714144.5407281, 'agent_1': -179142660.56120697, 'agent_2': -72574034.57750985, 'agent_3': -130731890.89154035} id_=bf97a6b8b0334a28a90e2f8f8f03c814)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bf97a6b8b0334a28a90e2f8f8f03c814 NAV Verification ====================\n",
      "  agent_0 NAV: 975,136.00\n",
      "  agent_1 NAV: 883,271.00\n",
      "  agent_2 NAV: 1,046,636.00\n",
      "  agent_3 NAV: 1,094,957.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 43a1c0edaa91419ba936e778437379d5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> champion_8\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -15559873.287226554, 'agent_1': -53384518.66184926, 'agent_2': -21689051.95212225, 'agent_3': -10522146.216755776} id_=43a1c0edaa91419ba936e778437379d5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 43a1c0edaa91419ba936e778437379d5 NAV Verification ====================\n",
      "  agent_0 NAV: 1,012,471.00\n",
      "  agent_1 NAV: 970,679.00\n",
      "  agent_2 NAV: 1,013,077.00\n",
      "  agent_3 NAV: 1,003,773.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 676812b6238c4c98811439113c00ff8d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> champion_8\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -60440846.82163381, 'agent_1': -109261741.78881733, 'agent_2': -7863282.208616613, 'agent_3': -35971111.77546179} id_=676812b6238c4c98811439113c00ff8d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 676812b6238c4c98811439113c00ff8d NAV Verification ====================\n",
      "  agent_0 NAV: 1,051,907.00\n",
      "  agent_1 NAV: 927,372.00\n",
      "  agent_2 NAV: 998,413.00\n",
      "  agent_3 NAV: 1,022,308.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode b6d981422e2844c8996eb3fe4d826a6b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -51533529.03 | Std: 13843875.60 | Threshold: -50149141.47\n",
      "Policy Returns: {'policy_1': -72882996.2361061, 'policy_0': -34529062.93461271, 'policy_2': -51832913.538074605, 'policy_3': -46889143.40889755}\n",
      "Best Trainable: policy_0 (-34529062.93)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ‚Üê KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-24 04:51:17\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
