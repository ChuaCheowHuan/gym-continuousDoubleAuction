{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with naive competitive self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"❌ No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 15:53:18,931\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-23 15:53:20,111\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_1', 'agent_6', 'agent_2', 'agent_3', 'agent_5', 'agent_4', 'agent_7', 'agent_0']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 15:53:22,178\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.76gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-12-23 15:53:22,220\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"50aca72a-d199-4992-b66d-01dd22684f2f\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 8\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbac0>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbaf0>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fba90>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbc70>, 'policy_4': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbd30>, 'policy_5': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbdc0>, 'policy_6': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbe50>, 'policy_7': <ray.rllib.policy.policy.PolicySpec object at 0x7177584fbe80>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=2,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ← ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 15:53:22,625\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2025-12-23 15:53:22,627\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 4096\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-12-23 15:53:22,870\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-23 15:53:22,882\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2025-12-23 15:53:22,891\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-23 15:53:22,910\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2025-12-23 15:53:22,925\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2025-12-23 15:53:22,937\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2025-12-23 15:53:22,941\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-12-23 15:53:22,962\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,962\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,963\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,963\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,963\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,979\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,980\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2025-12-23 15:53:22,981\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32), 'agent_4': Box(-inf, inf, (40,), float32), 'agent_5': Box(-inf, inf, (40,), float32), 'agent_6': Box(-inf, inf, (40,), float32), 'agent_7': Box(-inf, inf, (40,), float32)), Dict('agent_0': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_1': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_2': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_3': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_4': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_5': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_6': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_7': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)))), 'policy_0': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_1': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_2': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_3': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_4': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_5': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_6': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_7': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)))}\n",
      "2025-12-23 15:53:23,017\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:23,018\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:23,027\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:23,036\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:23,045\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:23,055\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:23,064\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:24,074\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2025-12-23 15:53:24,106\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 4096\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode f4e93f4fc39f46278466e77d8b5390da Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -77514438.40807725, 'agent_1': -404907154.96478486, 'agent_2': -470012446.2070956, 'agent_3': -424202622.11566645, 'agent_4': -172862758.62358454, 'agent_5': -411836674.0446298, 'agent_6': -364609288.52005684, 'agent_7': -224505478.37792096} id_=f4e93f4fc39f46278466e77d8b5390da)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f4e93f4fc39f46278466e77d8b5390da NAV Verification ====================\n",
      "  agent_0 NAV: 1,028,021.00\n",
      "  agent_1 NAV: 1,019,886.00\n",
      "  agent_2 NAV: 913,336.00\n",
      "  agent_3 NAV: 1,084,172.00\n",
      "  agent_4 NAV: 978,004.00\n",
      "  agent_5 NAV: 1,094,565.00\n",
      "  agent_6 NAV: 923,976.00\n",
      "  agent_7 NAV: 958,040.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode dbd7153f7f414670af280ef5e1afb237 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -130699723.0599315, 'agent_1': -438919316.4137063, 'agent_2': -99966407.27882719, 'agent_3': -145344671.33588022, 'agent_4': -139451020.21352732, 'agent_5': -298900533.6403888, 'agent_6': -254039650.6634967, 'agent_7': -133537338.91695008} id_=dbd7153f7f414670af280ef5e1afb237)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode dbd7153f7f414670af280ef5e1afb237 NAV Verification ====================\n",
      "  agent_0 NAV: 1,015,192.00\n",
      "  agent_1 NAV: 1,072,429.00\n",
      "  agent_2 NAV: 946,013.00\n",
      "  agent_3 NAV: 1,039,699.00\n",
      "  agent_4 NAV: 953,081.00\n",
      "  agent_5 NAV: 974,946.00\n",
      "  agent_6 NAV: 994,167.00\n",
      "  agent_7 NAV: 1,004,473.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode a77b6f48630c4c9fadc7588818e3c738 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -154881177.60084578, 'agent_1': -479137245.90799814, 'agent_2': -277904910.74376935, 'agent_3': -142888668.368239, 'agent_4': -222701337.09926674, 'agent_5': -347543460.0388271, 'agent_6': -97592107.43782145, 'agent_7': -188862052.88394102} id_=a77b6f48630c4c9fadc7588818e3c738)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a77b6f48630c4c9fadc7588818e3c738 NAV Verification ====================\n",
      "  agent_0 NAV: 999,121.00\n",
      "  agent_1 NAV: 1,047,942.00\n",
      "  agent_2 NAV: 946,012.00\n",
      "  agent_3 NAV: 1,001,173.00\n",
      "  agent_4 NAV: 1,005,658.00\n",
      "  agent_5 NAV: 988,856.00\n",
      "  agent_6 NAV: 1,016,631.00\n",
      "  agent_7 NAV: 994,607.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode be8e25ef0ed34b1faf392fbefece95c1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -254284186.79 | Std: 96558573.83 | Threshold: -244628329.40\n",
      "Policy Returns: {'policy_3': -237478653.93992853, 'policy_1': -440987905.7621631, 'policy_2': -282627921.4098974, 'policy_6': -238747015.54045835, 'policy_0': -121031779.68961819, 'policy_4': -178338371.97879288, 'policy_5': -352760222.57461524, 'policy_7': -182301623.39293733}\n",
      "Best Trainable: policy_0 (-121031779.69)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -121031779.69\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_1 created successfully!\n",
      "✓ League size now: 3 (2 trainable + 1 champions)\n",
      "✓ Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': -7760690.915441177, 'agent_1': -11770849.969008528, 'agent_2': -4180871.3370729894, 'agent_3': -5678890.696969697, 'agent_4': -4432140.273743729, 'agent_5': -14109959.036144579, 'agent_6': -5545648.083067093, 'agent_7': -6159357.940298508} id_=be8e25ef0ed34b1faf392fbefece95c1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode be8e25ef0ed34b1faf392fbefece95c1 NAV Verification ====================\n",
      "  agent_0 NAV: 944,840.00\n",
      "  agent_1 NAV: 1,121,216.00\n",
      "  agent_2 NAV: 1,060,303.00\n",
      "  agent_3 NAV: 1,042,362.00\n",
      "  agent_4 NAV: 1,071,959.00\n",
      "  agent_5 NAV: 888,391.00\n",
      "  agent_6 NAV: 923,789.00\n",
      "  agent_7 NAV: 947,140.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 81a1a63d32d64324aabc1677be0d4d12 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -70047179.40155208, 'agent_1': -541481308.9764967, 'agent_2': -335684563.96931475, 'agent_3': -321273088.0919306, 'agent_4': -423626290.0700325, 'agent_5': -286521129.4685758, 'agent_6': -203930958.0901105, 'agent_7': -338703591.7791107} id_=81a1a63d32d64324aabc1677be0d4d12)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 81a1a63d32d64324aabc1677be0d4d12 NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,399.00\n",
      "  agent_1 NAV: 1,048,219.00\n",
      "  agent_2 NAV: 1,032,936.00\n",
      "  agent_3 NAV: 962,274.00\n",
      "  agent_4 NAV: 977,055.00\n",
      "  agent_5 NAV: 1,035,058.00\n",
      "  agent_6 NAV: 962,924.00\n",
      "  agent_7 NAV: 976,135.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 13a727795c5646e09d6342ed9bbe51f2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -148480107.43883735, 'agent_1': -643288419.8002152, 'agent_2': -444399825.4548127, 'agent_3': -366254668.64868075, 'agent_4': -109514370.43745756, 'agent_5': -192968781.73739657, 'agent_6': -231503306.1915041, 'agent_7': -273538293.1193554} id_=13a727795c5646e09d6342ed9bbe51f2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 13a727795c5646e09d6342ed9bbe51f2 NAV Verification ====================\n",
      "  agent_0 NAV: 978,639.00\n",
      "  agent_1 NAV: 1,124,362.00\n",
      "  agent_2 NAV: 1,135,647.00\n",
      "  agent_3 NAV: 942,334.00\n",
      "  agent_4 NAV: 914,273.00\n",
      "  agent_5 NAV: 1,042,690.00\n",
      "  agent_6 NAV: 911,674.00\n",
      "  agent_7 NAV: 950,381.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode ddc40ed49fdc4baba7cbcb15b6e4dd8a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -139722329.45450526, 'agent_1': -468452894.2625553, 'agent_2': -32439661.479217496, 'agent_3': -145836782.01539418, 'agent_4': -81103325.83439817, 'agent_5': -141410462.55068743, 'agent_6': -62485211.206764996, 'agent_7': -133236688.2778308} id_=ddc40ed49fdc4baba7cbcb15b6e4dd8a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ddc40ed49fdc4baba7cbcb15b6e4dd8a NAV Verification ====================\n",
      "  agent_0 NAV: 979,259.00\n",
      "  agent_1 NAV: 1,080,788.00\n",
      "  agent_2 NAV: 999,329.00\n",
      "  agent_3 NAV: 986,517.00\n",
      "  agent_4 NAV: 1,000,541.00\n",
      "  agent_5 NAV: 973,175.00\n",
      "  agent_6 NAV: 981,938.00\n",
      "  agent_7 NAV: 998,453.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode d3cd02213d194e2ba9aaaea122c0d9db Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -271718604.71 | Std: 109424222.25 | Threshold: -260776182.48\n",
      "Policy Returns: {'policy_3': -246116149.5351885, 'policy_1': -531814843.85006076, 'policy_2': -274876268.0651878, 'policy_6': -205170756.93017906, 'policy_0': -161949727.29972562, 'policy_4': -216073259.76423755, 'policy_5': -331656723.26984656, 'policy_7': -206091108.96147463}\n",
      "Best Trainable: policy_0 (-161949727.30)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -26887781.263219558, 'agent_1': -25322120.89901738, 'agent_2': -12911176.725032553, 'agent_3': -126109.76161111466, 'agent_4': -13624273.4430905, 'agent_5': -18312498.24949702, 'agent_6': -599672.7493112948, 'agent_7': -3667288.4029477197} id_=d3cd02213d194e2ba9aaaea122c0d9db)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode d3cd02213d194e2ba9aaaea122c0d9db NAV Verification ====================\n",
      "  agent_0 NAV: 956,998.00\n",
      "  agent_1 NAV: 1,080,864.00\n",
      "  agent_2 NAV: 985,652.00\n",
      "  agent_3 NAV: 1,009,000.00\n",
      "  agent_4 NAV: 1,010,282.00\n",
      "  agent_5 NAV: 965,945.00\n",
      "  agent_6 NAV: 1,019,162.00\n",
      "  agent_7 NAV: 972,097.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode fdadafa960c0477f96ac7c052441218a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -301010635.51547086, 'agent_1': -658319312.3540072, 'agent_2': -240667683.12640765, 'agent_3': -131045514.3209338, 'agent_4': -138194666.67800188, 'agent_5': -61428589.790873304, 'agent_6': -357326034.87155163, 'agent_7': -117336458.1876682} id_=fdadafa960c0477f96ac7c052441218a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode fdadafa960c0477f96ac7c052441218a NAV Verification ====================\n",
      "  agent_0 NAV: 962,627.00\n",
      "  agent_1 NAV: 921,714.00\n",
      "  agent_2 NAV: 1,049,617.00\n",
      "  agent_3 NAV: 1,014,552.00\n",
      "  agent_4 NAV: 976,713.00\n",
      "  agent_5 NAV: 1,000,567.00\n",
      "  agent_6 NAV: 1,036,604.00\n",
      "  agent_7 NAV: 1,037,606.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode bcd1b93fba424cdfac4bf645c3483741 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -91218310.8417432, 'agent_1': -448970797.0508783, 'agent_2': -174859375.6295555, 'agent_3': -648704558.1161935, 'agent_4': -255882779.64969757, 'agent_5': -120002665.82266867, 'agent_6': -100376549.04966433, 'agent_7': -311199310.0711463} id_=bcd1b93fba424cdfac4bf645c3483741)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode bcd1b93fba424cdfac4bf645c3483741 NAV Verification ====================\n",
      "  agent_0 NAV: 984,477.00\n",
      "  agent_1 NAV: 1,109,840.00\n",
      "  agent_2 NAV: 933,490.00\n",
      "  agent_3 NAV: 881,414.00\n",
      "  agent_4 NAV: 1,070,737.00\n",
      "  agent_5 NAV: 967,600.00\n",
      "  agent_6 NAV: 957,186.00\n",
      "  agent_7 NAV: 1,095,256.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 4a5e3fd1dad04371a4f49945942961d2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -172607961.59875667, 'agent_1': -644505972.1636598, 'agent_2': -412820097.653575, 'agent_3': -47442865.81227137, 'agent_4': -90786753.53408596, 'agent_5': -34712080.706806324, 'agent_6': -927801287.3087801, 'agent_7': -395011448.9541863} id_=4a5e3fd1dad04371a4f49945942961d2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4a5e3fd1dad04371a4f49945942961d2 NAV Verification ====================\n",
      "  agent_0 NAV: 954,219.00\n",
      "  agent_1 NAV: 1,155,145.00\n",
      "  agent_2 NAV: 900,448.00\n",
      "  agent_3 NAV: 1,040,109.00\n",
      "  agent_4 NAV: 983,879.00\n",
      "  agent_5 NAV: 993,899.00\n",
      "  agent_6 NAV: 880,376.00\n",
      "  agent_7 NAV: 1,091,925.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 154ba822a6c54679932cc16bb68d596a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -276411861.72 | Std: 108760839.54 | Threshold: -265535777.76\n",
      "Policy Returns: {'policy_3': -239506068.88786718, 'policy_1': -554286376.2025497, 'policy_2': -275264144.3244763, 'policy_6': -266941672.79079208, 'policy_0': -197237943.49472043, 'policy_4': -201251393.6457624, 'policy_5': -262457988.0314882, 'policy_7': -214349306.36434087}\n",
      "Best Trainable: policy_0 (-197237943.49)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_0\n",
      "Return: -197237943.49\n",
      "Iteration: 3\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_2 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -40325.84744920769, 'agent_1': -21247230.166524947, 'agent_2': -3513541.412759289, 'agent_3': -11050284.588489521, 'agent_4': -15810660.932301389, 'agent_5': -15520316.249849955, 'agent_6': -21549407.785193913, 'agent_7': -20739306.178117048} id_=154ba822a6c54679932cc16bb68d596a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 154ba822a6c54679932cc16bb68d596a NAV Verification ====================\n",
      "  agent_0 NAV: 979,976.00\n",
      "  agent_1 NAV: 990,571.00\n",
      "  agent_2 NAV: 998,967.00\n",
      "  agent_3 NAV: 1,022,703.00\n",
      "  agent_4 NAV: 1,031,527.00\n",
      "  agent_5 NAV: 1,023,349.00\n",
      "  agent_6 NAV: 972,265.00\n",
      "  agent_7 NAV: 980,642.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 9c42c5482d9747bf87205595980805d9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -100578557.4264862, 'agent_1': -1235682861.478261, 'agent_2': -853827952.8315773, 'agent_3': -282142432.7256259, 'agent_4': -1247702238.8437672, 'agent_5': -135954229.3481827, 'agent_6': -1550844931.232392, 'agent_7': -2218796281.4165926} id_=9c42c5482d9747bf87205595980805d9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9c42c5482d9747bf87205595980805d9 NAV Verification ====================\n",
      "  agent_0 NAV: 1,065,014.00\n",
      "  agent_1 NAV: 954,272.00\n",
      "  agent_2 NAV: 959,397.00\n",
      "  agent_3 NAV: 1,057,708.00\n",
      "  agent_4 NAV: 1,064,482.00\n",
      "  agent_5 NAV: 969,592.00\n",
      "  agent_6 NAV: 838,838.00\n",
      "  agent_7 NAV: 1,090,697.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode e13a22aea06e453093282d5154537c48 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -168433192.0878188, 'agent_1': -1696620431.6643894, 'agent_2': -338355806.5327089, 'agent_3': -886758245.6255157, 'agent_4': -414297340.43629783, 'agent_5': -589524578.9353147, 'agent_6': -456956110.5104269, 'agent_7': -548685435.5317541} id_=e13a22aea06e453093282d5154537c48)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e13a22aea06e453093282d5154537c48 NAV Verification ====================\n",
      "  agent_0 NAV: 994,004.00\n",
      "  agent_1 NAV: 873,766.00\n",
      "  agent_2 NAV: 971,519.00\n",
      "  agent_3 NAV: 1,084,544.00\n",
      "  agent_4 NAV: 1,045,713.00\n",
      "  agent_5 NAV: 1,039,874.00\n",
      "  agent_6 NAV: 956,482.00\n",
      "  agent_7 NAV: 1,034,098.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 9e86fe492b6e4cdc8ee6fbec441c66e6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -70531921.97149394, 'agent_1': -388413333.053472, 'agent_2': -333672181.57364374, 'agent_3': -227728120.57623416, 'agent_4': -121408531.6707294, 'agent_5': -149465369.21116573, 'agent_6': -248181132.4930192, 'agent_7': -153787800.12302357} id_=9e86fe492b6e4cdc8ee6fbec441c66e6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9e86fe492b6e4cdc8ee6fbec441c66e6 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,124.00\n",
      "  agent_1 NAV: 1,115,419.00\n",
      "  agent_2 NAV: 886,309.00\n",
      "  agent_3 NAV: 1,065,296.00\n",
      "  agent_4 NAV: 962,667.00\n",
      "  agent_5 NAV: 1,066,099.00\n",
      "  agent_6 NAV: 955,987.00\n",
      "  agent_7 NAV: 945,099.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 59c088eb2d924c49859350da92021a59 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -343519020.78 | Std: 133771381.35 | Threshold: -330141882.64\n",
      "Policy Returns: {'policy_3': -282106543.27423733, 'policy_1': -659361541.3331985, 'policy_2': -308981644.4550268, 'policy_6': -366540617.37849945, 'policy_0': -170320487.05647916, 'policy_4': -295237705.1990005, 'policy_5': -281086677.1116674, 'policy_7': -384516950.39989686}\n",
      "Best Trainable: policy_0 (-170320487.06)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -553965.0321258239, 'agent_1': -11796218.404592056, 'agent_2': -8692322.841030415, 'agent_3': -6352635.629527394, 'agent_4': -10145280.004178109, 'agent_5': -25936296.293851152, 'agent_6': -19957464.0026459, 'agent_7': -10051292.607792255} id_=59c088eb2d924c49859350da92021a59)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 59c088eb2d924c49859350da92021a59 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,032.00\n",
      "  agent_1 NAV: 1,022,445.00\n",
      "  agent_2 NAV: 976,843.00\n",
      "  agent_3 NAV: 995,505.00\n",
      "  agent_4 NAV: 1,021,862.00\n",
      "  agent_5 NAV: 982,556.00\n",
      "  agent_6 NAV: 1,002,403.00\n",
      "  agent_7 NAV: 995,354.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode bf807bff87d84db8bc08bf08e29fee20 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -349029396.8172874, 'agent_1': -244935108.00865245, 'agent_2': -271632207.5990257, 'agent_3': -205082564.16603786, 'agent_4': -144334592.73115882, 'agent_5': -274021142.5353249, 'agent_6': -123927297.88728398, 'agent_7': -348859038.41169953} id_=bf807bff87d84db8bc08bf08e29fee20)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode bf807bff87d84db8bc08bf08e29fee20 NAV Verification ====================\n",
      "  agent_0 NAV: 1,117,784.00\n",
      "  agent_1 NAV: 1,037,034.00\n",
      "  agent_2 NAV: 1,053,211.00\n",
      "  agent_3 NAV: 969,504.00\n",
      "  agent_4 NAV: 977,785.00\n",
      "  agent_5 NAV: 936,424.00\n",
      "  agent_6 NAV: 1,006,550.00\n",
      "  agent_7 NAV: 901,708.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode d6cb62b87b984e6b83be74e35046282a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -355920364.8227765, 'agent_1': -569485904.1817783, 'agent_2': -283643064.49722266, 'agent_3': -87445235.47249863, 'agent_4': -58475557.206222095, 'agent_5': -173561565.96665016, 'agent_6': -82851215.58902551, 'agent_7': -123179218.90528218} id_=d6cb62b87b984e6b83be74e35046282a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode d6cb62b87b984e6b83be74e35046282a NAV Verification ====================\n",
      "  agent_0 NAV: 943,928.00\n",
      "  agent_1 NAV: 1,009,344.00\n",
      "  agent_2 NAV: 1,008,456.00\n",
      "  agent_3 NAV: 1,010,996.00\n",
      "  agent_4 NAV: 995,119.00\n",
      "  agent_5 NAV: 1,041,555.00\n",
      "  agent_6 NAV: 1,030,381.00\n",
      "  agent_7 NAV: 960,221.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode a76a0219e94c423da96b36a1b37a14fe Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -156335170.36419353, 'agent_1': -166921353.3529484, 'agent_2': -454395003.8219775, 'agent_3': -97674490.05733377, 'agent_4': -81674171.690818, 'agent_5': -508925968.6929078, 'agent_6': -336733618.38951164, 'agent_7': -111349611.63544439} id_=a76a0219e94c423da96b36a1b37a14fe)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a76a0219e94c423da96b36a1b37a14fe NAV Verification ====================\n",
      "  agent_0 NAV: 982,376.00\n",
      "  agent_1 NAV: 1,003,144.00\n",
      "  agent_2 NAV: 1,028,759.00\n",
      "  agent_3 NAV: 1,011,406.00\n",
      "  agent_4 NAV: 992,077.00\n",
      "  agent_5 NAV: 999,351.00\n",
      "  agent_6 NAV: 1,022,289.00\n",
      "  agent_7 NAV: 960,598.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode ecfa58e473d4487cbbfe2446fff22d6b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -320115558.00 | Std: 111592527.36 | Threshold: -308956305.26\n",
      "Policy Returns: {'policy_3': -255194660.12769002, 'policy_1': -585404468.4750721, 'policy_2': -305429882.6802535, 'policy_6': -341518577.9745428, 'policy_0': -181948600.60250986, 'policy_4': -258473236.4837116, 'policy_5': -289643814.2091772, 'policy_7': -343311223.41019946}\n",
      "Best Trainable: policy_0 (-181948600.60)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "⚠️  Removing oldest champion: champion_1 (from iteration 1, return=-121031779.69)\n",
      "✓ Champion removed. Active champions: ['champion_2']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -181948600.60\n",
      "Iteration: 5\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_3 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -485225.7758522607, 'agent_1': -32250004.435966298, 'agent_2': -2507734.1377326287, 'agent_3': -2759391.410945496, 'agent_4': -5452098.543001766, 'agent_5': -11277252.682575734, 'agent_6': -8547706.425947163, 'agent_7': -2933483.4651253154} id_=ecfa58e473d4487cbbfe2446fff22d6b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ecfa58e473d4487cbbfe2446fff22d6b NAV Verification ====================\n",
      "  agent_0 NAV: 999,344.00\n",
      "  agent_1 NAV: 1,051,821.00\n",
      "  agent_2 NAV: 1,000,141.00\n",
      "  agent_3 NAV: 988,136.00\n",
      "  agent_4 NAV: 989,525.00\n",
      "  agent_5 NAV: 1,002,044.00\n",
      "  agent_6 NAV: 962,639.00\n",
      "  agent_7 NAV: 1,006,350.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode db24fab5a08a4018bebcdb2f6485dae5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -134340979.43789086, 'agent_1': -538467248.1924624, 'agent_2': -263647327.7802687, 'agent_3': -377292173.6119529, 'agent_4': -201597410.98690835, 'agent_5': -183799624.99460363, 'agent_6': -103084852.4312874, 'agent_7': -92636694.67701246} id_=db24fab5a08a4018bebcdb2f6485dae5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode db24fab5a08a4018bebcdb2f6485dae5 NAV Verification ====================\n",
      "  agent_0 NAV: 951,310.00\n",
      "  agent_1 NAV: 1,018,657.00\n",
      "  agent_2 NAV: 991,621.00\n",
      "  agent_3 NAV: 907,257.00\n",
      "  agent_4 NAV: 1,140,115.00\n",
      "  agent_5 NAV: 965,156.00\n",
      "  agent_6 NAV: 1,025,934.00\n",
      "  agent_7 NAV: 999,950.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 5e7e8432198f46f6b9c44dd830c7e107 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -151416248.7157101, 'agent_1': -707633050.0587162, 'agent_2': -326940047.03333986, 'agent_3': -63210863.797548234, 'agent_4': -61644476.39686318, 'agent_5': -209307289.99168694, 'agent_6': -384492981.5149639, 'agent_7': -235199318.80868497} id_=5e7e8432198f46f6b9c44dd830c7e107)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 5e7e8432198f46f6b9c44dd830c7e107 NAV Verification ====================\n",
      "  agent_0 NAV: 984,319.00\n",
      "  agent_1 NAV: 1,058,287.00\n",
      "  agent_2 NAV: 964,435.00\n",
      "  agent_3 NAV: 990,219.00\n",
      "  agent_4 NAV: 1,003,180.00\n",
      "  agent_5 NAV: 993,533.00\n",
      "  agent_6 NAV: 979,336.00\n",
      "  agent_7 NAV: 1,026,691.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 1deedfddb1774f79bc8496b99e9c02be Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -180821649.0595063, 'agent_1': -344911287.30850947, 'agent_2': -64398228.7712653, 'agent_3': -201200196.7850671, 'agent_4': -232992374.18071714, 'agent_5': -236931846.2046119, 'agent_6': -84143680.44011259, 'agent_7': -132386982.0622927} id_=1deedfddb1774f79bc8496b99e9c02be)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 1deedfddb1774f79bc8496b99e9c02be NAV Verification ====================\n",
      "  agent_0 NAV: 992,801.00\n",
      "  agent_1 NAV: 1,033,957.00\n",
      "  agent_2 NAV: 989,320.00\n",
      "  agent_3 NAV: 985,606.00\n",
      "  agent_4 NAV: 991,934.00\n",
      "  agent_5 NAV: 1,011,930.00\n",
      "  agent_6 NAV: 1,009,261.00\n",
      "  agent_7 NAV: 985,191.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 4a8cdcc9e50a438b8b7dac1c9478f5b3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -304049602.29 | Std: 113565417.60 | Threshold: -292693060.53\n",
      "Policy Returns: {'policy_3': -243740066.1940966, 'policy_1': -582312517.031655, 'policy_2': -285989996.7097228, 'policy_6': -320420991.55284697, 'policy_0': -173102377.92583808, 'policy_4': -243882173.47769222, 'policy_5': -276784183.0569385, 'policy_7': -306164512.33725995}\n",
      "Best Trainable: policy_0 (-173102377.93)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -186896.53448625357, 'agent_1': -42137622.29963433, 'agent_2': -11217955.925107593, 'agent_3': -11504106.819215072, 'agent_4': -13470505.909887752, 'agent_5': -14008637.347732052, 'agent_6': -933576.7333106089, 'agent_7': -912265.8650711479} id_=4a8cdcc9e50a438b8b7dac1c9478f5b3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4a8cdcc9e50a438b8b7dac1c9478f5b3 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,409.00\n",
      "  agent_1 NAV: 1,067,488.00\n",
      "  agent_2 NAV: 959,761.00\n",
      "  agent_3 NAV: 975,587.00\n",
      "  agent_4 NAV: 971,948.00\n",
      "  agent_5 NAV: 1,005,551.00\n",
      "  agent_6 NAV: 1,007,914.00\n",
      "  agent_7 NAV: 1,011,342.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 037f6e95b0e44e499928b31718164656 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -387423891.44295603, 'agent_1': -1431196016.64718, 'agent_2': -317937878.34059143, 'agent_3': -624351313.9438113, 'agent_4': -105836626.51344664, 'agent_5': -358455010.94273394, 'agent_6': -684063996.6898304, 'agent_7': -413523180.778366} id_=037f6e95b0e44e499928b31718164656)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 037f6e95b0e44e499928b31718164656 NAV Verification ====================\n",
      "  agent_0 NAV: 929,265.00\n",
      "  agent_1 NAV: 1,174,712.00\n",
      "  agent_2 NAV: 961,739.00\n",
      "  agent_3 NAV: 911,399.00\n",
      "  agent_4 NAV: 1,002,324.00\n",
      "  agent_5 NAV: 979,637.00\n",
      "  agent_6 NAV: 1,084,204.00\n",
      "  agent_7 NAV: 956,720.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode d3dd1856f6f945fabca2ccc2c238b39b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -90240268.61718024, 'agent_1': -134171508.87951222, 'agent_2': -182513732.78518996, 'agent_3': -157910842.95885256, 'agent_4': -466228435.1343696, 'agent_5': -151296899.12047628, 'agent_6': -159510493.4414295, 'agent_7': -281326648.62544125} id_=d3dd1856f6f945fabca2ccc2c238b39b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode d3dd1856f6f945fabca2ccc2c238b39b NAV Verification ====================\n",
      "  agent_0 NAV: 1,018,066.00\n",
      "  agent_1 NAV: 1,001,931.00\n",
      "  agent_2 NAV: 978,283.00\n",
      "  agent_3 NAV: 995,034.00\n",
      "  agent_4 NAV: 982,705.00\n",
      "  agent_5 NAV: 1,002,644.00\n",
      "  agent_6 NAV: 991,680.00\n",
      "  agent_7 NAV: 1,029,657.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode a3eb4f9ed7364be1836ebc476975493e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -697863625.9276597, 'agent_1': -710164572.8381505, 'agent_2': -159561228.6951489, 'agent_3': -261866945.1767982, 'agent_4': -184165640.61088797, 'agent_5': -74180967.23340839, 'agent_6': -493813006.0251571, 'agent_7': -137017391.65975145} id_=a3eb4f9ed7364be1836ebc476975493e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a3eb4f9ed7364be1836ebc476975493e NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,848.00\n",
      "  agent_1 NAV: 1,048,489.00\n",
      "  agent_2 NAV: 951,280.00\n",
      "  agent_3 NAV: 1,011,389.00\n",
      "  agent_4 NAV: 1,075,261.00\n",
      "  agent_5 NAV: 963,915.00\n",
      "  agent_6 NAV: 939,002.00\n",
      "  agent_7 NAV: 1,009,816.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode ad8402375fd7445d83a16a1a31d351d1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -307910078.04 | Std: 118004308.25 | Threshold: -296109647.21\n",
      "Policy Returns: {'policy_3': -255833520.27426705, 'policy_1': -605346239.6157495, 'policy_2': -278480496.48964715, 'policy_6': -325144440.1606251, 'policy_0': -192609068.77479747, 'policy_4': -247937724.5268894, 'policy_5': -263310791.16711113, 'policy_7': -294618343.2873433}\n",
      "Best Trainable: policy_0 (-192609068.77)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "⚠️  Removing oldest champion: champion_2 (from iteration 3, return=-197237943.49)\n",
      "✓ Champion removed. Active champions: ['champion_3']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -192609068.77\n",
      "Iteration: 7\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_4 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -2895138.6826188737, 'agent_1': -20416744.253656246, 'agent_2': -12257256.055120995, 'agent_3': -23495603.307109587, 'agent_4': -1898601.3244096213, 'agent_5': -18203996.765499648, 'agent_6': -9969790.661275126, 'agent_7': -20676406.451589383} id_=ad8402375fd7445d83a16a1a31d351d1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ad8402375fd7445d83a16a1a31d351d1 NAV Verification ====================\n",
      "  agent_0 NAV: 949,107.00\n",
      "  agent_1 NAV: 1,100,899.00\n",
      "  agent_2 NAV: 1,117,409.00\n",
      "  agent_3 NAV: 910,396.00\n",
      "  agent_4 NAV: 987,885.00\n",
      "  agent_5 NAV: 960,162.00\n",
      "  agent_6 NAV: 1,047,863.00\n",
      "  agent_7 NAV: 926,279.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 3dd249fa91164ae4bc6f137b5226cd21 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -344908305.58252543, 'agent_1': -618938183.4209219, 'agent_2': -179383704.3570035, 'agent_3': -430990088.2507723, 'agent_4': -126108790.81463571, 'agent_5': -151919209.1605518, 'agent_6': -145341189.00404355, 'agent_7': -187527726.28249615} id_=3dd249fa91164ae4bc6f137b5226cd21)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3dd249fa91164ae4bc6f137b5226cd21 NAV Verification ====================\n",
      "  agent_0 NAV: 966,475.00\n",
      "  agent_1 NAV: 1,084,445.00\n",
      "  agent_2 NAV: 1,003,249.00\n",
      "  agent_3 NAV: 956,969.00\n",
      "  agent_4 NAV: 1,008,931.00\n",
      "  agent_5 NAV: 993,760.00\n",
      "  agent_6 NAV: 1,011,660.00\n",
      "  agent_7 NAV: 974,511.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 00c41cae7f0240cdac169d8ed0edce90 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -271794799.14965, 'agent_1': -316499272.71868104, 'agent_2': -541386213.232234, 'agent_3': -305269400.0417116, 'agent_4': -67764902.66510363, 'agent_5': -74478876.3164701, 'agent_6': -158864054.07450718, 'agent_7': -233473578.7273454} id_=00c41cae7f0240cdac169d8ed0edce90)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 00c41cae7f0240cdac169d8ed0edce90 NAV Verification ====================\n",
      "  agent_0 NAV: 964,829.00\n",
      "  agent_1 NAV: 1,057,769.00\n",
      "  agent_2 NAV: 899,607.00\n",
      "  agent_3 NAV: 1,072,319.00\n",
      "  agent_4 NAV: 1,011,432.00\n",
      "  agent_5 NAV: 1,001,447.00\n",
      "  agent_6 NAV: 964,081.00\n",
      "  agent_7 NAV: 1,028,516.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 2400255a7ed240369973c073f3faa543 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -167058563.60934797, 'agent_1': -668938993.3469661, 'agent_2': -244332137.70108467, 'agent_3': -88360421.3574668, 'agent_4': -313128450.2733017, 'agent_5': -461692586.33306605, 'agent_6': -91464852.95513979, 'agent_7': -349818755.7005959} id_=2400255a7ed240369973c073f3faa543)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 2400255a7ed240369973c073f3faa543 NAV Verification ====================\n",
      "  agent_0 NAV: 939,473.00\n",
      "  agent_1 NAV: 1,085,871.00\n",
      "  agent_2 NAV: 1,010,091.00\n",
      "  agent_3 NAV: 1,040,383.00\n",
      "  agent_4 NAV: 922,276.00\n",
      "  agent_5 NAV: 930,266.00\n",
      "  agent_6 NAV: 1,022,145.00\n",
      "  agent_7 NAV: 1,049,495.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 21cdc663a40943dea31ecaae16037a2d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -301724625.43 | Std: 112993925.07 | Threshold: -290425232.92\n",
      "Policy Returns: {'policy_3': -260677093.86415735, 'policy_1': -588692243.0653911, 'policy_2': -285139719.16368526, 'policy_6': -300260732.00810736, 'policy_0': -195564331.68063915, 'policy_4': -234747616.31306732, 'policy_5': -257406688.06217393, 'policy_7': -291308579.24803174}\n",
      "Best Trainable: policy_0 (-195564331.68)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -11741345.585356642, 'agent_1': -20647534.416902915, 'agent_2': -44853685.82808343, 'agent_3': -765308.8352172077, 'agent_4': -18289338.556140468, 'agent_5': -11443208.719826551, 'agent_6': -19907014.490109205, 'agent_7': -39499597.9109051} id_=21cdc663a40943dea31ecaae16037a2d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 21cdc663a40943dea31ecaae16037a2d NAV Verification ====================\n",
      "  agent_0 NAV: 986,368.00\n",
      "  agent_1 NAV: 991,641.00\n",
      "  agent_2 NAV: 1,031,740.00\n",
      "  agent_3 NAV: 964,741.00\n",
      "  agent_4 NAV: 1,009,579.00\n",
      "  agent_5 NAV: 1,001,451.00\n",
      "  agent_6 NAV: 982,048.00\n",
      "  agent_7 NAV: 1,032,432.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 1f9feea5b0004200beb02345c049089c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -314291432.7303682, 'agent_1': -678447062.982285, 'agent_2': -153034553.60539848, 'agent_3': -37911799.490587786, 'agent_4': -113547511.01974706, 'agent_5': -396334936.17637354, 'agent_6': -63941392.916323476, 'agent_7': -122706983.01482694} id_=1f9feea5b0004200beb02345c049089c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 1f9feea5b0004200beb02345c049089c NAV Verification ====================\n",
      "  agent_0 NAV: 951,300.00\n",
      "  agent_1 NAV: 1,076,821.00\n",
      "  agent_2 NAV: 987,584.00\n",
      "  agent_3 NAV: 1,002,486.00\n",
      "  agent_4 NAV: 1,043,862.00\n",
      "  agent_5 NAV: 944,719.00\n",
      "  agent_6 NAV: 989,499.00\n",
      "  agent_7 NAV: 1,003,729.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 3c67817506ac4f019bca3fbaec005c6d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -307763488.6712751, 'agent_1': -816513543.3793905, 'agent_2': -411572808.7634337, 'agent_3': -330714979.09561247, 'agent_4': -144363550.6853007, 'agent_5': -168891975.58293816, 'agent_6': -297725208.2851493, 'agent_7': -92902683.7683478} id_=3c67817506ac4f019bca3fbaec005c6d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3c67817506ac4f019bca3fbaec005c6d NAV Verification ====================\n",
      "  agent_0 NAV: 935,791.00\n",
      "  agent_1 NAV: 1,115,477.00\n",
      "  agent_2 NAV: 959,610.00\n",
      "  agent_3 NAV: 1,052,959.00\n",
      "  agent_4 NAV: 1,020,023.00\n",
      "  agent_5 NAV: 992,171.00\n",
      "  agent_6 NAV: 933,695.00\n",
      "  agent_7 NAV: 990,274.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode a517e63d29a7472095d96f7b345d40f5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -220958804.09826586, 'agent_1': -841171771.4061284, 'agent_2': -139506233.43203905, 'agent_3': -180941068.3430431, 'agent_4': -74186916.94056666, 'agent_5': -245619874.78425205, 'agent_6': -179273605.5532943, 'agent_7': -156178884.12163177} id_=a517e63d29a7472095d96f7b345d40f5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a517e63d29a7472095d96f7b345d40f5 NAV Verification ====================\n",
      "  agent_0 NAV: 972,942.00\n",
      "  agent_1 NAV: 1,041,837.00\n",
      "  agent_2 NAV: 991,610.00\n",
      "  agent_3 NAV: 964,683.00\n",
      "  agent_4 NAV: 1,005,689.00\n",
      "  agent_5 NAV: 1,020,225.00\n",
      "  agent_6 NAV: 1,009,733.00\n",
      "  agent_7 NAV: 993,281.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode abb9c3a78d7b42bd92284e6f38afc2cb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -297065939.26 | Std: 115540877.34 | Threshold: -285511851.52\n",
      "Policy Returns: {'policy_3': -248002819.89046815, 'policy_1': -593190170.0395625, 'policy_2': -282474918.2912842, 'policy_6': -287504455.5446364, 'policy_0': -201910525.99583495, 'policy_4': -223714819.96644008, 'policy_5': -254344707.72833017, 'policy_7': -285385096.6015805}\n",
      "Best Trainable: policy_0 (-201910526.00)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "⚠️  Removing oldest champion: champion_3 (from iteration 5, return=-181948600.60)\n",
      "✓ Champion removed. Active champions: ['champion_4']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -201910526.00\n",
      "Iteration: 9\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_5 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -45677830.755336374, 'agent_1': -80624750.3014734, 'agent_2': -11196779.830770107, 'agent_3': -19060790.659700558, 'agent_4': -6098819.979546254, 'agent_5': -34815891.520076096, 'agent_6': -21443650.680650633, 'agent_7': -9502124.567850377} id_=abb9c3a78d7b42bd92284e6f38afc2cb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode abb9c3a78d7b42bd92284e6f38afc2cb NAV Verification ====================\n",
      "  agent_0 NAV: 989,981.00\n",
      "  agent_1 NAV: 1,006,444.00\n",
      "  agent_2 NAV: 1,005,240.00\n",
      "  agent_3 NAV: 993,519.00\n",
      "  agent_4 NAV: 1,006,048.00\n",
      "  agent_5 NAV: 1,000,731.00\n",
      "  agent_6 NAV: 979,084.00\n",
      "  agent_7 NAV: 1,018,953.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 1761ed0e7c6149dbb4eaf22ca1baa957 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -474529318.20198417, 'agent_1': -379278645.6201689, 'agent_2': -139592652.21959478, 'agent_3': -568246534.2377843, 'agent_4': -182921480.47227335, 'agent_5': -264251396.764446, 'agent_6': -173177985.45668614, 'agent_7': -220327810.72089937} id_=1761ed0e7c6149dbb4eaf22ca1baa957)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 1761ed0e7c6149dbb4eaf22ca1baa957 NAV Verification ====================\n",
      "  agent_0 NAV: 869,990.00\n",
      "  agent_1 NAV: 1,116,375.00\n",
      "  agent_2 NAV: 947,407.00\n",
      "  agent_3 NAV: 1,143,347.00\n",
      "  agent_4 NAV: 928,523.00\n",
      "  agent_5 NAV: 933,778.00\n",
      "  agent_6 NAV: 987,458.00\n",
      "  agent_7 NAV: 1,073,122.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 4f5ac39d394b404aac337e2e5b6d44cf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -78512987.65558329, 'agent_1': -478314388.7035925, 'agent_2': -147866059.85193866, 'agent_3': -420542747.03422266, 'agent_4': -91621755.7918533, 'agent_5': -142026483.54043794, 'agent_6': -76110904.48938255, 'agent_7': -183342543.03065687} id_=4f5ac39d394b404aac337e2e5b6d44cf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4f5ac39d394b404aac337e2e5b6d44cf NAV Verification ====================\n",
      "  agent_0 NAV: 1,014,289.00\n",
      "  agent_1 NAV: 936,235.00\n",
      "  agent_2 NAV: 1,015,682.00\n",
      "  agent_3 NAV: 1,021,907.00\n",
      "  agent_4 NAV: 1,009,529.00\n",
      "  agent_5 NAV: 1,003,431.00\n",
      "  agent_6 NAV: 979,969.00\n",
      "  agent_7 NAV: 1,018,958.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 6574202328f6476e85de83ffebc3cd8d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -327895489.6654253, 'agent_1': -462347700.5607634, 'agent_2': -91963660.88823187, 'agent_3': -200117489.45288986, 'agent_4': -94707985.07278727, 'agent_5': -555919055.1211039, 'agent_6': -359024016.6686403, 'agent_7': -301378429.8913459} id_=6574202328f6476e85de83ffebc3cd8d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6574202328f6476e85de83ffebc3cd8d NAV Verification ====================\n",
      "  agent_0 NAV: 980,386.00\n",
      "  agent_1 NAV: 1,025,207.00\n",
      "  agent_2 NAV: 982,618.00\n",
      "  agent_3 NAV: 1,013,312.00\n",
      "  agent_4 NAV: 999,283.00\n",
      "  agent_5 NAV: 1,032,359.00\n",
      "  agent_6 NAV: 998,047.00\n",
      "  agent_7 NAV: 968,788.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 55b3de83129d44ecb01f035a7dd3e2c5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -293512059.70 | Std: 112474714.65 | Threshold: -282264588.23\n",
      "Policy Returns: {'policy_3': -256172189.6886811, 'policy_1': -583960961.9918046, 'policy_2': -268183185.9915673, 'policy_6': -278802080.44072217, 'policy_0': -213284326.86958987, 'policy_4': -211341666.40275684, 'policy_5': -260448346.79113036, 'policy_7': -275903719.4128702}\n",
      "Best Trainable: policy_0 (-213284326.87)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -61895928.23662139, 'agent_1': -114588937.21178916, 'agent_2': -31864602.40459674, 'agent_3': -39792912.81180939, 'agent_4': -32462491.985769372, 'agent_5': -125435406.75609921, 'agent_6': -51574460.48024625, 'agent_7': -22712800.04164309} id_=55b3de83129d44ecb01f035a7dd3e2c5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 55b3de83129d44ecb01f035a7dd3e2c5 NAV Verification ====================\n",
      "  agent_0 NAV: 988,383.00\n",
      "  agent_1 NAV: 1,017,184.00\n",
      "  agent_2 NAV: 992,794.00\n",
      "  agent_3 NAV: 1,014,753.00\n",
      "  agent_4 NAV: 1,020,139.00\n",
      "  agent_5 NAV: 1,004,022.00\n",
      "  agent_6 NAV: 1,006,328.00\n",
      "  agent_7 NAV: 956,397.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 9539ce2e83414395847dfa711bde5119 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_4\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -28379489.787492637, 'agent_1': -829098723.5000631, 'agent_2': -202509292.14335033, 'agent_3': -75723840.22128065, 'agent_4': -265524982.4769801, 'agent_5': -214092394.1687875, 'agent_6': -317482924.32067615, 'agent_7': -149149271.3788712} id_=9539ce2e83414395847dfa711bde5119)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9539ce2e83414395847dfa711bde5119 NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,874.00\n",
      "  agent_1 NAV: 954,789.00\n",
      "  agent_2 NAV: 1,009,575.00\n",
      "  agent_3 NAV: 973,744.00\n",
      "  agent_4 NAV: 999,951.00\n",
      "  agent_5 NAV: 1,000,575.00\n",
      "  agent_6 NAV: 1,039,646.00\n",
      "  agent_7 NAV: 1,014,846.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 4b57acd8b94a43cc9844d2351890b634 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -81688587.2299079, 'agent_1': -251473969.80699465, 'agent_2': -309305421.7800518, 'agent_3': -39663605.43193805, 'agent_4': -127985254.98282275, 'agent_5': -231240987.67910355, 'agent_6': -83591539.58645022, 'agent_7': -152139283.4702917} id_=4b57acd8b94a43cc9844d2351890b634)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4b57acd8b94a43cc9844d2351890b634 NAV Verification ====================\n",
      "  agent_0 NAV: 981,296.00\n",
      "  agent_1 NAV: 1,025,949.00\n",
      "  agent_2 NAV: 1,054,966.00\n",
      "  agent_3 NAV: 950,242.00\n",
      "  agent_4 NAV: 970,165.00\n",
      "  agent_5 NAV: 1,014,431.00\n",
      "  agent_6 NAV: 1,018,142.00\n",
      "  agent_7 NAV: 984,809.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 2072e45a59f7447e8bdb47472de51993 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -150269623.53384113, 'agent_1': -640771204.1344982, 'agent_2': -47976149.065033525, 'agent_3': -272437084.3432158, 'agent_4': -75255790.7767462, 'agent_5': -297850475.73950475, 'agent_6': -133367441.48126447, 'agent_7': -244439691.52177927} id_=2072e45a59f7447e8bdb47472de51993)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 2072e45a59f7447e8bdb47472de51993 NAV Verification ====================\n",
      "  agent_0 NAV: 998,494.00\n",
      "  agent_1 NAV: 1,074,523.00\n",
      "  agent_2 NAV: 985,712.00\n",
      "  agent_3 NAV: 978,889.00\n",
      "  agent_4 NAV: 991,337.00\n",
      "  agent_5 NAV: 1,027,067.00\n",
      "  agent_6 NAV: 992,501.00\n",
      "  agent_7 NAV: 951,477.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 550ecd8aca124ec084630b32a644275e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -287436864.20 | Std: 113557490.99 | Threshold: -276081115.10\n",
      "Policy Returns: {'policy_3': -248940695.48458236, 'policy_1': -580786485.7236431, 'policy_2': -259290454.51502144, 'policy_6': -271197487.7071699, 'policy_0': -204300063.97601512, 'policy_4': -206256679.88502595, 'policy_5': -263011654.8320723, 'policy_7': -265711391.49280548}\n",
      "Best Trainable: policy_0 (-204300063.98)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "⚠️  Removing oldest champion: champion_4 (from iteration 7, return=-192609068.77)\n",
      "✓ Champion removed. Active champions: ['champion_5']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -204300063.98\n",
      "Iteration: 11\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_6 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -6308093.163128398, 'agent_1': -75659805.58981192, 'agent_2': -4425377.884146785, 'agent_3': -652850.4494154741, 'agent_4': -39919059.101481825, 'agent_5': -39589738.490527794, 'agent_6': -35007361.439680904, 'agent_7': -17435489.999076415} id_=550ecd8aca124ec084630b32a644275e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 550ecd8aca124ec084630b32a644275e NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,508.00\n",
      "  agent_1 NAV: 886,499.00\n",
      "  agent_2 NAV: 999,891.00\n",
      "  agent_3 NAV: 1,017,062.00\n",
      "  agent_4 NAV: 1,045,716.00\n",
      "  agent_5 NAV: 945,730.00\n",
      "  agent_6 NAV: 1,075,130.00\n",
      "  agent_7 NAV: 1,024,464.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode e1487450d2874ef0a599fe37aa5f373a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -343711456.80060637, 'agent_1': -438412089.7266373, 'agent_2': -57817928.01397024, 'agent_3': -45907532.76086622, 'agent_4': -307296358.35131735, 'agent_5': -223163588.6767458, 'agent_6': -149444718.78604117, 'agent_7': -63523944.4026534} id_=e1487450d2874ef0a599fe37aa5f373a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e1487450d2874ef0a599fe37aa5f373a NAV Verification ====================\n",
      "  agent_0 NAV: 1,027,547.00\n",
      "  agent_1 NAV: 921,449.00\n",
      "  agent_2 NAV: 1,020,506.00\n",
      "  agent_3 NAV: 1,019,791.00\n",
      "  agent_4 NAV: 991,911.00\n",
      "  agent_5 NAV: 995,599.00\n",
      "  agent_6 NAV: 1,017,661.00\n",
      "  agent_7 NAV: 1,005,536.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode e5055822805b4b2386caadfe9cb33b8d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -72059756.42077082, 'agent_1': -373216478.2108543, 'agent_2': -256239883.64821067, 'agent_3': -242361168.81443653, 'agent_4': -525152314.7601849, 'agent_5': -77037103.7881375, 'agent_6': -76676576.8712398, 'agent_7': -373866995.9301462} id_=e5055822805b4b2386caadfe9cb33b8d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e5055822805b4b2386caadfe9cb33b8d NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,922.00\n",
      "  agent_1 NAV: 919,152.00\n",
      "  agent_2 NAV: 1,051,845.00\n",
      "  agent_3 NAV: 1,036,331.00\n",
      "  agent_4 NAV: 905,902.00\n",
      "  agent_5 NAV: 1,006,858.00\n",
      "  agent_6 NAV: 991,290.00\n",
      "  agent_7 NAV: 1,076,700.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 51f168d3c2e648debf77504cf9446858 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_5\n",
      "  agent_5 -> champion_6\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -57336280.31513721, 'agent_1': -589987884.2990888, 'agent_2': -722145526.1967739, 'agent_3': -324778345.23026013, 'agent_4': -200845532.3087681, 'agent_5': -247010523.1122024, 'agent_6': -177982728.11945337, 'agent_7': -314089026.5391809} id_=51f168d3c2e648debf77504cf9446858)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 51f168d3c2e648debf77504cf9446858 NAV Verification ====================\n",
      "  agent_0 NAV: 991,125.00\n",
      "  agent_1 NAV: 1,100,703.00\n",
      "  agent_2 NAV: 908,311.00\n",
      "  agent_3 NAV: 1,056,522.00\n",
      "  agent_4 NAV: 950,015.00\n",
      "  agent_5 NAV: 979,405.00\n",
      "  agent_6 NAV: 963,275.00\n",
      "  agent_7 NAV: 1,050,644.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 3403aa0eb70d497abc8f81abcc4382d6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -286035938.90 | Std: 112439575.85 | Threshold: -274791981.31\n",
      "Policy Returns: {'policy_3': -242424650.38516462, 'policy_1': -577902495.8635975, 'policy_2': -260135330.53896645, 'policy_6': -263531182.20934543, 'policy_0': -200649024.80002916, 'policy_4': -219390376.9180648, 'policy_5': -262371540.04631615, 'policy_7': -261882910.42775896}\n",
      "Best Trainable: policy_0 (-200649024.80)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -19882453.35853895, 'agent_1': -58144363.0239207, 'agent_2': -9281597.99029734, 'agent_3': -7325607.895521112, 'agent_4': -29438656.760970373, 'agent_5': -4317347.770954952, 'agent_6': -26940249.19091535, 'agent_7': -32504915.712840747} id_=3403aa0eb70d497abc8f81abcc4382d6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3403aa0eb70d497abc8f81abcc4382d6 NAV Verification ====================\n",
      "  agent_0 NAV: 994,584.00\n",
      "  agent_1 NAV: 1,138,356.00\n",
      "  agent_2 NAV: 981,196.00\n",
      "  agent_3 NAV: 991,592.00\n",
      "  agent_4 NAV: 929,366.00\n",
      "  agent_5 NAV: 929,476.00\n",
      "  agent_6 NAV: 1,067,634.00\n",
      "  agent_7 NAV: 967,796.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode f824f25ae8a7406cbec5701d384a6eca Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -145515485.35195452, 'agent_1': -349916169.22530407, 'agent_2': -382309560.8290011, 'agent_3': -285499126.9352, 'agent_4': -377167884.8115571, 'agent_5': -227236792.78211716, 'agent_6': -339167023.33969253, 'agent_7': -36452906.97105572} id_=f824f25ae8a7406cbec5701d384a6eca)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f824f25ae8a7406cbec5701d384a6eca NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,702.00\n",
      "  agent_1 NAV: 997,754.00\n",
      "  agent_2 NAV: 962,491.00\n",
      "  agent_3 NAV: 999,315.00\n",
      "  agent_4 NAV: 991,243.00\n",
      "  agent_5 NAV: 1,042,233.00\n",
      "  agent_6 NAV: 997,749.00\n",
      "  agent_7 NAV: 1,004,513.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 4bc675cf74b04d30bd3df879059e3207 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -189483023.85174093, 'agent_1': -1142167379.9165103, 'agent_2': -190198901.23143977, 'agent_3': -293773046.4623208, 'agent_4': -51671250.778955765, 'agent_5': -201794824.29283285, 'agent_6': -337316589.1272121, 'agent_7': -504073273.9880397} id_=4bc675cf74b04d30bd3df879059e3207)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4bc675cf74b04d30bd3df879059e3207 NAV Verification ====================\n",
      "  agent_0 NAV: 969,481.00\n",
      "  agent_1 NAV: 1,278,884.00\n",
      "  agent_2 NAV: 931,467.00\n",
      "  agent_3 NAV: 947,498.00\n",
      "  agent_4 NAV: 974,787.00\n",
      "  agent_5 NAV: 954,890.00\n",
      "  agent_6 NAV: 1,096,618.00\n",
      "  agent_7 NAV: 846,375.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 93b7438a98a543a1ac3a739ecee78c47 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -195471960.21002764, 'agent_1': -407098402.4674526, 'agent_2': -504636731.1248625, 'agent_3': -283767342.5495747, 'agent_4': -217759297.35376716, 'agent_5': -175220015.74345186, 'agent_6': -310826536.8821437, 'agent_7': -277138760.3731395} id_=93b7438a98a543a1ac3a739ecee78c47)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 93b7438a98a543a1ac3a739ecee78c47 NAV Verification ====================\n",
      "  agent_0 NAV: 994,815.00\n",
      "  agent_1 NAV: 1,068,057.00\n",
      "  agent_2 NAV: 1,042,030.00\n",
      "  agent_3 NAV: 976,001.00\n",
      "  agent_4 NAV: 964,555.00\n",
      "  agent_5 NAV: 1,003,023.00\n",
      "  agent_6 NAV: 1,012,575.00\n",
      "  agent_7 NAV: 938,944.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 6c3128cc521e411b8b39e7b446c204ce Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -286089127.52 | Std: 113306988.73 | Threshold: -274758428.65\n",
      "Policy Returns: {'policy_3': -241444949.49758315, 'policy_1': -579794870.1075581, 'policy_2': -262432731.4690974, 'policy_6': -267386145.6451465, 'policy_0': -198312820.87221178, 'policy_4': -219365605.44199508, 'policy_5': -256600795.8649163, 'policy_7': -263375101.26407516}\n",
      "Best Trainable: policy_0 (-198312820.87)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "⚠️  Removing oldest champion: champion_5 (from iteration 9, return=-201910526.00)\n",
      "✓ Champion removed. Active champions: ['champion_6']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -198312820.87\n",
      "Iteration: 13\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_7 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -22522875.517436396, 'agent_1': -61533438.371768184, 'agent_2': -41400351.12584444, 'agent_3': -10320570.679604063, 'agent_4': -21150222.266219627, 'agent_5': -11112151.625888681, 'agent_6': -50113277.23563678, 'agent_7': -60442644.76835528} id_=6c3128cc521e411b8b39e7b446c204ce)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6c3128cc521e411b8b39e7b446c204ce NAV Verification ====================\n",
      "  agent_0 NAV: 977,695.00\n",
      "  agent_1 NAV: 1,081,296.00\n",
      "  agent_2 NAV: 967,519.00\n",
      "  agent_3 NAV: 997,731.00\n",
      "  agent_4 NAV: 964,501.00\n",
      "  agent_5 NAV: 1,014,731.00\n",
      "  agent_6 NAV: 925,147.00\n",
      "  agent_7 NAV: 1,071,380.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 95860c183dc34b83a86ee223f1c576cf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -541376557.9443934, 'agent_1': -1432746423.7818182, 'agent_2': -313143908.97795564, 'agent_3': -153005228.91136283, 'agent_4': -170861896.34899276, 'agent_5': -218037689.98691416, 'agent_6': -564372544.6540165, 'agent_7': -81768417.15603842} id_=95860c183dc34b83a86ee223f1c576cf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 95860c183dc34b83a86ee223f1c576cf NAV Verification ====================\n",
      "  agent_0 NAV: 851,415.00\n",
      "  agent_1 NAV: 1,409,840.00\n",
      "  agent_2 NAV: 947,286.00\n",
      "  agent_3 NAV: 946,228.00\n",
      "  agent_4 NAV: 946,900.00\n",
      "  agent_5 NAV: 1,046,260.00\n",
      "  agent_6 NAV: 863,713.00\n",
      "  agent_7 NAV: 988,358.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode a1e24a919d1547bc891081a627b04f47 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -211340533.51596564, 'agent_1': -1037093207.4649615, 'agent_2': -101535673.996894, 'agent_3': -107830905.19977733, 'agent_4': -266143288.50612125, 'agent_5': -237229370.76504308, 'agent_6': -252394403.36436263, 'agent_7': -250945659.89647892} id_=a1e24a919d1547bc891081a627b04f47)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a1e24a919d1547bc891081a627b04f47 NAV Verification ====================\n",
      "  agent_0 NAV: 990,960.00\n",
      "  agent_1 NAV: 1,167,976.00\n",
      "  agent_2 NAV: 987,591.00\n",
      "  agent_3 NAV: 975,327.00\n",
      "  agent_4 NAV: 945,578.00\n",
      "  agent_5 NAV: 960,590.00\n",
      "  agent_6 NAV: 1,041,169.00\n",
      "  agent_7 NAV: 930,809.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 3328bd7d1ee041329ee9c7f5f6943f1c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_6\n",
      "  agent_5 -> champion_7\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -368119253.53823763, 'agent_1': -496370294.50775886, 'agent_2': -320511125.0883491, 'agent_3': -247045810.26529878, 'agent_4': -239916313.33986658, 'agent_5': -124596086.36952753, 'agent_6': -110845180.47323754, 'agent_7': -208362077.77980396} id_=3328bd7d1ee041329ee9c7f5f6943f1c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3328bd7d1ee041329ee9c7f5f6943f1c NAV Verification ====================\n",
      "  agent_0 NAV: 968,165.00\n",
      "  agent_1 NAV: 1,098,554.00\n",
      "  agent_2 NAV: 964,919.00\n",
      "  agent_3 NAV: 998,775.00\n",
      "  agent_4 NAV: 990,142.00\n",
      "  agent_5 NAV: 999,565.00\n",
      "  agent_6 NAV: 948,785.00\n",
      "  agent_7 NAV: 1,031,095.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode eb47eabc5fad4314b3f233406a3ecf52 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_6\n",
      "  agent_6 -> champion_7\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -286876302.54 | Std: 119038472.59 | Threshold: -274972455.28\n",
      "Policy Returns: {'policy_3': -234854236.42133287, 'policy_1': -597193872.0812145, 'policy_2': -259417778.27812877, 'policy_6': -268788872.5217625, 'policy_0': -206943270.07159036, 'policy_4': -217426427.13998985, 'policy_5': -249872824.1246084, 'policy_7': -260513139.69631052}\n",
      "Best Trainable: policy_0 (-206943270.07)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -25859839.230669394, 'agent_1': -183638412.36434615, 'agent_2': -27277167.523156658, 'agent_3': -67078699.0578967, 'agent_4': -64735590.05855771, 'agent_5': -24196877.697916105, 'agent_6': -32221898.276231796, 'agent_7': -49441938.36953226} id_=eb47eabc5fad4314b3f233406a3ecf52)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode eb47eabc5fad4314b3f233406a3ecf52 NAV Verification ====================\n",
      "  agent_0 NAV: 978,830.00\n",
      "  agent_1 NAV: 1,047,062.00\n",
      "  agent_2 NAV: 1,017,157.00\n",
      "  agent_3 NAV: 945,215.00\n",
      "  agent_4 NAV: 1,031,844.00\n",
      "  agent_5 NAV: 994,762.00\n",
      "  agent_6 NAV: 984,146.00\n",
      "  agent_7 NAV: 1,000,984.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 7ef6550a40514369bcb984716228f51b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_6\n",
      "  agent_6 -> champion_7\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -58546449.94462617, 'agent_1': -422432635.25239754, 'agent_2': -143746807.45874342, 'agent_3': -419625660.41139084, 'agent_4': -166807083.81449375, 'agent_5': -234853636.63578206, 'agent_6': -150287141.54487556, 'agent_7': -86090532.65148905} id_=7ef6550a40514369bcb984716228f51b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 7ef6550a40514369bcb984716228f51b NAV Verification ====================\n",
      "  agent_0 NAV: 1,025,697.00\n",
      "  agent_1 NAV: 1,062,310.00\n",
      "  agent_2 NAV: 1,030,163.00\n",
      "  agent_3 NAV: 944,069.00\n",
      "  agent_4 NAV: 1,032,425.00\n",
      "  agent_5 NAV: 962,949.00\n",
      "  agent_6 NAV: 973,086.00\n",
      "  agent_7 NAV: 969,301.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 857c65ced9154504842250031d377b79 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -280485462.7168777, 'agent_1': -467585342.99917746, 'agent_2': -296845803.6164669, 'agent_3': -59660626.75304337, 'agent_4': -217419968.69784462, 'agent_5': -125582669.6140831, 'agent_6': -259568937.0848582, 'agent_7': -465819294.0979652} id_=857c65ced9154504842250031d377b79)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 857c65ced9154504842250031d377b79 NAV Verification ====================\n",
      "  agent_0 NAV: 912,147.00\n",
      "  agent_1 NAV: 1,084,062.00\n",
      "  agent_2 NAV: 1,074,270.00\n",
      "  agent_3 NAV: 1,001,179.00\n",
      "  agent_4 NAV: 958,658.00\n",
      "  agent_5 NAV: 976,111.00\n",
      "  agent_6 NAV: 1,086,469.00\n",
      "  agent_7 NAV: 907,104.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 9446eaabe5d04354b8adf14f16221eef Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -228088734.87527707, 'agent_1': -384073153.86187035, 'agent_2': -311413831.14273953, 'agent_3': -214685696.86934507, 'agent_4': -99029692.4943396, 'agent_5': -90805189.1429511, 'agent_6': -238585130.0597134, 'agent_7': -329740479.7716833} id_=9446eaabe5d04354b8adf14f16221eef)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9446eaabe5d04354b8adf14f16221eef NAV Verification ====================\n",
      "  agent_0 NAV: 971,079.00\n",
      "  agent_1 NAV: 1,041,401.00\n",
      "  agent_2 NAV: 1,080,305.00\n",
      "  agent_3 NAV: 999,392.00\n",
      "  agent_4 NAV: 992,286.00\n",
      "  agent_5 NAV: 1,029,890.00\n",
      "  agent_6 NAV: 991,428.00\n",
      "  agent_7 NAV: 894,219.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 2e08c421fab74e9fb6675a2c182c664d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -284320562.96 | Std: 117586980.14 | Threshold: -272561864.95\n",
      "Policy Returns: {'policy_3': -237975948.15156102, 'policy_1': -591087070.8236551, 'policy_2': -256348083.0025428, 'policy_6': -262685053.9961885, 'policy_0': -205246090.88903576, 'policy_4': -216400207.66845095, 'policy_5': -242234321.77212408, 'policy_7': -262587727.39240107}\n",
      "Best Trainable: policy_0 (-205246090.89)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "⚠️  Removing oldest champion: champion_6 (from iteration 11, return=-204300063.98)\n",
      "✓ Champion removed. Active champions: ['champion_7']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -205246090.89\n",
      "Iteration: 15\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_8 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_7', 'champion_8']\n",
      "\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -51808449.45732748, 'agent_1': -96534747.49509582, 'agent_2': -37108286.43003924, 'agent_3': -70543750.85725065, 'agent_4': -42433587.75794902, 'agent_5': -57825449.917546965, 'agent_6': -116287625.63727562, 'agent_7': -6917039.974490248} id_=2e08c421fab74e9fb6675a2c182c664d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 2e08c421fab74e9fb6675a2c182c664d NAV Verification ====================\n",
      "  agent_0 NAV: 973,029.00\n",
      "  agent_1 NAV: 1,005,577.00\n",
      "  agent_2 NAV: 1,029,067.00\n",
      "  agent_3 NAV: 1,070,360.00\n",
      "  agent_4 NAV: 978,331.00\n",
      "  agent_5 NAV: 978,658.00\n",
      "  agent_6 NAV: 973,723.00\n",
      "  agent_7 NAV: 991,255.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 626e4fb430704e7ea1373ceb529b1f14 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> champion_8\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -327663231.88663894, 'agent_1': -277162092.3313091, 'agent_2': -301427183.3826019, 'agent_3': -67067438.89041478, 'agent_4': -292085400.30650336, 'agent_5': -22925105.24017413, 'agent_6': -60259176.028275214, 'agent_7': -485286557.8449352} id_=626e4fb430704e7ea1373ceb529b1f14)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 626e4fb430704e7ea1373ceb529b1f14 NAV Verification ====================\n",
      "  agent_0 NAV: 904,544.00\n",
      "  agent_1 NAV: 1,079,541.00\n",
      "  agent_2 NAV: 885,545.00\n",
      "  agent_3 NAV: 1,033,091.00\n",
      "  agent_4 NAV: 947,110.00\n",
      "  agent_5 NAV: 981,200.00\n",
      "  agent_6 NAV: 1,021,543.00\n",
      "  agent_7 NAV: 1,147,426.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 7232bb179a894455af62f50c5578fa14 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_7\n",
      "  agent_7 -> champion_8\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -186827678.5947715, 'agent_1': -357101024.8621815, 'agent_2': -168111209.64524576, 'agent_3': -145429484.06430614, 'agent_4': -204954450.3322382, 'agent_5': -114661456.2816798, 'agent_6': -59964140.48783151, 'agent_7': -201880721.50114152} id_=7232bb179a894455af62f50c5578fa14)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 7232bb179a894455af62f50c5578fa14 NAV Verification ====================\n",
      "  agent_0 NAV: 985,273.00\n",
      "  agent_1 NAV: 1,002,011.00\n",
      "  agent_2 NAV: 973,589.00\n",
      "  agent_3 NAV: 997,273.00\n",
      "  agent_4 NAV: 1,037,200.00\n",
      "  agent_5 NAV: 994,930.00\n",
      "  agent_6 NAV: 1,005,999.00\n",
      "  agent_7 NAV: 1,003,725.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode a07c869bd85c49288cb70bff43b94212 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_7\n",
      "  agent_7 -> champion_8\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -325793670.7542828, 'agent_1': -803617477.4787419, 'agent_2': -274404275.7607549, 'agent_3': -172795393.9442903, 'agent_4': -448016638.7074343, 'agent_5': -291451312.0843581, 'agent_6': -296320606.94651896, 'agent_7': -286591516.80351436} id_=a07c869bd85c49288cb70bff43b94212)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a07c869bd85c49288cb70bff43b94212 NAV Verification ====================\n",
      "  agent_0 NAV: 867,350.00\n",
      "  agent_1 NAV: 1,296,354.00\n",
      "  agent_2 NAV: 905,344.00\n",
      "  agent_3 NAV: 922,861.00\n",
      "  agent_4 NAV: 924,069.00\n",
      "  agent_5 NAV: 1,062,220.00\n",
      "  agent_6 NAV: 907,084.00\n",
      "  agent_7 NAV: 1,114,718.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 7415f96ac54046f2a08741bfb9478ea0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> champion_8\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_7', 'champion_8']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -282870286.59 | Std: 114531952.55 | Threshold: -271417091.33\n",
      "Policy Returns: {'policy_3': -235922823.2741877, 'policy_1': -582519330.3717219, 'policy_2': -254878369.82161924, 'policy_6': -258536948.90983206, 'policy_0': -211148620.21419325, 'policy_4': -220271951.08109286, 'policy_5': -237055319.73101276, 'policy_7': -262628929.2799615}\n",
      "Best Trainable: policy_0 (-211148620.21)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ← KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23 16:01:16\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
