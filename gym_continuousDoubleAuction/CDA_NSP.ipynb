{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-25 16:50:54\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Get current time in SGT (Singapore Time)\n",
    "sgt_time = datetime.now(ZoneInfo(\"Asia/Singapore\"))\n",
    "formatted_datetime = sgt_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"‚ùå No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 08:50:56,841\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2026-01-25 08:50:58,505\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.47.1\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_6', 'agent_5', 'agent_2', 'agent_3', 'agent_0', 'agent_1', 'agent_4', 'agent_7']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 08:51:00,925\tWARNING services.py:2152 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.77gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2026-01-25 08:51:02,075\tINFO worker.py:1917 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"7a4184b2-29a3-46e3-a172-b30e0b164816\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 8\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 * 4 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863b80>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863ac0>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863a60>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863c70>, 'policy_4': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863d30>, 'policy_5': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863dc0>, 'policy_6': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863e50>, 'policy_7': <ray.rllib.policy.policy.PolicySpec object at 0x704e38863e80>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=8,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ‚Üê ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 08:51:02,388\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2026-01-25 08:51:02,390\tWARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 16384\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2026-01-25 08:51:02,647\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2026-01-25 08:51:02,656\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2026-01-25 08:51:02,666\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2026-01-25 08:51:02,686\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2026-01-25 08:51:02,696\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2026-01-25 08:51:02,706\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2026-01-25 08:51:02,709\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2026-01-25 08:51:07,068\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,069\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,069\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,069\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,070\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,095\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,096\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2026-01-25 08:51:07,097\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32), 'agent_4': Box(-inf, inf, (40,), float32), 'agent_5': Box(-inf, inf, (40,), float32), 'agent_6': Box(-inf, inf, (40,), float32), 'agent_7': Box(-inf, inf, (40,), float32)), Dict('agent_0': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_1': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_2': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_3': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_4': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_5': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_6': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_7': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))), 'policy_0': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_1': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_2': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_3': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_4': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_5': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_6': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_7': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))}\n",
      "2026-01-25 08:51:07,136\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:07,136\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:07,146\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:07,154\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:07,163\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:07,172\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:07,180\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:09,047\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2026-01-25 08:51:09,083\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 16384\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "Episode a9df0a5974e24d73aefe82706011605e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5518536.600000005, 'agent_1': -24537989.749999985, 'agent_2': -14965356.35000006, 'agent_3': -3015259.3499999964, 'agent_4': -42176622.94999987, 'agent_5': -5137386.449999996, 'agent_6': -14293774.29999998, 'agent_7': -22556489.14999996} id_=a9df0a5974e24d73aefe82706011605e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a9df0a5974e24d73aefe82706011605e NAV Verification ====================\n",
      "  agent_0 NAV: 1,051,927.00\n",
      "  agent_1 NAV: 943,910.00\n",
      "  agent_2 NAV: 1,142,110.00\n",
      "  agent_3 NAV: 1,013,509.00\n",
      "  agent_4 NAV: 921,835.00\n",
      "  agent_5 NAV: 1,027,622.00\n",
      "  agent_6 NAV: 969,824.00\n",
      "  agent_7 NAV: 929,263.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode f9f5511175d747638ae2747193771b4d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7090371.849999992, 'agent_1': -5543220.200000005, 'agent_2': -8052670.750000002, 'agent_3': -6258504.999999996, 'agent_4': -11404062.800000027, 'agent_5': -4007728.7499999814, 'agent_6': -9601370.149999965, 'agent_7': -21207649.599999994} id_=f9f5511175d747638ae2747193771b4d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f9f5511175d747638ae2747193771b4d NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,335.00\n",
      "  agent_1 NAV: 1,005,444.00\n",
      "  agent_2 NAV: 993,970.00\n",
      "  agent_3 NAV: 998,782.00\n",
      "  agent_4 NAV: 993,269.00\n",
      "  agent_5 NAV: 1,005,916.00\n",
      "  agent_6 NAV: 1,004,228.00\n",
      "  agent_7 NAV: 987,056.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 3c8d209f4b174bf8a252e6619612df46 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6639825.150000002, 'agent_1': -12904958.450000001, 'agent_2': -6424663.499999986, 'agent_3': -17244383.75000001, 'agent_4': -6628960.85000001, 'agent_5': -11843707.349999964, 'agent_6': -7001072.949999994, 'agent_7': -22058554.49999996} id_=3c8d209f4b174bf8a252e6619612df46)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3c8d209f4b174bf8a252e6619612df46 NAV Verification ====================\n",
      "  agent_0 NAV: 1,022,927.00\n",
      "  agent_1 NAV: 963,660.00\n",
      "  agent_2 NAV: 1,114,007.00\n",
      "  agent_3 NAV: 919,566.00\n",
      "  agent_4 NAV: 1,022,630.00\n",
      "  agent_5 NAV: 1,008,812.00\n",
      "  agent_6 NAV: 993,662.00\n",
      "  agent_7 NAV: 954,736.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 2bf95f8c6f674953837da4d0c4a56e46 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -12338046.69 | Std: 5503750.64 | Threshold: -11787671.62\n",
      "Policy Returns: {'policy_0': -6416244.533333334, 'policy_2': -9814230.200000016, 'policy_6': -10298739.133333312, 'policy_7': -21940897.74999997, 'policy_1': -14328722.799999997, 'policy_4': -20069882.19999997, 'policy_5': -6996274.183333314, 'policy_3': -8839382.700000001}\n",
      "Best Trainable: policy_0 (-6416244.53)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -6416244.53\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_1 created successfully!\n",
      "‚úì League size now: 3 (2 trainable + 1 champions)\n",
      "‚úì Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': -37153.8, 'agent_1': -16715.15, 'agent_2': -12231.849999999999, 'agent_3': -3958.35, 'agent_4': -27821.0, 'agent_5': -34546.1, 'agent_6': -15404.45, 'agent_7': -9842.9} id_=2bf95f8c6f674953837da4d0c4a56e46)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 2bf95f8c6f674953837da4d0c4a56e46 NAV Verification ====================\n",
      "  agent_0 NAV: 964,011.00\n",
      "  agent_1 NAV: 982,267.00\n",
      "  agent_2 NAV: 999,943.00\n",
      "  agent_3 NAV: 999,144.00\n",
      "  agent_4 NAV: 1,066,771.00\n",
      "  agent_5 NAV: 961,943.00\n",
      "  agent_6 NAV: 1,012,870.00\n",
      "  agent_7 NAV: 1,013,051.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 8045c9d8b42d4a248c31f04db81b98ed Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8892942.550000018, 'agent_1': -19254279.95, 'agent_2': -20344175.799999963, 'agent_3': -11701001.199999982, 'agent_4': -11850402.54999999, 'agent_5': -34237473.299999975, 'agent_6': -21452640.99999999, 'agent_7': -11845469.150000028} id_=8045c9d8b42d4a248c31f04db81b98ed)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8045c9d8b42d4a248c31f04db81b98ed NAV Verification ====================\n",
      "  agent_0 NAV: 1,026,046.00\n",
      "  agent_1 NAV: 1,001,404.00\n",
      "  agent_2 NAV: 981,907.00\n",
      "  agent_3 NAV: 995,959.00\n",
      "  agent_4 NAV: 1,018,053.00\n",
      "  agent_5 NAV: 993,011.00\n",
      "  agent_6 NAV: 995,665.00\n",
      "  agent_7 NAV: 987,955.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 52db47eb4fbc4c92b2a5b178d2fa9aa0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8396615.449999986, 'agent_1': -2675939.4999999967, 'agent_2': -6604716.400000002, 'agent_3': -8419638.049999991, 'agent_4': -19304052.399999987, 'agent_5': -10631508.350000026, 'agent_6': -7771414.650000009, 'agent_7': -8299786.700000007} id_=52db47eb4fbc4c92b2a5b178d2fa9aa0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 52db47eb4fbc4c92b2a5b178d2fa9aa0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,010,409.00\n",
      "  agent_1 NAV: 1,003,295.00\n",
      "  agent_2 NAV: 1,014,836.00\n",
      "  agent_3 NAV: 1,000,154.00\n",
      "  agent_4 NAV: 974,183.00\n",
      "  agent_5 NAV: 1,000,619.00\n",
      "  agent_6 NAV: 1,009,426.00\n",
      "  agent_7 NAV: 987,078.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode d8450e4fad604f04a2c4f4976cacda34 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -21819680.049999945, 'agent_1': -3987759.9999999935, 'agent_2': -16541358.55000006, 'agent_3': -9612591.65000004, 'agent_4': -10022987.149999987, 'agent_5': -11955709.89999999, 'agent_6': -8727587.500000015, 'agent_7': -12738680.000000013} id_=d8450e4fad604f04a2c4f4976cacda34)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode d8450e4fad604f04a2c4f4976cacda34 NAV Verification ====================\n",
      "  agent_0 NAV: 983,420.00\n",
      "  agent_1 NAV: 1,006,868.00\n",
      "  agent_2 NAV: 1,022,716.00\n",
      "  agent_3 NAV: 981,916.00\n",
      "  agent_4 NAV: 990,207.00\n",
      "  agent_5 NAV: 1,031,524.00\n",
      "  agent_6 NAV: 998,885.00\n",
      "  agent_7 NAV: 984,464.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode e86691dfe5c942f681f9870686e8ac9f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -12317894.71 | Std: 2180786.92 | Threshold: -12099816.01\n",
      "Policy Returns: {'policy_0': -10688078.564285709, 'policy_2': -11622084.964285728, 'policy_6': -11044872.442857135, 'policy_7': -14783086.521428565, 'policy_1': -10895082.507142857, 'policy_4': -16177042.878571412, 'policy_5': -13839273.071428565, 'policy_3': -9493636.692857148}\n",
      "Best Trainable: policy_0 (-10688078.56)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -52686.49999999999, 'agent_1': -3573.0, 'agent_2': -31391.45, 'agent_3': -7119.950000000001, 'agent_4': -31468.250000000004, 'agent_5': -18567.300000000003, 'agent_6': -21715.850000000002, 'agent_7': -2916.600000000001} id_=e86691dfe5c942f681f9870686e8ac9f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e86691dfe5c942f681f9870686e8ac9f NAV Verification ====================\n",
      "  agent_0 NAV: 979,860.00\n",
      "  agent_1 NAV: 1,038,409.00\n",
      "  agent_2 NAV: 987,627.00\n",
      "  agent_3 NAV: 1,003,613.00\n",
      "  agent_4 NAV: 983,032.00\n",
      "  agent_5 NAV: 1,000,226.00\n",
      "  agent_6 NAV: 987,560.00\n",
      "  agent_7 NAV: 1,019,673.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 02bab3f2601845e8919ba784ecb6a69e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -14269582.099999964, 'agent_1': -8129790.300000003, 'agent_2': -9155429.199999986, 'agent_3': -8459448.300000006, 'agent_4': -7372088.799999987, 'agent_5': -14460237.49999997, 'agent_6': -6003865.75, 'agent_7': -7850877.049999995} id_=02bab3f2601845e8919ba784ecb6a69e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 02bab3f2601845e8919ba784ecb6a69e NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,196.00\n",
      "  agent_1 NAV: 977,772.00\n",
      "  agent_2 NAV: 1,014,392.00\n",
      "  agent_3 NAV: 1,014,172.00\n",
      "  agent_4 NAV: 977,279.00\n",
      "  agent_5 NAV: 1,012,713.00\n",
      "  agent_6 NAV: 1,004,119.00\n",
      "  agent_7 NAV: 999,357.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 7fa33ab4533141318c213670f01101ac Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -15857122.50000007, 'agent_1': -5435910.949999999, 'agent_2': -7081191.500000006, 'agent_3': -25769581.700000063, 'agent_4': -9924328.450000027, 'agent_5': -46720254.24999988, 'agent_6': -34615808.80000002, 'agent_7': -10893313.149999997} id_=7fa33ab4533141318c213670f01101ac)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 7fa33ab4533141318c213670f01101ac NAV Verification ====================\n",
      "  agent_0 NAV: 1,159,760.00\n",
      "  agent_1 NAV: 1,048,564.00\n",
      "  agent_2 NAV: 1,056,956.00\n",
      "  agent_3 NAV: 931,481.00\n",
      "  agent_4 NAV: 983,252.00\n",
      "  agent_5 NAV: 881,550.00\n",
      "  agent_6 NAV: 919,897.00\n",
      "  agent_7 NAV: 1,018,540.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 49b47d00740c4a12bb14c71c72a02bea Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5013306.200000003, 'agent_1': -8998729.200000042, 'agent_2': -5354834.299999994, 'agent_3': -14375628.999999983, 'agent_4': -16711680.2, 'agent_5': -4282921.549999989, 'agent_6': -9316063.149999972, 'agent_7': -5025617.9} id_=49b47d00740c4a12bb14c71c72a02bea)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 49b47d00740c4a12bb14c71c72a02bea NAV Verification ====================\n",
      "  agent_0 NAV: 994,986.00\n",
      "  agent_1 NAV: 991,129.00\n",
      "  agent_2 NAV: 1,010,018.00\n",
      "  agent_3 NAV: 1,019,123.00\n",
      "  agent_4 NAV: 990,206.00\n",
      "  agent_5 NAV: 995,102.00\n",
      "  agent_6 NAV: 983,827.00\n",
      "  agent_7 NAV: 1,015,609.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 9edcad841f0e4603a96ff06956cbaf5d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -11904700.07 | Std: 1810008.53 | Threshold: -11723699.22\n",
      "Policy Returns: {'policy_0': -11439881.695454543, 'policy_2': -10011875.522727279, 'policy_6': -12234814.127272723, 'policy_7': -12046250.490909087, 'policy_1': -9430529.022727275, 'policy_4': -14124439.672727259, 'policy_5': -15089349.477272708, 'policy_3': -10860460.581818193}\n",
      "Best Trainable: policy_1 (-9430529.02)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_1\n",
      "Return: -9430529.02\n",
      "Iteration: 3\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_2 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -47467.15, 'agent_1': -10530.8, 'agent_2': -79531.15, 'agent_3': -26445.100000000002, 'agent_4': -15303.900000000001, 'agent_5': -74166.65000000001, 'agent_6': -60530.49999999999, 'agent_7': -43254.549999999996} id_=9edcad841f0e4603a96ff06956cbaf5d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9edcad841f0e4603a96ff06956cbaf5d NAV Verification ====================\n",
      "  agent_0 NAV: 999,242.00\n",
      "  agent_1 NAV: 1,005,119.00\n",
      "  agent_2 NAV: 995,138.00\n",
      "  agent_3 NAV: 994,696.00\n",
      "  agent_4 NAV: 1,001,477.00\n",
      "  agent_5 NAV: 983,056.00\n",
      "  agent_6 NAV: 996,508.00\n",
      "  agent_7 NAV: 1,024,764.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 72cb5fc1cc5d431a8f64847756f2911d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -11014040.699999955, 'agent_1': -5225306.550000013, 'agent_2': -4052259.4499999783, 'agent_3': -11545261.350000054, 'agent_4': -24943553.949999984, 'agent_5': -15292203.050000036, 'agent_6': -7055274.500000005, 'agent_7': -7038504.850000018} id_=72cb5fc1cc5d431a8f64847756f2911d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 72cb5fc1cc5d431a8f64847756f2911d NAV Verification ====================\n",
      "  agent_0 NAV: 1,010,201.00\n",
      "  agent_1 NAV: 1,006,187.00\n",
      "  agent_2 NAV: 1,000,073.00\n",
      "  agent_3 NAV: 991,711.00\n",
      "  agent_4 NAV: 1,009,328.00\n",
      "  agent_5 NAV: 984,019.00\n",
      "  agent_6 NAV: 994,426.00\n",
      "  agent_7 NAV: 1,004,055.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 48f4698a4ac3435391c63a07e0955004 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -26548851.54999999, 'agent_1': -11249553.450000025, 'agent_2': -4198633.949999992, 'agent_3': -3379392.550000002, 'agent_4': -9438625.4, 'agent_5': -6016037.00000002, 'agent_6': -10417554.949999988, 'agent_7': -27391857.54999999} id_=48f4698a4ac3435391c63a07e0955004)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 48f4698a4ac3435391c63a07e0955004 NAV Verification ====================\n",
      "  agent_0 NAV: 920,669.00\n",
      "  agent_1 NAV: 987,750.00\n",
      "  agent_2 NAV: 1,032,392.00\n",
      "  agent_3 NAV: 1,011,966.00\n",
      "  agent_4 NAV: 1,014,261.00\n",
      "  agent_5 NAV: 995,728.00\n",
      "  agent_6 NAV: 1,113,479.00\n",
      "  agent_7 NAV: 923,755.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode fa21488dd55042c4b47c9b0c02d3ffba Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4662863.450000008, 'agent_1': -7669677.949999988, 'agent_2': -6199038.800000002, 'agent_3': -15236342.54999999, 'agent_4': -8160477.450000008, 'agent_5': -12681249.049999952, 'agent_6': -7571772.499999993, 'agent_7': -16031113.85} id_=fa21488dd55042c4b47c9b0c02d3ffba)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode fa21488dd55042c4b47c9b0c02d3ffba NAV Verification ====================\n",
      "  agent_0 NAV: 1,041,925.00\n",
      "  agent_1 NAV: 978,142.00\n",
      "  agent_2 NAV: 1,004,523.00\n",
      "  agent_3 NAV: 962,428.00\n",
      "  agent_4 NAV: 996,189.00\n",
      "  agent_5 NAV: 1,026,916.00\n",
      "  agent_6 NAV: 1,014,202.00\n",
      "  agent_7 NAV: 975,675.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 52dea2677671411b8d8b1cdc2a1567da Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -11441005.40 | Std: 1858017.64 | Threshold: -11255203.64\n",
      "Policy Returns: {'policy_0': -12013765.786666663, 'policy_2': -8981846.293333335, 'policy_6': -11243803.33333333, 'policy_7': -12589872.94333333, 'policy_1': -8694084.703333337, 'policy_4': -13463924.589999992, 'policy_5': -14123755.789999986, 'policy_3': -10416989.753333347}\n",
      "Best Trainable: policy_1 (-8694084.70)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -50116.25, 'agent_1': -229235.8, 'agent_2': -23519.750000000004, 'agent_3': -185328.40000000002, 'agent_4': -37184.35, 'agent_5': -60151.94999999999, 'agent_6': -120778.54999999999, 'agent_7': -90770.25} id_=52dea2677671411b8d8b1cdc2a1567da)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 52dea2677671411b8d8b1cdc2a1567da NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,561.00\n",
      "  agent_1 NAV: 998,159.00\n",
      "  agent_2 NAV: 1,012,485.00\n",
      "  agent_3 NAV: 1,000,012.00\n",
      "  agent_4 NAV: 999,817.00\n",
      "  agent_5 NAV: 993,216.00\n",
      "  agent_6 NAV: 1,004,052.00\n",
      "  agent_7 NAV: 980,698.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 99f1d15570bf459c98662d5db739dc13 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6894299.199999989, 'agent_1': -28585499.049999997, 'agent_2': -4501145.749999988, 'agent_3': -3527506.350000013, 'agent_4': -8829036.450000023, 'agent_5': -21805411.699999988, 'agent_6': -5129041.949999991, 'agent_7': -9863105.650000002} id_=99f1d15570bf459c98662d5db739dc13)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 99f1d15570bf459c98662d5db739dc13 NAV Verification ====================\n",
      "  agent_0 NAV: 1,094,491.00\n",
      "  agent_1 NAV: 909,308.00\n",
      "  agent_2 NAV: 1,061,250.00\n",
      "  agent_3 NAV: 1,031,779.00\n",
      "  agent_4 NAV: 972,326.00\n",
      "  agent_5 NAV: 933,037.00\n",
      "  agent_6 NAV: 1,021,812.00\n",
      "  agent_7 NAV: 975,997.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 45b491d4d262408fae59819a37df7b1e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4555243.599999984, 'agent_1': -3634394.6500000027, 'agent_2': -10556516.049999991, 'agent_3': -3933533.900000002, 'agent_4': -5563262.249999978, 'agent_5': -5700963.250000013, 'agent_6': -10104085.30000002, 'agent_7': -9012598.99999998} id_=45b491d4d262408fae59819a37df7b1e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 45b491d4d262408fae59819a37df7b1e NAV Verification ====================\n",
      "  agent_0 NAV: 1,007,228.00\n",
      "  agent_1 NAV: 999,770.00\n",
      "  agent_2 NAV: 997,455.00\n",
      "  agent_3 NAV: 995,895.00\n",
      "  agent_4 NAV: 996,869.00\n",
      "  agent_5 NAV: 992,846.00\n",
      "  agent_6 NAV: 982,053.00\n",
      "  agent_7 NAV: 1,027,884.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 234f075d16504fe0856da65f3810f289 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7012702.250000025, 'agent_1': -5333457.399999985, 'agent_2': -5217714.900000015, 'agent_3': -42805373.04999992, 'agent_4': -6385935.0500000175, 'agent_5': -2694239.050000002, 'agent_6': -3683335.349999999, 'agent_7': -4149020.150000012} id_=234f075d16504fe0856da65f3810f289)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 234f075d16504fe0856da65f3810f289 NAV Verification ====================\n",
      "  agent_0 NAV: 1,009,601.00\n",
      "  agent_1 NAV: 1,032,351.00\n",
      "  agent_2 NAV: 1,032,856.00\n",
      "  agent_3 NAV: 855,970.00\n",
      "  agent_4 NAV: 1,050,185.00\n",
      "  agent_5 NAV: 1,027,355.00\n",
      "  agent_6 NAV: 994,614.00\n",
      "  agent_7 NAV: 997,068.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 3664b1faeaf24a7e9cd3b938215793d1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -11184079.36 | Std: 1453640.76 | Threshold: -11038715.29\n",
      "Policy Returns: {'policy_0': -10942684.278947363, 'policy_2': -8359272.4605263155, 'policy_6': -10628980.905263154, 'policy_7': -11971391.965789467, 'policy_1': -10004053.728947368, 'policy_4': -11987373.071052626, 'policy_5': -13400450.163157882, 'policy_3': -12178428.34210527}\n",
      "Best Trainable: policy_1 (-10004053.73)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_1\n",
      "Return: -10004053.73\n",
      "Iteration: 5\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_3 created successfully!\n",
      "‚úì League size now: 5 (2 trainable + 3 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -36133.75, 'agent_1': -197458.0, 'agent_2': -189227.0, 'agent_3': -23848.7, 'agent_4': -5869.4, 'agent_5': -59068.65000000002, 'agent_6': -72550.15, 'agent_7': -108253.44999999998} id_=3664b1faeaf24a7e9cd3b938215793d1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3664b1faeaf24a7e9cd3b938215793d1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,786.00\n",
      "  agent_1 NAV: 957,700.00\n",
      "  agent_2 NAV: 985,751.00\n",
      "  agent_3 NAV: 1,009,488.00\n",
      "  agent_4 NAV: 1,018,467.00\n",
      "  agent_5 NAV: 1,004,497.00\n",
      "  agent_6 NAV: 984,380.00\n",
      "  agent_7 NAV: 1,038,931.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 3e90cf2227894fbba576550306ce0be6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -12908637.099999992, 'agent_1': -10288297.799999986, 'agent_2': -9347381.29999996, 'agent_3': -8464641.800000006, 'agent_4': -24018790.999999937, 'agent_5': -11970772.300000047, 'agent_6': -14627670.0, 'agent_7': -9197127.300000014} id_=3e90cf2227894fbba576550306ce0be6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3e90cf2227894fbba576550306ce0be6 NAV Verification ====================\n",
      "  agent_0 NAV: 980,733.00\n",
      "  agent_1 NAV: 1,037,938.00\n",
      "  agent_2 NAV: 1,041,182.00\n",
      "  agent_3 NAV: 1,020,266.00\n",
      "  agent_4 NAV: 952,982.00\n",
      "  agent_5 NAV: 999,298.00\n",
      "  agent_6 NAV: 966,596.00\n",
      "  agent_7 NAV: 1,001,005.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 4315459578b0448f8639bd8b2f138f8e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -10850745.099999996, 'agent_1': -5517489.65, 'agent_2': -22933059.350000035, 'agent_3': -11088056.449999949, 'agent_4': -5351425.4, 'agent_5': -10610932.000000002, 'agent_6': -15092213.09999996, 'agent_7': -6011256.85000001} id_=4315459578b0448f8639bd8b2f138f8e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4315459578b0448f8639bd8b2f138f8e NAV Verification ====================\n",
      "  agent_0 NAV: 1,015,797.00\n",
      "  agent_1 NAV: 998,572.00\n",
      "  agent_2 NAV: 991,705.00\n",
      "  agent_3 NAV: 1,000,637.00\n",
      "  agent_4 NAV: 1,008,467.00\n",
      "  agent_5 NAV: 1,005,518.00\n",
      "  agent_6 NAV: 982,146.00\n",
      "  agent_7 NAV: 997,158.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 8bf7a4a545ea40bcb27367d9062ad07d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -10028825.899999993, 'agent_1': -10012039.750000013, 'agent_2': -4603600.550000005, 'agent_3': -6875808.349999957, 'agent_4': -14340698.849999994, 'agent_5': -22563158.599999953, 'agent_6': -6852533.550000008, 'agent_7': -6240454.5500000315} id_=8bf7a4a545ea40bcb27367d9062ad07d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8bf7a4a545ea40bcb27367d9062ad07d NAV Verification ====================\n",
      "  agent_0 NAV: 990,380.00\n",
      "  agent_1 NAV: 1,062,788.00\n",
      "  agent_2 NAV: 984,597.00\n",
      "  agent_3 NAV: 1,015,565.00\n",
      "  agent_4 NAV: 1,018,065.00\n",
      "  agent_5 NAV: 943,598.00\n",
      "  agent_6 NAV: 985,288.00\n",
      "  agent_7 NAV: 999,719.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode c1275a3895d448fab94be7b7419fccd3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -11093949.88 | Std: 1199612.76 | Threshold: -10973988.60\n",
      "Policy Returns: {'policy_0': -10848228.743478255, 'policy_2': -8867895.880434783, 'policy_6': -10772504.30434782, 'policy_7': -11398346.082608694, 'policy_1': -10205059.578260867, 'policy_4': -12040028.9673913, 'policy_5': -13220610.426086947, 'policy_3': -11398925.026086958}\n",
      "Best Trainable: policy_1 (-10205059.58)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -188093.75, 'agent_1': -145886.6, 'agent_2': -57282.899999999994, 'agent_3': -16406.949999999997, 'agent_4': -178248.8, 'agent_5': -126319.54999999999, 'agent_6': -81441.6, 'agent_7': -24641.150000000005} id_=c1275a3895d448fab94be7b7419fccd3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode c1275a3895d448fab94be7b7419fccd3 NAV Verification ====================\n",
      "  agent_0 NAV: 995,102.00\n",
      "  agent_1 NAV: 974,832.00\n",
      "  agent_2 NAV: 999,120.00\n",
      "  agent_3 NAV: 1,008,816.00\n",
      "  agent_4 NAV: 1,007,098.00\n",
      "  agent_5 NAV: 1,002,088.00\n",
      "  agent_6 NAV: 1,001,556.00\n",
      "  agent_7 NAV: 1,011,388.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 7a54e80cb89347d8b94c9e46cae6782d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -11274803.050000012, 'agent_1': -19289670.54999997, 'agent_2': -9964072.300000008, 'agent_3': -7879974.049999996, 'agent_4': -32636092.149999883, 'agent_5': -13703826.34999999, 'agent_6': -12589062.949999912, 'agent_7': -24556684.799999963} id_=7a54e80cb89347d8b94c9e46cae6782d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 7a54e80cb89347d8b94c9e46cae6782d NAV Verification ====================\n",
      "  agent_0 NAV: 1,032,956.00\n",
      "  agent_1 NAV: 960,412.00\n",
      "  agent_2 NAV: 997,561.00\n",
      "  agent_3 NAV: 1,025,303.00\n",
      "  agent_4 NAV: 949,643.00\n",
      "  agent_5 NAV: 1,040,475.00\n",
      "  agent_6 NAV: 1,033,899.00\n",
      "  agent_7 NAV: 959,751.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode f5f8aafc108046e9bbaa7b893aede3cd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7368427.700000019, 'agent_1': -8035176.299999987, 'agent_2': -24215527.70000002, 'agent_3': -5568501.999999985, 'agent_4': -4186540.6000000024, 'agent_5': -15219166.249999953, 'agent_6': -14172709.54999998, 'agent_7': -64627447.29999998} id_=f5f8aafc108046e9bbaa7b893aede3cd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f5f8aafc108046e9bbaa7b893aede3cd NAV Verification ====================\n",
      "  agent_0 NAV: 980,832.00\n",
      "  agent_1 NAV: 1,072,487.00\n",
      "  agent_2 NAV: 937,538.00\n",
      "  agent_3 NAV: 1,033,326.00\n",
      "  agent_4 NAV: 1,063,357.00\n",
      "  agent_5 NAV: 1,101,844.00\n",
      "  agent_6 NAV: 970,509.00\n",
      "  agent_7 NAV: 840,107.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode a15bfebb41af43719d9b4de019630c65 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3496136.2000000025, 'agent_1': -19440700.400000025, 'agent_2': -7237967.149999994, 'agent_3': -5954288.699999979, 'agent_4': -4332043.35000002, 'agent_5': -16317162.74999999, 'agent_6': -7859791.949999975, 'agent_7': -3028677.299999997} id_=a15bfebb41af43719d9b4de019630c65)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a15bfebb41af43719d9b4de019630c65 NAV Verification ====================\n",
      "  agent_0 NAV: 998,774.00\n",
      "  agent_1 NAV: 997,326.00\n",
      "  agent_2 NAV: 993,968.00\n",
      "  agent_3 NAV: 996,996.00\n",
      "  agent_4 NAV: 1,004,617.00\n",
      "  agent_5 NAV: 999,983.00\n",
      "  agent_6 NAV: 993,048.00\n",
      "  agent_7 NAV: 1,015,288.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode ef95816bbe704f69a609bc44092b235d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -11396656.27 | Std: 1330784.62 | Threshold: -11263577.81\n",
      "Policy Returns: {'policy_0': -10484201.438888885, 'policy_2': -9379419.3962963, 'policy_6': -10767214.966666656, 'policy_7': -13295759.681481479, 'policy_1': -10957600.755555555, 'policy_4': -12329911.28703703, 'policy_5': -13306217.174074061, 'policy_3': -10652925.44074074}\n",
      "Best Trainable: policy_0 (-10484201.44)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -10484201.44\n",
      "Iteration: 7\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_4 created successfully!\n",
      "‚úì League size now: 6 (2 trainable + 4 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -73179.44999999998, 'agent_1': -202720.9, 'agent_2': -283806.39999999997, 'agent_3': -66944.45000000001, 'agent_4': -152165.60000000003, 'agent_5': -98378.09999999999, 'agent_6': -177022.95000000004, 'agent_7': -420004.25000000006} id_=ef95816bbe704f69a609bc44092b235d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ef95816bbe704f69a609bc44092b235d NAV Verification ====================\n",
      "  agent_0 NAV: 1,027,467.00\n",
      "  agent_1 NAV: 974,479.00\n",
      "  agent_2 NAV: 1,078,991.00\n",
      "  agent_3 NAV: 1,004,784.00\n",
      "  agent_4 NAV: 984,365.00\n",
      "  agent_5 NAV: 1,013,768.00\n",
      "  agent_6 NAV: 979,759.00\n",
      "  agent_7 NAV: 936,387.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 6a6e53dfc8c04e34b867a74a05c5ab76 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -12208706.09999992, 'agent_1': -12761406.449999968, 'agent_2': -6555865.650000008, 'agent_3': -19990741.75000002, 'agent_4': -9369144.950000016, 'agent_5': -16969899.750000015, 'agent_6': -35850402.15000004, 'agent_7': -10315869.799999962} id_=6a6e53dfc8c04e34b867a74a05c5ab76)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6a6e53dfc8c04e34b867a74a05c5ab76 NAV Verification ====================\n",
      "  agent_0 NAV: 1,017,010.00\n",
      "  agent_1 NAV: 996,575.00\n",
      "  agent_2 NAV: 1,007,330.00\n",
      "  agent_3 NAV: 986,900.00\n",
      "  agent_4 NAV: 1,002,696.00\n",
      "  agent_5 NAV: 1,005,086.00\n",
      "  agent_6 NAV: 934,528.00\n",
      "  agent_7 NAV: 1,049,875.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 6f1392b69c8942cb842044506302132d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6797467.849999988, 'agent_1': -7592054.200000006, 'agent_2': -8258893.800000009, 'agent_3': -3142261.3500000034, 'agent_4': -5316537.4000000255, 'agent_5': -10270371.20000002, 'agent_6': -8035608.3999999715, 'agent_7': -23085903.699999973} id_=6f1392b69c8942cb842044506302132d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6f1392b69c8942cb842044506302132d NAV Verification ====================\n",
      "  agent_0 NAV: 1,017,522.00\n",
      "  agent_1 NAV: 994,472.00\n",
      "  agent_2 NAV: 991,471.00\n",
      "  agent_3 NAV: 1,003,323.00\n",
      "  agent_4 NAV: 1,000,246.00\n",
      "  agent_5 NAV: 993,128.00\n",
      "  agent_6 NAV: 996,032.00\n",
      "  agent_7 NAV: 1,003,806.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 37f2c5ab9e2b4bc7826527b044c23773 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3403188.0499999933, 'agent_1': -5611307.70000001, 'agent_2': -7692397.550000007, 'agent_3': -5644835.299999985, 'agent_4': -8855331.049999999, 'agent_5': -9220660.849999988, 'agent_6': -6736621.650000004, 'agent_7': -5206441.449999998} id_=37f2c5ab9e2b4bc7826527b044c23773)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 37f2c5ab9e2b4bc7826527b044c23773 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,491.00\n",
      "  agent_1 NAV: 991,997.00\n",
      "  agent_2 NAV: 1,021,550.00\n",
      "  agent_3 NAV: 1,000,010.00\n",
      "  agent_4 NAV: 984,726.00\n",
      "  agent_5 NAV: 999,937.00\n",
      "  agent_6 NAV: 1,001,983.00\n",
      "  agent_7 NAV: 995,306.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 506ae16abcbf4f928e37e8d39f736c67 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -11362390.36 | Std: 1422115.62 | Threshold: -11220178.79\n",
      "Policy Returns: {'policy_0': -10027201.76290322, 'policy_2': -9259853.65161291, 'policy_6': -11659040.26935483, 'policy_7': -13786161.374193544, 'policy_1': -10922595.770967739, 'policy_4': -11882360.533870963, 'policy_5': -12974494.769354826, 'policy_3': -10387414.71935484}\n",
      "Best Trainable: policy_0 (-10027201.76)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -88818.8, 'agent_1': -193282.15000000002, 'agent_2': -999300.25, 'agent_3': -247244.99999999997, 'agent_4': -97152.54999999997, 'agent_5': -216011.55000000005, 'agent_6': -49480.950000000004, 'agent_7': -39253.45} id_=506ae16abcbf4f928e37e8d39f736c67)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 506ae16abcbf4f928e37e8d39f736c67 NAV Verification ====================\n",
      "  agent_0 NAV: 1,026,530.00\n",
      "  agent_1 NAV: 1,021,441.00\n",
      "  agent_2 NAV: 857,945.00\n",
      "  agent_3 NAV: 975,858.00\n",
      "  agent_4 NAV: 1,011,283.00\n",
      "  agent_5 NAV: 1,048,597.00\n",
      "  agent_6 NAV: 1,042,406.00\n",
      "  agent_7 NAV: 1,015,940.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode eface364d2a746a5a10142a086867c56 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7566219.949999995, 'agent_1': -8430667.250000035, 'agent_2': -18822236.149999984, 'agent_3': -11161872.299999988, 'agent_4': -4012482.299999992, 'agent_5': -14776606.849999988, 'agent_6': -16449054.349999983, 'agent_7': -14388783.850000005} id_=eface364d2a746a5a10142a086867c56)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode eface364d2a746a5a10142a086867c56 NAV Verification ====================\n",
      "  agent_0 NAV: 1,064,182.00\n",
      "  agent_1 NAV: 988,902.00\n",
      "  agent_2 NAV: 1,089,857.00\n",
      "  agent_3 NAV: 952,812.00\n",
      "  agent_4 NAV: 991,544.00\n",
      "  agent_5 NAV: 964,340.00\n",
      "  agent_6 NAV: 984,759.00\n",
      "  agent_7 NAV: 963,604.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 8bd8d2a004a444f684bbd2aa1d4d1cba Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -16087225.90000007, 'agent_1': -12415380.65000001, 'agent_2': -7760373.549999996, 'agent_3': -12242497.050000014, 'agent_4': -5865084.999999997, 'agent_5': -6326203.799999989, 'agent_6': -9199065.25000001, 'agent_7': -6757922.899999999} id_=8bd8d2a004a444f684bbd2aa1d4d1cba)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8bd8d2a004a444f684bbd2aa1d4d1cba NAV Verification ====================\n",
      "  agent_0 NAV: 986,811.00\n",
      "  agent_1 NAV: 983,370.00\n",
      "  agent_2 NAV: 989,074.00\n",
      "  agent_3 NAV: 969,333.00\n",
      "  agent_4 NAV: 1,035,862.00\n",
      "  agent_5 NAV: 999,898.00\n",
      "  agent_6 NAV: 1,004,934.00\n",
      "  agent_7 NAV: 1,030,718.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 8dd70892066c4672877974578a4aa2dc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8017314.3500000015, 'agent_1': -7852326.050000008, 'agent_2': -10192170.149999976, 'agent_3': -30623551.700000018, 'agent_4': -7060353.199999978, 'agent_5': -12787472.100000003, 'agent_6': -21423636.700000018, 'agent_7': -8177616.34999999} id_=8dd70892066c4672877974578a4aa2dc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8dd70892066c4672877974578a4aa2dc NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,794.00\n",
      "  agent_1 NAV: 986,912.00\n",
      "  agent_2 NAV: 998,844.00\n",
      "  agent_3 NAV: 957,629.00\n",
      "  agent_4 NAV: 995,350.00\n",
      "  agent_5 NAV: 1,030,756.00\n",
      "  agent_6 NAV: 1,023,219.00\n",
      "  agent_7 NAV: 1,002,496.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 30c1b40707b4483a96ac730a2608de14 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -11527027.52 | Std: 967424.53 | Threshold: -11430285.06\n",
      "Policy Returns: {'policy_0': -9989410.439999998, 'policy_2': -11321927.698571434, 'policy_6': -11843981.492857136, 'policy_7': -13162975.347142851, 'policy_1': -10806567.612857142, 'policy_4': -11180877.642857142, 'policy_5': -12761016.10857142, 'policy_3': -11149463.8}\n",
      "Best Trainable: policy_0 (-9989410.44)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -9989410.44\n",
      "Iteration: 9\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_5 created successfully!\n",
      "‚úì League size now: 7 (2 trainable + 5 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -79383.65, 'agent_1': -315775.1999999999, 'agent_2': -110659.40000000002, 'agent_3': -69837.45000000001, 'agent_4': -210933.25, 'agent_5': -123724.94999999998, 'agent_6': -306029.5, 'agent_7': -84984.30000000002} id_=30c1b40707b4483a96ac730a2608de14)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 30c1b40707b4483a96ac730a2608de14 NAV Verification ====================\n",
      "  agent_0 NAV: 1,016,140.00\n",
      "  agent_1 NAV: 964,711.00\n",
      "  agent_2 NAV: 997,025.00\n",
      "  agent_3 NAV: 1,013,294.00\n",
      "  agent_4 NAV: 986,483.00\n",
      "  agent_5 NAV: 1,030,440.00\n",
      "  agent_6 NAV: 991,304.00\n",
      "  agent_7 NAV: 1,000,603.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 9d858a593d4c4e539b06c9cdd516afb2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> champion_4\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5169894.900000011, 'agent_1': -21027250.54999996, 'agent_2': -8935143.350000003, 'agent_3': -14573357.449999992, 'agent_4': -11995467.550000029, 'agent_5': -4949898.4, 'agent_6': -8623892.750000017, 'agent_7': -4368877.349999995} id_=9d858a593d4c4e539b06c9cdd516afb2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9d858a593d4c4e539b06c9cdd516afb2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,016,423.00\n",
      "  agent_1 NAV: 969,337.00\n",
      "  agent_2 NAV: 979,678.00\n",
      "  agent_3 NAV: 1,054,966.00\n",
      "  agent_4 NAV: 986,843.00\n",
      "  agent_5 NAV: 1,000,321.00\n",
      "  agent_6 NAV: 989,706.00\n",
      "  agent_7 NAV: 1,002,726.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode a39378e2fc9946dda7f6f4d215a111af Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -12185526.55000005, 'agent_1': -8658721.049999995, 'agent_2': -8863980.299999999, 'agent_3': -3854901.8500000075, 'agent_4': -10461902.550000016, 'agent_5': -5716945.40000001, 'agent_6': -6208788.149999993, 'agent_7': -4754375.749999994} id_=a39378e2fc9946dda7f6f4d215a111af)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a39378e2fc9946dda7f6f4d215a111af NAV Verification ====================\n",
      "  agent_0 NAV: 992,261.00\n",
      "  agent_1 NAV: 1,017,636.00\n",
      "  agent_2 NAV: 997,258.00\n",
      "  agent_3 NAV: 997,282.00\n",
      "  agent_4 NAV: 1,001,129.00\n",
      "  agent_5 NAV: 1,015,547.00\n",
      "  agent_6 NAV: 985,609.00\n",
      "  agent_7 NAV: 993,278.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode f26a5560796b49618562229be1d3a738 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> champion_5\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -12951641.699999982, 'agent_1': -3791814.799999993, 'agent_2': -3563874.0499999993, 'agent_3': -5708078.200000001, 'agent_4': -10311505.400000015, 'agent_5': -10815452.699999979, 'agent_6': -14763201.25000001, 'agent_7': -11793173.800000016} id_=f26a5560796b49618562229be1d3a738)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f26a5560796b49618562229be1d3a738 NAV Verification ====================\n",
      "  agent_0 NAV: 988,265.00\n",
      "  agent_1 NAV: 1,003,656.00\n",
      "  agent_2 NAV: 1,009,727.00\n",
      "  agent_3 NAV: 998,561.00\n",
      "  agent_4 NAV: 972,413.00\n",
      "  agent_5 NAV: 1,066,879.00\n",
      "  agent_6 NAV: 997,391.00\n",
      "  agent_7 NAV: 963,108.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 6068d87f6f2f4acd84cd4beeae15285c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> champion_5\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -11267009.63 | Std: 820013.05 | Threshold: -11185008.33\n",
      "Policy Returns: {'policy_0': -9931999.001282051, 'policy_2': -10939620.993589748, 'policy_6': -11729452.62820512, 'policy_7': -12652909.512820508, 'policy_1': -10773666.934615385, 'policy_4': -11103927.384615384, 'policy_5': -12200356.080769224, 'policy_3': -10804144.517948717}\n",
      "Best Trainable: policy_0 (-9931999.00)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -44316.50000000001, 'agent_1': -239398.7, 'agent_2': -236749.09999999995, 'agent_3': -104769.60000000002, 'agent_4': -77626.04999999999, 'agent_5': -49221.3, 'agent_6': -90391.35000000002, 'agent_7': -260494.60000000003} id_=6068d87f6f2f4acd84cd4beeae15285c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6068d87f6f2f4acd84cd4beeae15285c NAV Verification ====================\n",
      "  agent_0 NAV: 1,014,799.00\n",
      "  agent_1 NAV: 979,385.00\n",
      "  agent_2 NAV: 984,556.00\n",
      "  agent_3 NAV: 992,530.00\n",
      "  agent_4 NAV: 1,027,958.00\n",
      "  agent_5 NAV: 1,014,306.00\n",
      "  agent_6 NAV: 998,658.00\n",
      "  agent_7 NAV: 987,808.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 54d2cba4f37f416aa7bd1eaf8805090c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> champion_5\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6631205.049999992, 'agent_1': -10231461.350000013, 'agent_2': -6763603.450000012, 'agent_3': -11095562.749999966, 'agent_4': -10694108.649999982, 'agent_5': -5368901.299999983, 'agent_6': -27415380.249999955, 'agent_7': -21589175.59999998} id_=54d2cba4f37f416aa7bd1eaf8805090c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 54d2cba4f37f416aa7bd1eaf8805090c NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,987.00\n",
      "  agent_1 NAV: 1,030,039.00\n",
      "  agent_2 NAV: 1,006,613.00\n",
      "  agent_3 NAV: 983,920.00\n",
      "  agent_4 NAV: 977,274.00\n",
      "  agent_5 NAV: 991,811.00\n",
      "  agent_6 NAV: 929,978.00\n",
      "  agent_7 NAV: 1,073,378.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode d08aeae1638b49bfb631a52ece9b97c8 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -10882135.599999987, 'agent_1': -14768046.100000005, 'agent_2': -5783968.65000002, 'agent_3': -6396417.89999999, 'agent_4': -3645295.3499999978, 'agent_5': -8541944.749999989, 'agent_6': -11713135.499999994, 'agent_7': -8933273.249999998} id_=d08aeae1638b49bfb631a52ece9b97c8)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode d08aeae1638b49bfb631a52ece9b97c8 NAV Verification ====================\n",
      "  agent_0 NAV: 1,020,653.00\n",
      "  agent_1 NAV: 970,144.00\n",
      "  agent_2 NAV: 1,007,996.00\n",
      "  agent_3 NAV: 993,783.00\n",
      "  agent_4 NAV: 1,019,850.00\n",
      "  agent_5 NAV: 1,011,341.00\n",
      "  agent_6 NAV: 979,233.00\n",
      "  agent_7 NAV: 997,000.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode de196d9096094ecaaa241ef68863e463 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> champion_5\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -14262334.80000004, 'agent_1': -8117456.0499999905, 'agent_2': -10764922.050000032, 'agent_3': -21918517.40000001, 'agent_4': -11636234.199999958, 'agent_5': -18891553.350000046, 'agent_6': -16505075.200000022, 'agent_7': -8173830.64999999} id_=de196d9096094ecaaa241ef68863e463)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode de196d9096094ecaaa241ef68863e463 NAV Verification ====================\n",
      "  agent_0 NAV: 1,041,045.00\n",
      "  agent_1 NAV: 1,001,131.00\n",
      "  agent_2 NAV: 983,272.00\n",
      "  agent_3 NAV: 993,964.00\n",
      "  agent_4 NAV: 1,001,123.00\n",
      "  agent_5 NAV: 962,853.00\n",
      "  agent_6 NAV: 996,613.00\n",
      "  agent_7 NAV: 1,019,999.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 38fbce92a83545dda65f5bedbc74b633 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -11249646.50 | Std: 820484.64 | Threshold: -11167598.03\n",
      "Policy Returns: {'policy_0': -9968459.059302323, 'policy_2': -10756463.600000005, 'policy_6': -12110936.465116272, 'policy_7': -12538676.326744182, 'policy_1': -10814093.784883719, 'policy_4': -10893582.161627902, 'policy_5': -12046799.26279069, 'policy_3': -10868161.311627906}\n",
      "Best Trainable: policy_0 (-9968459.06)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -9968459.06\n",
      "Iteration: 11\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_6 created successfully!\n",
      "‚úì League size now: 8 (2 trainable + 6 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -70759.09999999999, 'agent_1': -751187.7499999999, 'agent_2': -602198.6, 'agent_3': -481669.65, 'agent_4': -102861.40000000002, 'agent_5': -47950.45000000001, 'agent_6': -129747.19999999997, 'agent_7': -47632.450000000004} id_=38fbce92a83545dda65f5bedbc74b633)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 38fbce92a83545dda65f5bedbc74b633 NAV Verification ====================\n",
      "  agent_0 NAV: 1,046,329.00\n",
      "  agent_1 NAV: 931,382.00\n",
      "  agent_2 NAV: 950,294.00\n",
      "  agent_3 NAV: 948,293.00\n",
      "  agent_4 NAV: 991,580.00\n",
      "  agent_5 NAV: 1,054,678.00\n",
      "  agent_6 NAV: 1,007,487.00\n",
      "  agent_7 NAV: 1,069,957.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 0a866dd5720d4c058b860124b5aefaff Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -2875479.599999995, 'agent_1': -8326662.149999994, 'agent_2': -18371468.000000004, 'agent_3': -5540273.350000012, 'agent_4': -16966840.150000036, 'agent_5': -7839127.149999989, 'agent_6': -7214277.900000015, 'agent_7': -3733471.3999999943} id_=0a866dd5720d4c058b860124b5aefaff)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 0a866dd5720d4c058b860124b5aefaff NAV Verification ====================\n",
      "  agent_0 NAV: 1,020,776.00\n",
      "  agent_1 NAV: 990,026.00\n",
      "  agent_2 NAV: 961,884.00\n",
      "  agent_3 NAV: 1,043,597.00\n",
      "  agent_4 NAV: 975,077.00\n",
      "  agent_5 NAV: 984,939.00\n",
      "  agent_6 NAV: 1,006,281.00\n",
      "  agent_7 NAV: 1,017,420.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode edcaa600c7654c87be273c166e94030e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7618493.799999995, 'agent_1': -9355480.650000013, 'agent_2': -21749237.550000045, 'agent_3': -8866033.800000003, 'agent_4': -14924963.500000017, 'agent_5': -4604210.549999988, 'agent_6': -5313996.0000000065, 'agent_7': -11488349.650000036} id_=edcaa600c7654c87be273c166e94030e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode edcaa600c7654c87be273c166e94030e NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,036.00\n",
      "  agent_1 NAV: 1,040,820.00\n",
      "  agent_2 NAV: 977,683.00\n",
      "  agent_3 NAV: 1,034,455.00\n",
      "  agent_4 NAV: 965,298.00\n",
      "  agent_5 NAV: 987,412.00\n",
      "  agent_6 NAV: 1,014,786.00\n",
      "  agent_7 NAV: 978,510.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode fe77e314a6ad4346aa9e66138bdf8c7e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> champion_5\n",
      "  agent_7 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -24695951.49999998, 'agent_1': -15055870.900000004, 'agent_2': -3825485.4999999967, 'agent_3': -12292062.649999982, 'agent_4': -11112356.750000061, 'agent_5': -7449898.500000006, 'agent_6': -5611538.300000011, 'agent_7': -7330511.899999976} id_=fe77e314a6ad4346aa9e66138bdf8c7e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode fe77e314a6ad4346aa9e66138bdf8c7e NAV Verification ====================\n",
      "  agent_0 NAV: 957,666.00\n",
      "  agent_1 NAV: 1,037,146.00\n",
      "  agent_2 NAV: 1,016,169.00\n",
      "  agent_3 NAV: 994,480.00\n",
      "  agent_4 NAV: 977,103.00\n",
      "  agent_5 NAV: 1,015,377.00\n",
      "  agent_6 NAV: 993,060.00\n",
      "  agent_7 NAV: 1,008,999.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode ec4dd24a521e40a3a2f87f3b59fc4078 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> champion_6\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -11235738.17 | Std: 573901.27 | Threshold: -11178348.04\n",
      "Policy Returns: {'policy_0': -10020542.69255319, 'policy_2': -11247151.468085112, 'policy_6': -11609291.362765951, 'policy_7': -12131286.981914887, 'policy_1': -11079236.187234042, 'policy_4': -11245650.647872338, 'policy_5': -11583478.744680844, 'policy_3': -10969267.2893617}\n",
      "Best Trainable: policy_0 (-10020542.69)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -110770.94999999998, 'agent_1': -215837.35000000012, 'agent_2': -446490.65, 'agent_3': -116892.35000000003, 'agent_4': -194277.89999999997, 'agent_5': -142698.35000000003, 'agent_6': -333214.39999999997, 'agent_7': -146220.9500000001} id_=ec4dd24a521e40a3a2f87f3b59fc4078)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ec4dd24a521e40a3a2f87f3b59fc4078 NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,192.00\n",
      "  agent_1 NAV: 984,669.00\n",
      "  agent_2 NAV: 992,549.00\n",
      "  agent_3 NAV: 1,026,036.00\n",
      "  agent_4 NAV: 991,115.00\n",
      "  agent_5 NAV: 997,869.00\n",
      "  agent_6 NAV: 1,004,809.00\n",
      "  agent_7 NAV: 996,761.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode bbb6d558d3b44a07a7728143fc786baf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> champion_4\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3731991.4500000076, 'agent_1': -9441068.799999991, 'agent_2': -5854096.1499999855, 'agent_3': -6949408.199999984, 'agent_4': -5782189.049999999, 'agent_5': -4610267.850000009, 'agent_6': -5277530.849999992, 'agent_7': -19195127.850000057} id_=bbb6d558d3b44a07a7728143fc786baf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode bbb6d558d3b44a07a7728143fc786baf NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,357.00\n",
      "  agent_1 NAV: 979,607.00\n",
      "  agent_2 NAV: 991,168.00\n",
      "  agent_3 NAV: 1,005,910.00\n",
      "  agent_4 NAV: 998,652.00\n",
      "  agent_5 NAV: 1,033,459.00\n",
      "  agent_6 NAV: 1,007,630.00\n",
      "  agent_7 NAV: 970,217.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode fb2d3df8faaa479f9a835e979215b182 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> champion_5\n",
      "  agent_7 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3165898.2999999984, 'agent_1': -9403994.150000013, 'agent_2': -4349659.3999999985, 'agent_3': -21124825.749999918, 'agent_4': -20028276.300000034, 'agent_5': -22904193.94999999, 'agent_6': -19280730.19999999, 'agent_7': -11733529.14999996} id_=fb2d3df8faaa479f9a835e979215b182)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode fb2d3df8faaa479f9a835e979215b182 NAV Verification ====================\n",
      "  agent_0 NAV: 1,007,971.00\n",
      "  agent_1 NAV: 1,006,406.00\n",
      "  agent_2 NAV: 1,008,004.00\n",
      "  agent_3 NAV: 998,281.00\n",
      "  agent_4 NAV: 1,013,632.00\n",
      "  agent_5 NAV: 973,667.00\n",
      "  agent_6 NAV: 985,641.00\n",
      "  agent_7 NAV: 1,006,398.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode c4f36500fd0e4ed29ecffddb1c78b347 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4334887.649999989, 'agent_1': -6825418.500000018, 'agent_2': -24126626.50000001, 'agent_3': -13730931.000000037, 'agent_4': -13291585.65000003, 'agent_5': -8182429.999999982, 'agent_6': -8996852.349999964, 'agent_7': -5613120.249999992} id_=c4f36500fd0e4ed29ecffddb1c78b347)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode c4f36500fd0e4ed29ecffddb1c78b347 NAV Verification ====================\n",
      "  agent_0 NAV: 1,019,050.00\n",
      "  agent_1 NAV: 1,020,034.00\n",
      "  agent_2 NAV: 937,782.00\n",
      "  agent_3 NAV: 978,354.00\n",
      "  agent_4 NAV: 976,614.00\n",
      "  agent_5 NAV: 1,037,962.00\n",
      "  agent_6 NAV: 979,330.00\n",
      "  agent_7 NAV: 1,050,874.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 69fc8c1a05b3499ea0377317160a471a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -11215171.97 | Std: 716885.54 | Threshold: -11143483.41\n",
      "Policy Returns: {'policy_0': -9533709.161764704, 'policy_2': -11392580.051960789, 'policy_6': -11869455.676470589, 'policy_7': -12028190.49313725, 'policy_1': -10947623.199019605, 'policy_4': -11307401.524509804, 'policy_5': -11495773.082352934, 'policy_3': -11146642.536274506}\n",
      "Best Trainable: policy_0 (-9533709.16)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -9533709.16\n",
      "Iteration: 13\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_7 created successfully!\n",
      "‚úì League size now: 9 (2 trainable + 7 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -156106.25000000006, 'agent_1': -56353.2, 'agent_2': -231017.6000000001, 'agent_3': -139707.60000000003, 'agent_4': -267438.1000000001, 'agent_5': -27739.249999999996, 'agent_6': -195840.05000000002, 'agent_7': -294701.75000000006} id_=69fc8c1a05b3499ea0377317160a471a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 69fc8c1a05b3499ea0377317160a471a NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,987.00\n",
      "  agent_1 NAV: 996,199.00\n",
      "  agent_2 NAV: 981,409.00\n",
      "  agent_3 NAV: 995,226.00\n",
      "  agent_4 NAV: 981,391.00\n",
      "  agent_5 NAV: 1,010,130.00\n",
      "  agent_6 NAV: 993,393.00\n",
      "  agent_7 NAV: 1,030,265.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode d06303eaa5d84de7baefa96dd6e9de3b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -21193704.899999943, 'agent_1': -7160965.400000014, 'agent_2': -5517382.300000001, 'agent_3': -8369503.999999983, 'agent_4': -21438303.29999999, 'agent_5': -8758003.700000012, 'agent_6': -4573364.050000013, 'agent_7': -5103889.650000007} id_=d06303eaa5d84de7baefa96dd6e9de3b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode d06303eaa5d84de7baefa96dd6e9de3b NAV Verification ====================\n",
      "  agent_0 NAV: 989,968.00\n",
      "  agent_1 NAV: 1,018,136.00\n",
      "  agent_2 NAV: 1,029,969.00\n",
      "  agent_3 NAV: 999,115.00\n",
      "  agent_4 NAV: 968,009.00\n",
      "  agent_5 NAV: 987,552.00\n",
      "  agent_6 NAV: 1,015,765.00\n",
      "  agent_7 NAV: 991,486.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode b35909747e8c4b39b33926d337cd7470 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4841493.299999994, 'agent_1': -11888073.499999989, 'agent_2': -10596935.350000033, 'agent_3': -9863825.599999983, 'agent_4': -2201399.0500000035, 'agent_5': -10233311.200000018, 'agent_6': -17537385.799999982, 'agent_7': -6299723.600000008} id_=b35909747e8c4b39b33926d337cd7470)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode b35909747e8c4b39b33926d337cd7470 NAV Verification ====================\n",
      "  agent_0 NAV: 1,014,390.00\n",
      "  agent_1 NAV: 974,247.00\n",
      "  agent_2 NAV: 1,021,224.00\n",
      "  agent_3 NAV: 993,463.00\n",
      "  agent_4 NAV: 1,021,478.00\n",
      "  agent_5 NAV: 982,332.00\n",
      "  agent_6 NAV: 989,567.00\n",
      "  agent_7 NAV: 1,003,299.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode fa3f8c060d554813afcc31b9dd338779 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -9252904.04999998, 'agent_1': -9139893.99999998, 'agent_2': -11330631.700000007, 'agent_3': -2969602.399999992, 'agent_4': -11432453.649999985, 'agent_5': -5081039.300000001, 'agent_6': -9538837.15000001, 'agent_7': -12495184.94999999} id_=fa3f8c060d554813afcc31b9dd338779)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode fa3f8c060d554813afcc31b9dd338779 NAV Verification ====================\n",
      "  agent_0 NAV: 979,335.00\n",
      "  agent_1 NAV: 1,027,460.00\n",
      "  agent_2 NAV: 992,747.00\n",
      "  agent_3 NAV: 1,004,822.00\n",
      "  agent_4 NAV: 979,532.00\n",
      "  agent_5 NAV: 1,016,218.00\n",
      "  agent_6 NAV: 1,017,088.00\n",
      "  agent_7 NAV: 982,798.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 1b668c908df041fb8417429a3163e7dd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> champion_5\n",
      "  agent_6 -> champion_6\n",
      "  agent_7 -> champion_7\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -11069043.65 | Std: 639335.38 | Threshold: -11005110.11\n",
      "Policy Returns: {'policy_0': -9602516.374545451, 'policy_2': -11294364.384545458, 'policy_6': -11674836.535454547, 'policy_7': -11785400.660909086, 'policy_1': -10736350.538181813, 'policy_4': -11311455.839090906, 'policy_5': -11170876.79454545, 'policy_3': -10976548.07454545}\n",
      "Best Trainable: policy_0 (-9602516.37)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -16719.249999999996, 'agent_1': -903054.4500000001, 'agent_2': -366307.10000000003, 'agent_3': -59647.15000000002, 'agent_4': -1276270.1500000001, 'agent_5': -93945.60000000003, 'agent_6': -56106.10000000001, 'agent_7': -68163.80000000002} id_=1b668c908df041fb8417429a3163e7dd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 1b668c908df041fb8417429a3163e7dd NAV Verification ====================\n",
      "  agent_0 NAV: 1,045,175.00\n",
      "  agent_1 NAV: 924,841.00\n",
      "  agent_2 NAV: 970,802.00\n",
      "  agent_3 NAV: 1,013,948.00\n",
      "  agent_4 NAV: 893,369.00\n",
      "  agent_5 NAV: 1,006,970.00\n",
      "  agent_6 NAV: 1,094,950.00\n",
      "  agent_7 NAV: 1,049,945.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 056e4c1b9fb444ea972022f089a0c82d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5641744.950000004, 'agent_1': -7467159.249999985, 'agent_2': -11517452.700000018, 'agent_3': -6540330.449999999, 'agent_4': -4620544.149999988, 'agent_5': -4490007.849999999, 'agent_6': -12023832.30000003, 'agent_7': -14444815.249999993} id_=056e4c1b9fb444ea972022f089a0c82d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 056e4c1b9fb444ea972022f089a0c82d NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,379.00\n",
      "  agent_1 NAV: 1,011,468.00\n",
      "  agent_2 NAV: 1,003,022.00\n",
      "  agent_3 NAV: 1,017,079.00\n",
      "  agent_4 NAV: 996,159.00\n",
      "  agent_5 NAV: 1,005,990.00\n",
      "  agent_6 NAV: 993,677.00\n",
      "  agent_7 NAV: 968,226.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode f5ec93f13255426483f137408c757b40 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> champion_5\n",
      "  agent_5 -> champion_6\n",
      "  agent_6 -> champion_7\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5810832.800000012, 'agent_1': -11784686.499999994, 'agent_2': -26062769.649999984, 'agent_3': -20032500.300000012, 'agent_4': -4144729.6999999736, 'agent_5': -3881292.649999996, 'agent_6': -5057455.499999984, 'agent_7': -2342873.1999999983} id_=f5ec93f13255426483f137408c757b40)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f5ec93f13255426483f137408c757b40 NAV Verification ====================\n",
      "  agent_0 NAV: 1,029,388.00\n",
      "  agent_1 NAV: 1,025,875.00\n",
      "  agent_2 NAV: 958,582.00\n",
      "  agent_3 NAV: 965,409.00\n",
      "  agent_4 NAV: 1,003,456.00\n",
      "  agent_5 NAV: 1,004,012.00\n",
      "  agent_6 NAV: 999,899.00\n",
      "  agent_7 NAV: 1,013,379.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 72170b38d9e443fa921c592821378b23 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -16268771.199999979, 'agent_1': -5435247.800000002, 'agent_2': -8470588.349999994, 'agent_3': -5011991.950000003, 'agent_4': -7638371.550000003, 'agent_5': -10665102.149999991, 'agent_6': -4361563.449999994, 'agent_7': -22512129.650000006} id_=72170b38d9e443fa921c592821378b23)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 72170b38d9e443fa921c592821378b23 NAV Verification ====================\n",
      "  agent_0 NAV: 1,062,945.00\n",
      "  agent_1 NAV: 1,016,958.00\n",
      "  agent_2 NAV: 990,594.00\n",
      "  agent_3 NAV: 1,013,877.00\n",
      "  agent_4 NAV: 1,007,255.00\n",
      "  agent_5 NAV: 967,956.00\n",
      "  agent_6 NAV: 1,001,402.00\n",
      "  agent_7 NAV: 939,013.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode da5162219b6c4537a2118f58404ed148 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -11067068.67 | Std: 681038.09 | Threshold: -10998964.86\n",
      "Policy Returns: {'policy_0': -9473977.072033891, 'policy_2': -11591312.066949159, 'policy_6': -11393997.36694915, 'policy_7': -11742743.029661013, 'policy_1': -11086630.85932203, 'policy_4': -11552379.556779653, 'policy_5': -10814541.322033891, 'policy_3': -10880968.063559318}\n",
      "Best Trainable: policy_0 (-9473977.07)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -9473977.07\n",
      "Iteration: 15\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_8 created successfully!\n",
      "‚úì League size now: 10 (2 trainable + 8 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -196239.0000000001, 'agent_1': -170884.79999999996, 'agent_2': -216641.15000000005, 'agent_3': -70529.49999999999, 'agent_4': -172638.99999999988, 'agent_5': -136447.25000000006, 'agent_6': -240416.15000000008, 'agent_7': -97112.25000000001} id_=da5162219b6c4537a2118f58404ed148)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode da5162219b6c4537a2118f58404ed148 NAV Verification ====================\n",
      "  agent_0 NAV: 999,806.00\n",
      "  agent_1 NAV: 991,487.00\n",
      "  agent_2 NAV: 991,503.00\n",
      "  agent_3 NAV: 1,011,648.00\n",
      "  agent_4 NAV: 1,016,915.00\n",
      "  agent_5 NAV: 1,001,587.00\n",
      "  agent_6 NAV: 980,846.00\n",
      "  agent_7 NAV: 1,006,208.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 8af00bba9b1f4634b92f44d60a3fcfff Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -11096846.350000022, 'agent_1': -12465917.95000001, 'agent_2': -8240259.399999986, 'agent_3': -8728478.49999999, 'agent_4': -4849217.949999989, 'agent_5': -4272781.249999995, 'agent_6': -16965871.04999999, 'agent_7': -8625526.649999991} id_=8af00bba9b1f4634b92f44d60a3fcfff)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8af00bba9b1f4634b92f44d60a3fcfff NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,539.00\n",
      "  agent_1 NAV: 980,933.00\n",
      "  agent_2 NAV: 1,009,121.00\n",
      "  agent_3 NAV: 996,212.00\n",
      "  agent_4 NAV: 1,002,208.00\n",
      "  agent_5 NAV: 1,006,788.00\n",
      "  agent_6 NAV: 1,005,781.00\n",
      "  agent_7 NAV: 995,418.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode f0d2d3df02364101a0634ddcb1786cc6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7651731.8500000015, 'agent_1': -5411872.750000008, 'agent_2': -8842872.899999995, 'agent_3': -9530988.150000012, 'agent_4': -11501649.249999937, 'agent_5': -6821519.8999999985, 'agent_6': -4133466.849999989, 'agent_7': -7089829.349999995} id_=f0d2d3df02364101a0634ddcb1786cc6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f0d2d3df02364101a0634ddcb1786cc6 NAV Verification ====================\n",
      "  agent_0 NAV: 986,712.00\n",
      "  agent_1 NAV: 1,007,909.00\n",
      "  agent_2 NAV: 984,459.00\n",
      "  agent_3 NAV: 1,031,778.00\n",
      "  agent_4 NAV: 978,094.00\n",
      "  agent_5 NAV: 1,012,565.00\n",
      "  agent_6 NAV: 1,005,359.00\n",
      "  agent_7 NAV: 993,124.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode b10977a44dc1406c90a08ff096174480 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_8\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3082994.8999999915, 'agent_1': -5502613.800000011, 'agent_2': -20985849.65000001, 'agent_3': -9189732.950000035, 'agent_4': -5532297.699999996, 'agent_5': -4783770.849999998, 'agent_6': -18576241.650000058, 'agent_7': -6731162.700000002} id_=b10977a44dc1406c90a08ff096174480)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode b10977a44dc1406c90a08ff096174480 NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,112.00\n",
      "  agent_1 NAV: 1,018,806.00\n",
      "  agent_2 NAV: 968,701.00\n",
      "  agent_3 NAV: 991,488.00\n",
      "  agent_4 NAV: 1,021,329.00\n",
      "  agent_5 NAV: 1,026,345.00\n",
      "  agent_6 NAV: 969,626.00\n",
      "  agent_7 NAV: 990,593.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "Episode 39b25e692c4d453d95d523cb9b51a591 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> champion_6\n",
      "  agent_5 -> champion_7\n",
      "  agent_6 -> champion_8\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -10878342.76 | Std: 693938.03 | Threshold: -10808948.96\n",
      "Policy Returns: {'policy_0': -9324554.81666666, 'policy_2': -11580484.414285721, 'policy_6': -11440276.37142857, 'policy_7': -11411826.996031743, 'policy_1': -10879244.44126984, 'policy_4': -11241853.711111102, 'policy_5': -10456606.78492063, 'policy_3': -10691894.570634918}\n",
      "Best Trainable: policy_0 (-9324554.82)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ‚Üê KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-25 17:21:45\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Get current time in SGT (Singapore Time)\n",
    "sgt_time = datetime.now(ZoneInfo(\"Asia/Singapore\"))\n",
    "formatted_datetime = sgt_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
