{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with naive competitive self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"‚ùå No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 03:47:43,041\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-23 03:47:44,388\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_1', 'agent_3', 'agent_2', 'agent_0']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 03:47:46,793\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.77gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-12-23 03:47:47,947\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"d7e30dac-fce0-4870-a4fe-7dae7ffd2b3a\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 4\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x7cbe409a7af0>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x7cbe409a7a90>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x7cbe409a7a30>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x7cbe409a7ca0>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=2,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ‚Üê ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 03:47:48,315\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2025-12-23 03:47:48,317\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 4096\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-12-23 03:47:48,579\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-23 03:47:48,590\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2025-12-23 03:47:48,599\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-23 03:47:48,620\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2025-12-23 03:47:48,629\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2025-12-23 03:47:48,640\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2025-12-23 03:47:48,642\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-12-23 03:47:48,679\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,679\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,680\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,680\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,680\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,695\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,695\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2025-12-23 03:47:48,696\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32)), Dict('agent_0': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_1': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_2': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)), 'agent_3': Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)))), 'policy_0': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_1': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_2': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12))), 'policy_3': (Box(-inf, inf, (40,), float32), Tuple(Discrete(3), Discrete(4), Box(-1.0, 1.0, (1,), float32), Box(0.0, 1.0, (1,), float32), Discrete(12)))}\n",
      "2025-12-23 03:47:48,740\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:48,741\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:48,750\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:48,759\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:48,769\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:48,777\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:48,787\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:50,467\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2025-12-23 03:47:50,500\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 4096\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 6a620b94f12a43279a1986c5852ae4de Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -6318016551.939322, 'agent_1': -16057134140.500809, 'agent_2': -2197591778.889251, 'agent_3': -10876421462.939863} id_=6a620b94f12a43279a1986c5852ae4de)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6a620b94f12a43279a1986c5852ae4de NAV Verification ====================\n",
      "  agent_0 NAV: 2,353,799.00\n",
      "  agent_1 NAV: -1,463,303.00\n",
      "  agent_2 NAV: 1,195,660.00\n",
      "  agent_3 NAV: 1,913,844.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode d8a337c7f3a142d4a02e371efa0e2553 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -3075010676.502483, 'agent_1': -11895672607.04215, 'agent_2': -1731771762.595011, 'agent_3': -6897452188.844903} id_=d8a337c7f3a142d4a02e371efa0e2553)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d8a337c7f3a142d4a02e371efa0e2553 NAV Verification ====================\n",
      "  agent_0 NAV: 1,078,066.00\n",
      "  agent_1 NAV: 1,201,424.00\n",
      "  agent_2 NAV: 2,555,262.00\n",
      "  agent_3 NAV: -834,752.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 59e26b71502f406ebc0ec7bc74a6628b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -17117368788.27504, 'agent_1': -19535030932.303135, 'agent_2': -10215327276.864433, 'agent_3': -13317407973.77387} id_=59e26b71502f406ebc0ec7bc74a6628b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 59e26b71502f406ebc0ec7bc74a6628b NAV Verification ====================\n",
      "  agent_0 NAV: 969,260.00\n",
      "  agent_1 NAV: 1,279,615.00\n",
      "  agent_2 NAV: 1,649,305.00\n",
      "  agent_3 NAV: 101,820.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 3e8f232d8d49433298f40e20e5314ad9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -9936183845.04 | Std: 3980636874.82 | Threshold: -9538120157.56\n",
      "Policy Returns: {'policy_2': -4714896939.449565, 'policy_0': -8836798672.238947, 'policy_1': -15829279226.615366, 'policy_3': -10363760541.85288}\n",
      "Best Trainable: policy_0 (-8836798672.24)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -8836798672.24\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_1 created successfully!\n",
      "‚úì League size now: 3 (2 trainable + 1 champions)\n",
      "‚úì Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': 0.0, 'agent_1': 0.0, 'agent_2': 0.0, 'agent_3': 0.0} id_=3e8f232d8d49433298f40e20e5314ad9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3e8f232d8d49433298f40e20e5314ad9 NAV Verification ====================\n",
      "  agent_0 NAV: 3,357,905.00\n",
      "  agent_1 NAV: 979,537.00\n",
      "  agent_2 NAV: -1,124,205.00\n",
      "  agent_3 NAV: 786,763.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 5b2c5c1411ca439ebc350b24a5537fc3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -11624908506.908806, 'agent_1': -9282823452.80788, 'agent_2': -4589574511.197767, 'agent_3': -2399389884.2767963} id_=5b2c5c1411ca439ebc350b24a5537fc3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5b2c5c1411ca439ebc350b24a5537fc3 NAV Verification ====================\n",
      "  agent_0 NAV: 1,597,704.00\n",
      "  agent_1 NAV: 28,200.00\n",
      "  agent_2 NAV: 2,694,488.00\n",
      "  agent_3 NAV: -320,392.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 81da6587170f480cb2ef0f2705f75cb7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -24770655794.24026, 'agent_1': -18875409882.08173, 'agent_2': -3715583856.645576, 'agent_3': -3485262798.047252} id_=81da6587170f480cb2ef0f2705f75cb7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 81da6587170f480cb2ef0f2705f75cb7 NAV Verification ====================\n",
      "  agent_0 NAV: 873,573.00\n",
      "  agent_1 NAV: 727,407.00\n",
      "  agent_2 NAV: 2,383,635.00\n",
      "  agent_3 NAV: 15,385.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode e803464321a84680ad86dfa16ad46873 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -16942370004.193659, 'agent_1': -11885208258.006277, 'agent_2': -2146581763.8743744, 'agent_3': -2479281562.307083} id_=e803464321a84680ad86dfa16ad46873)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e803464321a84680ad86dfa16ad46873 NAV Verification ====================\n",
      "  agent_0 NAV: 1,440,619.00\n",
      "  agent_1 NAV: 555,190.00\n",
      "  agent_2 NAV: 348,175.00\n",
      "  agent_3 NAV: 1,656,016.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 7f1a1319b84e43b3b3869455e5e8e779 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=947 done=True Rs={'agent_0': -24583538228.522728, 'agent_1': -8091709342.452362, 'agent_2': -7528570254.136685, 'agent_3': -8227147590.371773} id_=7f1a1319b84e43b3b3869455e5e8e779)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7f1a1319b84e43b3b3869455e5e8e779 NAV Verification ====================\n",
      "  agent_0 NAV: -236,053.00\n",
      "  agent_1 NAV: 3,660,887.00\n",
      "  agent_2 NAV: 232,291.00\n",
      "  agent_3 NAV: 342,875.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6976c1455b8f46f09a2fcb4447be01ae Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -10219692921.87 | Std: 4426691675.67 | Threshold: -9777023754.30\n",
      "Policy Returns: {'policy_2': -5058417258.787683, 'policy_0': -15340241562.00039, 'policy_1': -13812365390.74155, 'policy_3': -6667747475.936238}\n",
      "Best Trainable: policy_1 (-13812365390.74)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=955 done=True Rs={'agent_0': -943381714.914574, 'agent_1': -15360549296.028996, 'agent_2': -8437369989.5022545, 'agent_3': -2221125635.837766} id_=6976c1455b8f46f09a2fcb4447be01ae)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6976c1455b8f46f09a2fcb4447be01ae NAV Verification ====================\n",
      "  agent_0 NAV: 416,097.00\n",
      "  agent_1 NAV: -2,090,702.00\n",
      "  agent_2 NAV: 4,725,495.00\n",
      "  agent_3 NAV: 949,110.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 749f776ec23a4cacbeb6f5d5aab5c10e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -14069075344.983208, 'agent_1': -6325111549.195008, 'agent_2': -4917958746.719698, 'agent_3': -7460053027.228603} id_=749f776ec23a4cacbeb6f5d5aab5c10e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 749f776ec23a4cacbeb6f5d5aab5c10e NAV Verification ====================\n",
      "  agent_0 NAV: 8,225,500.00\n",
      "  agent_1 NAV: -1,661,446.00\n",
      "  agent_2 NAV: -516,197.00\n",
      "  agent_3 NAV: -2,047,857.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 86181ca5c180451688ddcf9c2e539100 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -10776994661.031923, 'agent_1': -15797373504.021576, 'agent_2': -2063844616.286788, 'agent_3': -2440206312.1265287} id_=86181ca5c180451688ddcf9c2e539100)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 86181ca5c180451688ddcf9c2e539100 NAV Verification ====================\n",
      "  agent_0 NAV: 781,120.00\n",
      "  agent_1 NAV: 1,934,819.00\n",
      "  agent_2 NAV: 1,420,860.00\n",
      "  agent_3 NAV: -136,799.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 725baee8cac34a9f9500036c64d97582 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -4504033737.229478, 'agent_1': -8596227338.943705, 'agent_2': -8582067791.877298, 'agent_3': -5632888130.382006} id_=725baee8cac34a9f9500036c64d97582)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 725baee8cac34a9f9500036c64d97582 NAV Verification ====================\n",
      "  agent_0 NAV: -454,513.00\n",
      "  agent_1 NAV: -184,804.00\n",
      "  agent_2 NAV: 2,391,013.00\n",
      "  agent_3 NAV: 2,248,304.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode bf844c3ffc5d4163877ccabb485a5dea Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -9274926962.52 | Std: 3632126848.08 | Threshold: -8911714277.71\n",
      "Policy Returns: {'policy_2': -5373685856.652463, 'policy_0': -12751980547.68155, 'policy_1': -13048609584.283949, 'policy_3': -5925431861.44548}\n",
      "Best Trainable: policy_0 (-12751980547.68)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=959 done=True Rs={'agent_0': -4871896656.380844, 'agent_1': -12898563300.466259, 'agent_2': -1752521031.3048513, 'agent_3': -8698052493.323053} id_=bf844c3ffc5d4163877ccabb485a5dea)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bf844c3ffc5d4163877ccabb485a5dea NAV Verification ====================\n",
      "  agent_0 NAV: 1,292,142.00\n",
      "  agent_1 NAV: 875,330.00\n",
      "  agent_2 NAV: 1,634,066.00\n",
      "  agent_3 NAV: 198,462.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 8ce2dae62cdf4a22bb5b558078410f87 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -6036130666.775601, 'agent_1': -7537515848.283432, 'agent_2': -2650908231.963224, 'agent_3': -1606500376.948159} id_=8ce2dae62cdf4a22bb5b558078410f87)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8ce2dae62cdf4a22bb5b558078410f87 NAV Verification ====================\n",
      "  agent_0 NAV: 984,395.00\n",
      "  agent_1 NAV: -686,495.00\n",
      "  agent_2 NAV: -367,565.00\n",
      "  agent_3 NAV: 4,069,665.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 0d05d7ad07e749ee877bfbdb2fae07c4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1797767791.4220052, 'agent_1': -14966956992.821003, 'agent_2': -4707573596.933738, 'agent_3': -7372437446.647968} id_=0d05d7ad07e749ee877bfbdb2fae07c4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 0d05d7ad07e749ee877bfbdb2fae07c4 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,158.00\n",
      "  agent_1 NAV: -5,084,748.00\n",
      "  agent_2 NAV: 3,408,486.00\n",
      "  agent_3 NAV: 4,675,104.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode be653e20796e47148088dafb2b866276 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -7694888898.668113, 'agent_1': -21470280451.809, 'agent_2': -5419703772.985795, 'agent_3': -7203480015.058077} id_=be653e20796e47148088dafb2b866276)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode be653e20796e47148088dafb2b866276 NAV Verification ====================\n",
      "  agent_0 NAV: 1,515,369.00\n",
      "  agent_1 NAV: 301,488.00\n",
      "  agent_2 NAV: 1,109,490.00\n",
      "  agent_3 NAV: 1,073,653.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 904ddb16da0344289f24833b3971681b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -8779673647.59 | Std: 3447373683.87 | Threshold: -8434936279.20\n",
      "Policy Returns: {'policy_2': -4938696131.715397, 'policy_0': -10839108052.580555, 'policy_1': -13341699415.892319, 'policy_3': -5999190990.161005}\n",
      "Best Trainable: policy_0 (-10839108052.58)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=963 done=True Rs={'agent_0': -8023751841.998598, 'agent_1': -3916967636.401315, 'agent_2': -4232293846.712496, 'agent_3': -11416225007.752308} id_=904ddb16da0344289f24833b3971681b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 904ddb16da0344289f24833b3971681b NAV Verification ====================\n",
      "  agent_0 NAV: -230,122.00\n",
      "  agent_1 NAV: 1,692,608.00\n",
      "  agent_2 NAV: 1,810,215.00\n",
      "  agent_3 NAV: 727,299.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 428e06f1e57e47b0a321bafdafef06dd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -3487173750.8627853, 'agent_1': -8488805777.070606, 'agent_2': -1118884966.7210553, 'agent_3': -2557376856.506228} id_=428e06f1e57e47b0a321bafdafef06dd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 428e06f1e57e47b0a321bafdafef06dd NAV Verification ====================\n",
      "  agent_0 NAV: 726,763.00\n",
      "  agent_1 NAV: -652,451.00\n",
      "  agent_2 NAV: 2,119,749.00\n",
      "  agent_3 NAV: 1,805,939.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 49ac64f0d74c4d09a7f9dab34e18b15c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=866 done=True Rs={'agent_0': -4940367458.06128, 'agent_1': -14358682066.550797, 'agent_2': -10884206615.02474, 'agent_3': -2279820727.5376425} id_=49ac64f0d74c4d09a7f9dab34e18b15c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 49ac64f0d74c4d09a7f9dab34e18b15c NAV Verification ====================\n",
      "  agent_0 NAV: -82,083.00\n",
      "  agent_1 NAV: 2,786,577.00\n",
      "  agent_2 NAV: -1,129,432.00\n",
      "  agent_3 NAV: 2,424,938.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 60ba3b8a92fe4c6bbcba4a82965fb10f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -6094009891.488638, 'agent_1': -16604508727.39611, 'agent_2': -3140688362.5354567, 'agent_3': -4972887987.468768} id_=60ba3b8a92fe4c6bbcba4a82965fb10f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 60ba3b8a92fe4c6bbcba4a82965fb10f NAV Verification ====================\n",
      "  agent_0 NAV: 525,260.00\n",
      "  agent_1 NAV: 2,330,368.00\n",
      "  agent_2 NAV: -376,237.00\n",
      "  agent_3 NAV: 1,520,609.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 8446d86ec2a74a2d8adb62f863132999 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -8355368581.82 | Std: 3171674024.69 | Threshold: -8038201179.35\n",
      "Policy Returns: {'policy_2': -4919904030.05387, 'policy_0': -9798855855.31497, 'policy_1': -12841916312.413675, 'policy_3': -5860798129.501031}\n",
      "Best Trainable: policy_0 (-9798855855.31)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=808 done=True Rs={'agent_0': -3133719015.284114, 'agent_1': -3579228978.108181, 'agent_2': -4257400468.413318, 'agent_3': -4134540825.181798} id_=8446d86ec2a74a2d8adb62f863132999)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8446d86ec2a74a2d8adb62f863132999 NAV Verification ====================\n",
      "  agent_0 NAV: 399,735.00\n",
      "  agent_1 NAV: 695,274.00\n",
      "  agent_2 NAV: 1,263,471.00\n",
      "  agent_3 NAV: 1,641,520.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6faa68f9d0dc4728be9dc0c784048397 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -4083724605.5736985, 'agent_1': -17607030414.041183, 'agent_2': -4196332455.515366, 'agent_3': -15605416889.727703} id_=6faa68f9d0dc4728be9dc0c784048397)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6faa68f9d0dc4728be9dc0c784048397 NAV Verification ====================\n",
      "  agent_0 NAV: 1,371,886.00\n",
      "  agent_1 NAV: -2,469,389.00\n",
      "  agent_2 NAV: 1,941,164.00\n",
      "  agent_3 NAV: 3,156,339.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 99060bcd2d2743a08440662156c4a56c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=428 done=True Rs={'agent_0': -1367167926.089426, 'agent_1': -2897846477.5358534, 'agent_2': -1306980881.3963, 'agent_3': -2109192366.2620318} id_=99060bcd2d2743a08440662156c4a56c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 99060bcd2d2743a08440662156c4a56c NAV Verification ====================\n",
      "  agent_0 NAV: -284,173.00\n",
      "  agent_1 NAV: 2,415,465.00\n",
      "  agent_2 NAV: 1,335,303.00\n",
      "  agent_3 NAV: 533,405.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode a03e524ca88a420fa10e3c09fc7e829d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -835484728.9846066, 'agent_1': -4047937509.123317, 'agent_2': -8882112493.081104, 'agent_3': -3029313800.3203216} id_=a03e524ca88a420fa10e3c09fc7e829d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a03e524ca88a420fa10e3c09fc7e829d NAV Verification ====================\n",
      "  agent_0 NAV: 2,854,908.00\n",
      "  agent_1 NAV: 724,687.00\n",
      "  agent_2 NAV: -251,346.00\n",
      "  agent_3 NAV: 671,751.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 5f07cdfc57d546b2a4e6198b75c344a4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=456 done=True Rs={'agent_0': -2136717149.2706466, 'agent_1': -2173328621.22226, 'agent_2': -2126029117.2411513, 'agent_3': -1779429731.1841838} id_=5f07cdfc57d546b2a4e6198b75c344a4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5f07cdfc57d546b2a4e6198b75c344a4 NAV Verification ====================\n",
      "  agent_0 NAV: -1,097,399.00\n",
      "  agent_1 NAV: 2,448,125.00\n",
      "  agent_2 NAV: -235,324.00\n",
      "  agent_3 NAV: 2,884,598.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 093b108c9aaa49bba5a2fc6ae4d0dcad Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -7582002578.17 | Std: 2596932114.84 | Threshold: -7322309366.68\n",
      "Policy Returns: {'policy_2': -4775797503.077371, 'policy_0': -8303772983.955555, 'policy_1': -11488487031.035704, 'policy_3': -5759952794.596816}\n",
      "Best Trainable: policy_0 (-8303772983.96)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=671 done=True Rs={'agent_0': -8512487889.612001, 'agent_1': -7481873647.571704, 'agent_2': -3953289307.978775, 'agent_3': -3193671477.1523337} id_=093b108c9aaa49bba5a2fc6ae4d0dcad)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 093b108c9aaa49bba5a2fc6ae4d0dcad NAV Verification ====================\n",
      "  agent_0 NAV: 1,343,602.00\n",
      "  agent_1 NAV: 362,073.00\n",
      "  agent_2 NAV: -1,470,577.00\n",
      "  agent_3 NAV: 3,764,902.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode d735e093335149abb2ac6957c999c26d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -5153256004.9468155, 'agent_1': -11679171710.287464, 'agent_2': -4214676046.8085027, 'agent_3': -9616152636.431255} id_=d735e093335149abb2ac6957c999c26d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d735e093335149abb2ac6957c999c26d NAV Verification ====================\n",
      "  agent_0 NAV: 417,895.00\n",
      "  agent_1 NAV: -1,172,541.00\n",
      "  agent_2 NAV: 36,541.00\n",
      "  agent_3 NAV: 4,718,105.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode ce476a580c524aa6b2a199c8cf75aaf4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1654834913.9270804, 'agent_1': -7855834330.579777, 'agent_2': -8966292269.826012, 'agent_3': -1593635106.871932} id_=ce476a580c524aa6b2a199c8cf75aaf4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ce476a580c524aa6b2a199c8cf75aaf4 NAV Verification ====================\n",
      "  agent_0 NAV: 1,120,606.00\n",
      "  agent_1 NAV: 598,956.00\n",
      "  agent_2 NAV: 1,476,552.00\n",
      "  agent_3 NAV: 803,886.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode eb443a24e41b47b68dc3b006938c0d4a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -689934013.4145006, 'agent_1': -7640388277.641943, 'agent_2': -7335636184.779612, 'agent_3': -915992597.814795} id_=eb443a24e41b47b68dc3b006938c0d4a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode eb443a24e41b47b68dc3b006938c0d4a NAV Verification ====================\n",
      "  agent_0 NAV: 402,167.00\n",
      "  agent_1 NAV: -1,170,178.00\n",
      "  agent_2 NAV: 4,850,751.00\n",
      "  agent_3 NAV: -82,740.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode a2fbb3c5035848b6be4df4cf65771230 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -7338975175.22 | Std: 2424556995.70 | Threshold: -7096519475.65\n",
      "Policy Returns: {'policy_2': -4968165877.718356, 'policy_0': -7732938962.335726, 'policy_1': -11136668585.309752, 'policy_3': -5518127275.509943}\n",
      "Best Trainable: policy_0 (-7732938962.34)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=675 done=True Rs={'agent_0': -1437918447.2851713, 'agent_1': -17814282631.39009, 'agent_2': -7560270400.770476, 'agent_3': -11822075739.068674} id_=a2fbb3c5035848b6be4df4cf65771230)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a2fbb3c5035848b6be4df4cf65771230 NAV Verification ====================\n",
      "  agent_0 NAV: 1,176,319.00\n",
      "  agent_1 NAV: 938,761.00\n",
      "  agent_2 NAV: 685,228.00\n",
      "  agent_3 NAV: 1,199,692.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode df4d0f3a526e49e38bf3170fe2ffba72 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1611648962.7301285, 'agent_1': -4657312877.63527, 'agent_2': -10935712807.502962, 'agent_3': -5786755547.388237} id_=df4d0f3a526e49e38bf3170fe2ffba72)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode df4d0f3a526e49e38bf3170fe2ffba72 NAV Verification ====================\n",
      "  agent_0 NAV: 1,082,594.00\n",
      "  agent_1 NAV: -461,703.00\n",
      "  agent_2 NAV: 4,002,224.00\n",
      "  agent_3 NAV: -623,115.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode d3230908eeec46e79a9d977bf47d5c50 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -3625827602.418523, 'agent_1': -14774749829.64199, 'agent_2': -2568767670.44362, 'agent_3': -9281472465.622404} id_=d3230908eeec46e79a9d977bf47d5c50)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d3230908eeec46e79a9d977bf47d5c50 NAV Verification ====================\n",
      "  agent_0 NAV: -37,788.00\n",
      "  agent_1 NAV: 2,471,152.00\n",
      "  agent_2 NAV: 460,726.00\n",
      "  agent_3 NAV: 1,105,910.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6d1207883d1e48e39a02d692a4ec8d0d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -4809376801.506735, 'agent_1': -4888212469.790384, 'agent_2': -1296766518.5086088, 'agent_3': -921773978.3484266} id_=6d1207883d1e48e39a02d692a4ec8d0d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6d1207883d1e48e39a02d692a4ec8d0d NAV Verification ====================\n",
      "  agent_0 NAV: -129,580.00\n",
      "  agent_1 NAV: 1,461,694.00\n",
      "  agent_2 NAV: 2,732,748.00\n",
      "  agent_3 NAV: -64,862.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 460d4ef4725649e9afbde72b148044e0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -7249772177.11 | Std: 2342232667.42 | Threshold: -7015548910.36\n",
      "Policy Returns: {'policy_2': -5047778676.190614, 'policy_0': -7146099311.918066, 'policy_1': -11088368132.29419, 'policy_3': -5716842588.021434}\n",
      "Best Trainable: policy_0 (-7146099311.92)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=679 done=True Rs={'agent_0': -6637951210.449991, 'agent_1': -2241540450.8830376, 'agent_2': -6874679867.973997, 'agent_3': -4321038396.637665} id_=460d4ef4725649e9afbde72b148044e0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 460d4ef4725649e9afbde72b148044e0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,144,630.00\n",
      "  agent_1 NAV: 1,025,163.00\n",
      "  agent_2 NAV: -260,368.00\n",
      "  agent_3 NAV: 2,090,575.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode fd04af29911041d3a5882de66ce51410 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -2957719837.1965013, 'agent_1': -9393923327.56763, 'agent_2': -4171909022.448668, 'agent_3': -3032284768.6359067} id_=fd04af29911041d3a5882de66ce51410)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fd04af29911041d3a5882de66ce51410 NAV Verification ====================\n",
      "  agent_0 NAV: 1,047,805.00\n",
      "  agent_1 NAV: 678,960.00\n",
      "  agent_2 NAV: 444,014.00\n",
      "  agent_3 NAV: 1,829,221.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode e7fbddd0b15441be981d8c60df899031 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -5544085926.528212, 'agent_1': -11881067099.259039, 'agent_2': -3097989546.1153464, 'agent_3': -2641676189.7857} id_=e7fbddd0b15441be981d8c60df899031)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e7fbddd0b15441be981d8c60df899031 NAV Verification ====================\n",
      "  agent_0 NAV: 941,745.00\n",
      "  agent_1 NAV: 1,566,655.00\n",
      "  agent_2 NAV: 833,468.00\n",
      "  agent_3 NAV: 658,132.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode aea0477f88cd45ccb9a47c9aff0e11c6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -3389691148.830895, 'agent_1': -13851016689.081947, 'agent_2': -1211789288.211458, 'agent_3': -11110108603.726933} id_=aea0477f88cd45ccb9a47c9aff0e11c6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode aea0477f88cd45ccb9a47c9aff0e11c6 NAV Verification ====================\n",
      "  agent_0 NAV: 1,312,137.00\n",
      "  agent_1 NAV: 1,443,740.00\n",
      "  agent_2 NAV: 712,335.00\n",
      "  agent_3 NAV: 531,788.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode efffc79264f94a228d71deb87d1ac088 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -7092318821.43 | Std: 2307048150.20 | Threshold: -6861614006.41\n",
      "Policy Returns: {'policy_2': -4919061759.373215, 'policy_0': -6877343148.72909, 'policy_1': -10900703353.517572, 'policy_3': -5672167024.094436}\n",
      "Best Trainable: policy_0 (-6877343148.73)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=683 done=True Rs={'agent_0': -2306157623.6653595, 'agent_1': -4764950307.25772, 'agent_2': -2826057465.7456474, 'agent_3': -8434333957.094175} id_=efffc79264f94a228d71deb87d1ac088)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode efffc79264f94a228d71deb87d1ac088 NAV Verification ====================\n",
      "  agent_0 NAV: 387,798.00\n",
      "  agent_1 NAV: 733,956.00\n",
      "  agent_2 NAV: 1,468,154.00\n",
      "  agent_3 NAV: 1,410,092.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 8848f0a5a74442d392469bd25c46d0dc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -3529992824.480929, 'agent_1': -18033330281.31832, 'agent_2': -6506836361.643384, 'agent_3': -8602719113.130482} id_=8848f0a5a74442d392469bd25c46d0dc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8848f0a5a74442d392469bd25c46d0dc NAV Verification ====================\n",
      "  agent_0 NAV: 2,785,488.00\n",
      "  agent_1 NAV: -7,122,955.00\n",
      "  agent_2 NAV: 4,529,814.00\n",
      "  agent_3 NAV: 3,807,653.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode e16b3f58a6534a9a9b5ab59e6f73f48c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -14836259226.338346, 'agent_1': -19186645554.688725, 'agent_2': -1732165905.831071, 'agent_3': -2946559860.3092117} id_=e16b3f58a6534a9a9b5ab59e6f73f48c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e16b3f58a6534a9a9b5ab59e6f73f48c NAV Verification ====================\n",
      "  agent_0 NAV: 454,312.00\n",
      "  agent_1 NAV: 259,754.00\n",
      "  agent_2 NAV: 1,244,286.00\n",
      "  agent_3 NAV: 2,041,648.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 158b8cb15fde4a9a92a47096016bf745 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1602366233.4988065, 'agent_1': -14747768626.511919, 'agent_2': -5679008380.902506, 'agent_3': -10467886287.667645} id_=158b8cb15fde4a9a92a47096016bf745)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 158b8cb15fde4a9a92a47096016bf745 NAV Verification ====================\n",
      "  agent_0 NAV: 243,643.00\n",
      "  agent_1 NAV: 1,074,047.00\n",
      "  agent_2 NAV: 2,027,525.00\n",
      "  agent_3 NAV: 654,785.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode daca31a43a704da1a68967066342db91 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -7182796571.27 | Std: 2435931721.95 | Threshold: -6939203399.07\n",
      "Policy Returns: {'policy_2': -4859311293.659036, 'policy_0': -6757057970.888181, 'policy_1': -11238462431.686405, 'policy_3': -5876354588.832149}\n",
      "Best Trainable: policy_0 (-6757057970.89)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_0\n",
      "Return: -6757057970.89\n",
      "Iteration: 10\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_2 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=687 done=True Rs={'agent_0': -4605804093.679366, 'agent_1': -6039904538.779127, 'agent_2': -6578162060.159434, 'agent_3': -5179044799.951099} id_=daca31a43a704da1a68967066342db91)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode daca31a43a704da1a68967066342db91 NAV Verification ====================\n",
      "  agent_0 NAV: 606,151.00\n",
      "  agent_1 NAV: 1,588,696.00\n",
      "  agent_2 NAV: 65,261.00\n",
      "  agent_3 NAV: 1,739,892.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode bc4f39d264b24da29d9466fac40e5ac2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -2907911973.169753, 'agent_1': -9972262610.16551, 'agent_2': -11176967155.766476, 'agent_3': -1743476894.8558357} id_=bc4f39d264b24da29d9466fac40e5ac2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bc4f39d264b24da29d9466fac40e5ac2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,486,703.00\n",
      "  agent_1 NAV: -756,705.00\n",
      "  agent_2 NAV: 1,316,215.00\n",
      "  agent_3 NAV: 1,953,787.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode bd0d100392ab4f16b3aa038ce9e0a689 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1685397760.890958, 'agent_1': -18371974393.487297, 'agent_2': -4705653344.8817425, 'agent_3': -13534826859.89414} id_=bd0d100392ab4f16b3aa038ce9e0a689)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bd0d100392ab4f16b3aa038ce9e0a689 NAV Verification ====================\n",
      "  agent_0 NAV: 1,942,520.00\n",
      "  agent_1 NAV: -5,251,870.00\n",
      "  agent_2 NAV: 3,001,392.00\n",
      "  agent_3 NAV: 4,307,958.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 8121a2537c56452894fc9ec3be3f70ca Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1358575097.8539066, 'agent_1': -10662566644.701822, 'agent_2': -3656207947.5355735, 'agent_3': -9649978309.685677} id_=8121a2537c56452894fc9ec3be3f70ca)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8121a2537c56452894fc9ec3be3f70ca NAV Verification ====================\n",
      "  agent_0 NAV: 57,230.00\n",
      "  agent_1 NAV: 618,877.00\n",
      "  agent_2 NAV: 1,089,520.00\n",
      "  agent_3 NAV: 2,234,373.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode b038cd36e1b340c5aadaef1bd0911deb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -7179684575.76 | Std: 2410142548.04 | Threshold: -6938670320.95\n",
      "Policy Returns: {'policy_2': -5024984202.288171, 'policy_0': -6400821154.617288, 'policy_1': -11262081908.363153, 'policy_3': -6030851037.753849}\n",
      "Best Trainable: policy_0 (-6400821154.62)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=691 done=True Rs={'agent_0': -2250237295.242454, 'agent_1': -16475007881.226183, 'agent_2': -10875098065.437536, 'agent_3': -3454524183.3236117} id_=b038cd36e1b340c5aadaef1bd0911deb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode b038cd36e1b340c5aadaef1bd0911deb NAV Verification ====================\n",
      "  agent_0 NAV: -12,410.00\n",
      "  agent_1 NAV: 187,539.00\n",
      "  agent_2 NAV: 2,628,154.00\n",
      "  agent_3 NAV: 1,196,717.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 4ec3b85de0ab4f3db6d8ed0976af6376 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -2662353254.5581384, 'agent_1': -9145539115.991718, 'agent_2': -4481419017.350227, 'agent_3': -3688496231.0909805} id_=4ec3b85de0ab4f3db6d8ed0976af6376)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4ec3b85de0ab4f3db6d8ed0976af6376 NAV Verification ====================\n",
      "  agent_0 NAV: 1,851,582.00\n",
      "  agent_1 NAV: -3,671,034.00\n",
      "  agent_2 NAV: 4,848,687.00\n",
      "  agent_3 NAV: 970,765.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 4fd547fce5d34c2da153375c5abf8540 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -2852441925.4335785, 'agent_1': -24407602295.987816, 'agent_2': -29325916538.5201, 'agent_3': -1814909716.9994035} id_=4fd547fce5d34c2da153375c5abf8540)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4fd547fce5d34c2da153375c5abf8540 NAV Verification ====================\n",
      "  agent_0 NAV: 1,800,976.00\n",
      "  agent_1 NAV: 449,386.00\n",
      "  agent_2 NAV: 1,125,623.00\n",
      "  agent_3 NAV: 624,015.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 5a3deda12156474fac714d1af293fd6d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1800114739.7184615, 'agent_1': -3500562107.736448, 'agent_2': -6485993880.79036, 'agent_3': -1638982383.9173532} id_=5a3deda12156474fac714d1af293fd6d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5a3deda12156474fac714d1af293fd6d NAV Verification ====================\n",
      "  agent_0 NAV: 529,119.00\n",
      "  agent_1 NAV: 1,232,979.00\n",
      "  agent_2 NAV: 198,184.00\n",
      "  agent_3 NAV: 2,039,718.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode fcd695003026448fa3a8d1cad4c857eb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -7234674695.03 | Std: 2433888867.06 | Threshold: -6991285808.32\n",
      "Policy Returns: {'policy_2': -5660788839.374617, 'policy_0': -6075194112.944526, 'policy_1': -11441965429.953123, 'policy_3': -5760750397.846384}\n",
      "Best Trainable: policy_0 (-6075194112.94)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_1 (from iteration 1, return=-8836798672.24)\n",
      "‚úì Champion removed. Active champions: ['champion_2']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -6075194112.94\n",
      "Iteration: 12\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_3 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=695 done=True Rs={'agent_0': -1264555122.581195, 'agent_1': -6125903004.695776, 'agent_2': -2683856549.8901668, 'agent_3': -6524992901.1673975} id_=fcd695003026448fa3a8d1cad4c857eb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fcd695003026448fa3a8d1cad4c857eb NAV Verification ====================\n",
      "  agent_0 NAV: 1,181,224.00\n",
      "  agent_1 NAV: 375,894.00\n",
      "  agent_2 NAV: 970,306.00\n",
      "  agent_3 NAV: 1,472,576.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 5b5a7e4ce74f447596cb5464898bf6ea Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1874556456.1009233, 'agent_1': -14402547143.665468, 'agent_2': -10098242338.455246, 'agent_3': -3354965140.965051} id_=5b5a7e4ce74f447596cb5464898bf6ea)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5b5a7e4ce74f447596cb5464898bf6ea NAV Verification ====================\n",
      "  agent_0 NAV: 1,172,154.00\n",
      "  agent_1 NAV: 653,300.00\n",
      "  agent_2 NAV: 1,274,923.00\n",
      "  agent_3 NAV: 899,623.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode f6b0565ee39d43ee8aeea5d32cdcbf8f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -14799891958.715618, 'agent_1': -10294210626.417921, 'agent_2': -4722320884.505347, 'agent_3': -684923212.2802194} id_=f6b0565ee39d43ee8aeea5d32cdcbf8f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f6b0565ee39d43ee8aeea5d32cdcbf8f NAV Verification ====================\n",
      "  agent_0 NAV: 6,746,382.00\n",
      "  agent_1 NAV: -2,656,866.00\n",
      "  agent_2 NAV: -696,089.00\n",
      "  agent_3 NAV: 606,573.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode c3a138c586894d459796b6eac253dc14 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -6239196864.27489, 'agent_1': -2082013429.815341, 'agent_2': -2210709416.369725, 'agent_3': -4354479136.204625} id_=c3a138c586894d459796b6eac253dc14)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c3a138c586894d459796b6eac253dc14 NAV Verification ====================\n",
      "  agent_0 NAV: 921,311.00\n",
      "  agent_1 NAV: 799,055.00\n",
      "  agent_2 NAV: 1,549,828.00\n",
      "  agent_3 NAV: 729,806.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode bf3055f84cf04f4aa70e83adf2be533c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -7129690559.19 | Std: 2364462154.80 | Threshold: -6893244343.71\n",
      "Policy Returns: {'policy_2': -5614220783.429456, 'policy_0': -6074984543.618725, 'policy_1': -11212167407.631346, 'policy_3': -5617389502.077903}\n",
      "Best Trainable: policy_0 (-6074984543.62)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=699 done=True Rs={'agent_0': -811617095.7862892, 'agent_1': -2745771075.734043, 'agent_2': -1462861311.8733034, 'agent_3': -2058099313.9810915} id_=bf3055f84cf04f4aa70e83adf2be533c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bf3055f84cf04f4aa70e83adf2be533c NAV Verification ====================\n",
      "  agent_0 NAV: 511,954.00\n",
      "  agent_1 NAV: 1,614,782.00\n",
      "  agent_2 NAV: 899,142.00\n",
      "  agent_3 NAV: 974,122.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 7def18ef41de4a8ab1379c89e9971ca9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1729282674.1275842, 'agent_1': -8727183737.272125, 'agent_2': -959022278.0699573, 'agent_3': -7084750626.066734} id_=7def18ef41de4a8ab1379c89e9971ca9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7def18ef41de4a8ab1379c89e9971ca9 NAV Verification ====================\n",
      "  agent_0 NAV: 568,243.00\n",
      "  agent_1 NAV: 1,320,282.00\n",
      "  agent_2 NAV: 1,013,313.00\n",
      "  agent_3 NAV: 1,098,162.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 57cda2c386ea4d219c7a22f884e23acb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -5309607863.302582, 'agent_1': -6377779734.990123, 'agent_2': -3780509352.214066, 'agent_3': -2293808767.6515107} id_=57cda2c386ea4d219c7a22f884e23acb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 57cda2c386ea4d219c7a22f884e23acb NAV Verification ====================\n",
      "  agent_0 NAV: -461,929.00\n",
      "  agent_1 NAV: 376,183.00\n",
      "  agent_2 NAV: 481,050.00\n",
      "  agent_3 NAV: 3,604,696.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 8f8c0448dd4a46699bdab0fac63d3b8e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1469170280.348451, 'agent_1': -11053569653.066584, 'agent_2': -8475402414.4675865, 'agent_3': -3577659788.41859} id_=8f8c0448dd4a46699bdab0fac63d3b8e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8f8c0448dd4a46699bdab0fac63d3b8e NAV Verification ====================\n",
      "  agent_0 NAV: 152,788.00\n",
      "  agent_1 NAV: -372,408.00\n",
      "  agent_2 NAV: 1,943,108.00\n",
      "  agent_3 NAV: 2,276,512.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode f37a699042b74e9a9a3141b6bed90d61 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -6929460784.64 | Std: 2316814629.93 | Threshold: -6697779321.65\n",
      "Policy Returns: {'policy_2': -5481098961.397892, 'policy_0': -5814185645.1461935, 'policy_1': -10935505052.513802, 'policy_3': -5487053479.498645}\n",
      "Best Trainable: policy_0 (-5814185645.15)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_2 (from iteration 10, return=-6757057970.89)\n",
      "‚úì Champion removed. Active champions: ['champion_3']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -5814185645.15\n",
      "Iteration: 14\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_4 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=703 done=True Rs={'agent_0': -711044379.379196, 'agent_1': -12272393557.537857, 'agent_2': -11857689417.936878, 'agent_3': -1334853451.678222} id_=f37a699042b74e9a9a3141b6bed90d61)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f37a699042b74e9a9a3141b6bed90d61 NAV Verification ====================\n",
      "  agent_0 NAV: 1,105,918.00\n",
      "  agent_1 NAV: 265,403.00\n",
      "  agent_2 NAV: 1,412,495.00\n",
      "  agent_3 NAV: 1,216,184.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode d44b456939c448fbbd745a5a43384b4e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -4387171819.379498, 'agent_1': -8034096415.983175, 'agent_2': -12611551871.756098, 'agent_3': -1453998272.3856423} id_=d44b456939c448fbbd745a5a43384b4e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d44b456939c448fbbd745a5a43384b4e NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,324.00\n",
      "  agent_1 NAV: 495,572.00\n",
      "  agent_2 NAV: 1,555,292.00\n",
      "  agent_3 NAV: 945,812.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 38ccac0f2edd4f41b3356ac165836438 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -3829633849.7506905, 'agent_1': -8361070898.33733, 'agent_2': -2413806900.3597817, 'agent_3': -5477404986.642021} id_=38ccac0f2edd4f41b3356ac165836438)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 38ccac0f2edd4f41b3356ac165836438 NAV Verification ====================\n",
      "  agent_0 NAV: -483,189.00\n",
      "  agent_1 NAV: 3,167,868.00\n",
      "  agent_2 NAV: 1,052,093.00\n",
      "  agent_3 NAV: 263,228.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 05bd3e94b46f4397b8c77c26669b74bc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -4795243793.227556, 'agent_1': -3909666841.1578846, 'agent_2': -5218458980.739919, 'agent_3': -2507522417.632676} id_=05bd3e94b46f4397b8c77c26669b74bc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 05bd3e94b46f4397b8c77c26669b74bc NAV Verification ====================\n",
      "  agent_0 NAV: -1,231,101.00\n",
      "  agent_1 NAV: 113,474.00\n",
      "  agent_2 NAV: 2,663,566.00\n",
      "  agent_3 NAV: 2,454,061.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 8f5c1be5069e4330b557b581bf20c887 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -6846023916.30 | Std: 2266119252.77 | Threshold: -6619411991.03\n",
      "Policy Returns: {'policy_2': -5654870798.921634, 'policy_0': -5660963782.446854, 'policy_1': -10763121004.844185, 'policy_3': -5305140079.001112}\n",
      "Best Trainable: policy_0 (-5660963782.45)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=707 done=True Rs={'agent_0': -6753782232.309427, 'agent_1': -4625311414.817771, 'agent_2': -3800358587.2028365, 'agent_3': -4623680543.118295} id_=8f5c1be5069e4330b557b581bf20c887)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8f5c1be5069e4330b557b581bf20c887 NAV Verification ====================\n",
      "  agent_0 NAV: 1,030,662.00\n",
      "  agent_1 NAV: 815,656.00\n",
      "  agent_2 NAV: 877,968.00\n",
      "  agent_3 NAV: 1,275,714.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 2498c6ca952e488fb3d6a6be3dda6e6e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -4342656117.1882305, 'agent_1': -5603116571.155143, 'agent_2': -1404153979.3280723, 'agent_3': -1761077537.8334675} id_=2498c6ca952e488fb3d6a6be3dda6e6e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 2498c6ca952e488fb3d6a6be3dda6e6e NAV Verification ====================\n",
      "  agent_0 NAV: 1,543,220.00\n",
      "  agent_1 NAV: 416,181.00\n",
      "  agent_2 NAV: 652,153.00\n",
      "  agent_3 NAV: 1,388,446.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode da7c3536d8b94d2a9aef3adf87d75d27 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -1634255605.374233, 'agent_1': -3802579946.4802465, 'agent_2': -3738870122.810454, 'agent_3': -1111297381.1772153} id_=da7c3536d8b94d2a9aef3adf87d75d27)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode da7c3536d8b94d2a9aef3adf87d75d27 NAV Verification ====================\n",
      "  agent_0 NAV: 1,034,565.00\n",
      "  agent_1 NAV: -405,233.00\n",
      "  agent_2 NAV: 1,565,085.00\n",
      "  agent_3 NAV: 1,805,583.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode f816ea4837fa4cf599a55f28f047205b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -755822182.5428747, 'agent_1': -1150748900.0500498, 'agent_2': -855715889.174251, 'agent_3': -2540213681.5164123} id_=f816ea4837fa4cf599a55f28f047205b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f816ea4837fa4cf599a55f28f047205b NAV Verification ====================\n",
      "  agent_0 NAV: 2,588,436.00\n",
      "  agent_1 NAV: 906,069.00\n",
      "  agent_2 NAV: -329,590.00\n",
      "  agent_3 NAV: 835,085.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 14dc9c457e9b4fff8dddb83eab2d973f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -6613867695.24 | Std: 2154952210.72 | Threshold: -6398372474.17\n",
      "Policy Returns: {'policy_2': -5462334427.187313, 'policy_0': -5521991366.281655, 'policy_1': -10337553472.43231, 'policy_3': -5133591515.073448}\n",
      "Best Trainable: policy_0 (-5521991366.28)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_3 (from iteration 12, return=-6075194112.94)\n",
      "‚úì Champion removed. Active champions: ['champion_4']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -5521991366.28\n",
      "Iteration: 16\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_5 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_4', 'champion_5']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ‚Üê KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-23 03:52:34\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087446269,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "sF-9OyQangj-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
