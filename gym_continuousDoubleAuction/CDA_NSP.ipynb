{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-13 21:04:37\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Get current time in SGT (Singapore Time)\n",
    "sgt_time = datetime.now(ZoneInfo(\"Asia/Singapore\"))\n",
    "formatted_datetime = sgt_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"❌ No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 13:04:40,202\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2026-01-13 13:04:41,916\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_5', 'agent_0', 'agent_6', 'agent_7', 'agent_4', 'agent_2', 'agent_1', 'agent_3']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 13:04:44,165\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.72gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2026-01-13 13:04:45,214\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"6e969267-e9c3-4c53-8d5e-3f5fc6fab867\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 8\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 * 4 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99e9b0>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99ea70>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99ead0>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99d0c0>, 'policy_4': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99cf40>, 'policy_5': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99ceb0>, 'policy_6': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99ce20>, 'policy_7': <ray.rllib.policy.policy.PolicySpec object at 0x718acc99cdf0>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=8,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ← ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 13:04:45,530\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2026-01-13 13:04:45,531\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 16384\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2026-01-13 13:04:45,774\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2026-01-13 13:04:45,783\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2026-01-13 13:04:45,792\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2026-01-13 13:04:45,811\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2026-01-13 13:04:45,821\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2026-01-13 13:04:45,831\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2026-01-13 13:04:45,834\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2026-01-13 13:04:45,854\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,855\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,855\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,856\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,856\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,869\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,869\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2026-01-13 13:04:45,870\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32), 'agent_4': Box(-inf, inf, (40,), float32), 'agent_5': Box(-inf, inf, (40,), float32), 'agent_6': Box(-inf, inf, (40,), float32), 'agent_7': Box(-inf, inf, (40,), float32)), Dict('agent_0': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_1': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_2': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_3': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_4': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_5': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_6': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_7': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))), 'policy_0': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_1': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_2': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_3': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_4': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_5': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_6': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_7': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))}\n",
      "2026-01-13 13:04:45,909\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:45,909\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:45,918\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:45,926\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:45,935\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:45,943\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:45,951\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:47,236\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2026-01-13 13:04:47,265\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 16384\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode 86ee2a7c83bd4be793807ed15f575879 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -11129069.499999989, 'agent_1': -16283226.800000018, 'agent_2': -6529707.600000001, 'agent_3': -5252040.449999992, 'agent_4': -5916487.600000005, 'agent_5': -7624775.049999973, 'agent_6': -28878959.699999984, 'agent_7': -4335182.399999996} id_=86ee2a7c83bd4be793807ed15f575879)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 86ee2a7c83bd4be793807ed15f575879 NAV Verification ====================\n",
      "  agent_0 NAV: 979,359.00\n",
      "  agent_1 NAV: 1,050,469.00\n",
      "  agent_2 NAV: 1,004,186.00\n",
      "  agent_3 NAV: 1,001,758.00\n",
      "  agent_4 NAV: 1,019,709.00\n",
      "  agent_5 NAV: 980,604.00\n",
      "  agent_6 NAV: 948,506.00\n",
      "  agent_7 NAV: 1,015,409.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode b84efd3fb07f4db88cd242792be5c60f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7576100.5499999905, 'agent_1': -11049653.400000006, 'agent_2': -5249155.599999991, 'agent_3': -23933046.699999988, 'agent_4': -10219549.000000024, 'agent_5': -7341796.450000021, 'agent_6': -15688022.450000016, 'agent_7': -3438399.2500000023} id_=b84efd3fb07f4db88cd242792be5c60f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode b84efd3fb07f4db88cd242792be5c60f NAV Verification ====================\n",
      "  agent_0 NAV: 986,073.00\n",
      "  agent_1 NAV: 1,018,441.00\n",
      "  agent_2 NAV: 996,693.00\n",
      "  agent_3 NAV: 974,372.00\n",
      "  agent_4 NAV: 1,027,691.00\n",
      "  agent_5 NAV: 992,220.00\n",
      "  agent_6 NAV: 992,829.00\n",
      "  agent_7 NAV: 1,011,681.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode 86aa4306766747658d002adfe8348f42 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4979403.199999989, 'agent_1': -12683507.69999998, 'agent_2': -24195974.900000017, 'agent_3': -10473164.700000016, 'agent_4': -5157966.1, 'agent_5': -2457166.549999993, 'agent_6': -4170436.2999999877, 'agent_7': -17377447.750000034} id_=86aa4306766747658d002adfe8348f42)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 86aa4306766747658d002adfe8348f42 NAV Verification ====================\n",
      "  agent_0 NAV: 1,010,783.00\n",
      "  agent_1 NAV: 992,122.00\n",
      "  agent_2 NAV: 987,040.00\n",
      "  agent_3 NAV: 981,631.00\n",
      "  agent_4 NAV: 999,244.00\n",
      "  agent_5 NAV: 1,007,700.00\n",
      "  agent_6 NAV: 1,002,318.00\n",
      "  agent_7 NAV: 1,019,162.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "========================================\n",
      "Episode ce8a0c565aa44d9c9b7dab147003dca2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -10497509.99 | Std: 3455937.15 | Threshold: -10151916.27\n",
      "Policy Returns: {'policy_1': -13338795.966666669, 'policy_0': -7894857.749999989, 'policy_6': -16245806.149999997, 'policy_2': -11991612.700000003, 'policy_7': -8383676.466666677, 'policy_4': -7098000.90000001, 'policy_3': -13219417.283333331, 'policy_5': -5807912.683333329}\n",
      "Best Trainable: policy_0 (-7894857.75)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -7894857.75\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_1 created successfully!\n",
      "✓ League size now: 3 (2 trainable + 1 champions)\n",
      "✓ Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': -3855.05, 'agent_1': -35097.34999999999, 'agent_2': -40339.950000000004, 'agent_3': -26502.600000000006, 'agent_4': -3544.3000000000006, 'agent_5': -18843.45, 'agent_6': -20866.6, 'agent_7': -3257.7999999999993} id_=ce8a0c565aa44d9c9b7dab147003dca2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ce8a0c565aa44d9c9b7dab147003dca2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,028,825.00\n",
      "  agent_1 NAV: 1,009,212.00\n",
      "  agent_2 NAV: 976,652.00\n",
      "  agent_3 NAV: 980,869.00\n",
      "  agent_4 NAV: 997,409.00\n",
      "  agent_5 NAV: 996,192.00\n",
      "  agent_6 NAV: 1,010,062.00\n",
      "  agent_7 NAV: 1,000,779.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6c83b100137d4ad3aee15b436073bb6e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -28433017.30000005, 'agent_1': -2781399.950000006, 'agent_2': -13904415.300000003, 'agent_3': -8265749.450000001, 'agent_4': -4822678.15, 'agent_5': -12082572.950000027, 'agent_6': -24082185.849999968, 'agent_7': -6593995.550000013} id_=6c83b100137d4ad3aee15b436073bb6e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6c83b100137d4ad3aee15b436073bb6e NAV Verification ====================\n",
      "  agent_0 NAV: 959,569.00\n",
      "  agent_1 NAV: 1,017,842.00\n",
      "  agent_2 NAV: 983,347.00\n",
      "  agent_3 NAV: 1,033,579.00\n",
      "  agent_4 NAV: 1,016,279.00\n",
      "  agent_5 NAV: 981,547.00\n",
      "  agent_6 NAV: 965,701.00\n",
      "  agent_7 NAV: 1,042,136.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 4eddb78b216746b79a5e0b9f0e4f3418 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -13059756.00000002, 'agent_1': -3701356.4999999986, 'agent_2': -14746468.650000017, 'agent_3': -12336325.150000026, 'agent_4': -5850672.399999983, 'agent_5': -6806539.549999989, 'agent_6': -25568659.549999986, 'agent_7': -15959538.099999972} id_=4eddb78b216746b79a5e0b9f0e4f3418)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4eddb78b216746b79a5e0b9f0e4f3418 NAV Verification ====================\n",
      "  agent_0 NAV: 971,868.00\n",
      "  agent_1 NAV: 1,014,593.00\n",
      "  agent_2 NAV: 990,151.00\n",
      "  agent_3 NAV: 1,054,422.00\n",
      "  agent_4 NAV: 1,026,060.00\n",
      "  agent_5 NAV: 1,000,538.00\n",
      "  agent_6 NAV: 998,402.00\n",
      "  agent_7 NAV: 943,966.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 29e34021a660400c974effd7408a80bc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -9121388.649999982, 'agent_1': -12155622.100000005, 'agent_2': -19927269.60000003, 'agent_3': -9804200.09999998, 'agent_4': -23407063.09999995, 'agent_5': -18211091.29999999, 'agent_6': -6903125.499999984, 'agent_7': -7299610.050000001} id_=29e34021a660400c974effd7408a80bc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 29e34021a660400c974effd7408a80bc NAV Verification ====================\n",
      "  agent_0 NAV: 985,488.00\n",
      "  agent_1 NAV: 1,013,611.00\n",
      "  agent_2 NAV: 993,552.00\n",
      "  agent_3 NAV: 1,007,672.00\n",
      "  agent_4 NAV: 967,959.00\n",
      "  agent_5 NAV: 1,023,255.00\n",
      "  agent_6 NAV: 995,167.00\n",
      "  agent_7 NAV: 1,013,296.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 534e0e2620124e7ea29e183c5614c1ab Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -11506332.25 | Std: 2429244.39 | Threshold: -11263407.81\n",
      "Policy Returns: {'policy_1': -9655977.821428576, 'policy_0': -11249883.92857143, 'policy_6': -16247318.77142856, 'policy_2': -14417554.214285728, 'policy_7': -11030408.135714289, 'policy_4': -9900192.47142857, 'policy_3': -11182589.85, 'policy_5': -8366732.8071428565}\n",
      "Best Trainable: policy_1 (-9655977.82)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -5467.95, 'agent_1': -80476.8, 'agent_2': -7923.949999999999, 'agent_3': -34415.799999999996, 'agent_4': -25315.25, 'agent_5': -11718.5, 'agent_6': -34230.549999999996, 'agent_7': -89811.40000000001} id_=534e0e2620124e7ea29e183c5614c1ab)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 534e0e2620124e7ea29e183c5614c1ab NAV Verification ====================\n",
      "  agent_0 NAV: 1,024,330.00\n",
      "  agent_1 NAV: 950,794.00\n",
      "  agent_2 NAV: 1,002,607.00\n",
      "  agent_3 NAV: 982,084.00\n",
      "  agent_4 NAV: 1,061,175.00\n",
      "  agent_5 NAV: 995,082.00\n",
      "  agent_6 NAV: 1,033,080.00\n",
      "  agent_7 NAV: 950,848.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode c6d8973bcca348fabea19c6a633cddba Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6169802.850000014, 'agent_1': -41141010.10000001, 'agent_2': -41639254.20000002, 'agent_3': -26450230.20000002, 'agent_4': -14782283.59999999, 'agent_5': -8625727.649999993, 'agent_6': -60552926.94999994, 'agent_7': -8178059.849999992} id_=c6d8973bcca348fabea19c6a633cddba)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode c6d8973bcca348fabea19c6a633cddba NAV Verification ====================\n",
      "  agent_0 NAV: 1,100,373.00\n",
      "  agent_1 NAV: 878,431.00\n",
      "  agent_2 NAV: 853,717.00\n",
      "  agent_3 NAV: 935,318.00\n",
      "  agent_4 NAV: 1,172,596.00\n",
      "  agent_5 NAV: 1,121,736.00\n",
      "  agent_6 NAV: 821,051.00\n",
      "  agent_7 NAV: 1,116,778.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 39090bfa27d048c1828ea0a9631dce26 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -17698548.050000004, 'agent_1': -6029448.749999995, 'agent_2': -4883767.100000004, 'agent_3': -8876687.499999996, 'agent_4': -4935279.49999999, 'agent_5': -24183708.899999958, 'agent_6': -14433257.299999977, 'agent_7': -14667605.100000056} id_=39090bfa27d048c1828ea0a9631dce26)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 39090bfa27d048c1828ea0a9631dce26 NAV Verification ====================\n",
      "  agent_0 NAV: 980,416.00\n",
      "  agent_1 NAV: 997,961.00\n",
      "  agent_2 NAV: 1,035,576.00\n",
      "  agent_3 NAV: 965,452.00\n",
      "  agent_4 NAV: 1,013,574.00\n",
      "  agent_5 NAV: 988,052.00\n",
      "  agent_6 NAV: 980,133.00\n",
      "  agent_7 NAV: 1,038,836.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode fb759fb7b2b64247b04c932826ed6d53 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3219721.0000000037, 'agent_1': -13275121.049999995, 'agent_2': -5420891.100000001, 'agent_3': -20092056.30000005, 'agent_4': -17820752.25000003, 'agent_5': -22226491.100000013, 'agent_6': -7467553.499999986, 'agent_7': -7294369.099999997} id_=fb759fb7b2b64247b04c932826ed6d53)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode fb759fb7b2b64247b04c932826ed6d53 NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,328.00\n",
      "  agent_1 NAV: 969,080.00\n",
      "  agent_2 NAV: 1,002,312.00\n",
      "  agent_3 NAV: 1,037,649.00\n",
      "  agent_4 NAV: 961,446.00\n",
      "  agent_5 NAV: 972,948.00\n",
      "  agent_6 NAV: 1,013,812.00\n",
      "  agent_7 NAV: 1,036,425.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 57cebb23cddd4cc7bca8bb19c0fe209e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -12976845.46 | Std: 2587791.75 | Threshold: -12718066.28\n",
      "Policy Returns: {'policy_1': -13738995.713636361, 'policy_0': -10008418.400000004, 'policy_6': -18544939.72727271, 'policy_2': -14448790.050000012, 'policy_7': -12562794.218181832, 'policy_4': -10683445.427272722, 'policy_3': -13201882.82727273, 'policy_5': -10625497.290909087}\n",
      "Best Trainable: policy_0 (-10008418.40)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_0\n",
      "Return: -10008418.40\n",
      "Iteration: 3\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_2 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -111633.8, 'agent_1': -97111.85, 'agent_2': -130763.65000000001, 'agent_3': -8242.1, 'agent_4': -35384.5, 'agent_5': -99236.75000000001, 'agent_6': -185178.0, 'agent_7': -177791.25} id_=57cebb23cddd4cc7bca8bb19c0fe209e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 57cebb23cddd4cc7bca8bb19c0fe209e NAV Verification ====================\n",
      "  agent_0 NAV: 964,870.00\n",
      "  agent_1 NAV: 973,011.00\n",
      "  agent_2 NAV: 1,060,467.00\n",
      "  agent_3 NAV: 1,041,453.00\n",
      "  agent_4 NAV: 989,298.00\n",
      "  agent_5 NAV: 967,447.00\n",
      "  agent_6 NAV: 1,052,723.00\n",
      "  agent_7 NAV: 950,731.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 11acbc9569c740fda18eda1e0998a935 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3362020.49999999, 'agent_1': -31796362.250000108, 'agent_2': -6613201.7, 'agent_3': -10458585.200000007, 'agent_4': -14272312.850000022, 'agent_5': -6718753.049999991, 'agent_6': -8957621.900000002, 'agent_7': -25515871.550000023} id_=11acbc9569c740fda18eda1e0998a935)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 11acbc9569c740fda18eda1e0998a935 NAV Verification ====================\n",
      "  agent_0 NAV: 1,009,660.00\n",
      "  agent_1 NAV: 901,233.00\n",
      "  agent_2 NAV: 1,059,790.00\n",
      "  agent_3 NAV: 1,041,303.00\n",
      "  agent_4 NAV: 968,118.00\n",
      "  agent_5 NAV: 1,017,798.00\n",
      "  agent_6 NAV: 1,088,362.00\n",
      "  agent_7 NAV: 913,736.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode b1249894342143ba9064f06da0456232 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6497483.399999983, 'agent_1': -23983506.55000003, 'agent_2': -27832313.800000004, 'agent_3': -21489479.54999998, 'agent_4': -6990418.050000003, 'agent_5': -9414533.699999988, 'agent_6': -7902668.800000007, 'agent_7': -10340810.849999985} id_=b1249894342143ba9064f06da0456232)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode b1249894342143ba9064f06da0456232 NAV Verification ====================\n",
      "  agent_0 NAV: 1,018,727.00\n",
      "  agent_1 NAV: 960,247.00\n",
      "  agent_2 NAV: 948,697.00\n",
      "  agent_3 NAV: 950,657.00\n",
      "  agent_4 NAV: 1,032,612.00\n",
      "  agent_5 NAV: 1,044,794.00\n",
      "  agent_6 NAV: 1,004,253.00\n",
      "  agent_7 NAV: 1,040,013.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode e16a2316935549be879e391794e52010 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_5\n",
      "  agent_3 -> policy_6\n",
      "  agent_4 -> policy_7\n",
      "  agent_5 -> champion_1\n",
      "  agent_6 -> champion_2\n",
      "  agent_7 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -23457681.099999823, 'agent_1': -9862620.349999985, 'agent_2': -5963404.850000006, 'agent_3': -8748521.800000003, 'agent_4': -4025385.799999995, 'agent_5': -16515024.950000055, 'agent_6': -43054963.75000006, 'agent_7': -10273477.30000002} id_=e16a2316935549be879e391794e52010)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e16a2316935549be879e391794e52010 NAV Verification ====================\n",
      "  agent_0 NAV: 978,705.00\n",
      "  agent_1 NAV: 1,009,611.00\n",
      "  agent_2 NAV: 987,671.00\n",
      "  agent_3 NAV: 1,021,572.00\n",
      "  agent_4 NAV: 1,041,844.00\n",
      "  agent_5 NAV: 988,818.00\n",
      "  agent_6 NAV: 947,136.00\n",
      "  agent_7 NAV: 1,024,643.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode a7ebd146c9d04da5820c64f7905c2dd0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -13738953.10 | Std: 2704745.13 | Threshold: -13468478.59\n",
      "Policy Returns: {'policy_1': -16037304.26000001, 'policy_0': -11340738.866666656, 'policy_6': -18766646.01666666, 'policy_2': -14156180.36000001, 'policy_7': -15303970.786666678, 'policy_4': -10042073.649999999, 'policy_3': -12749216.693333335, 'policy_5': -11515494.2}\n",
      "Best Trainable: policy_0 (-11340738.87)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -8901.500000000004, 'agent_1': -117438.25, 'agent_2': -54529.70000000001, 'agent_3': -205501.55000000002, 'agent_4': -46378.49999999999, 'agent_5': -39315.6, 'agent_6': -45610.450000000004, 'agent_7': -323465.85} id_=a7ebd146c9d04da5820c64f7905c2dd0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a7ebd146c9d04da5820c64f7905c2dd0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,305.00\n",
      "  agent_1 NAV: 964,899.00\n",
      "  agent_2 NAV: 1,028,430.00\n",
      "  agent_3 NAV: 998,990.00\n",
      "  agent_4 NAV: 1,002,994.00\n",
      "  agent_5 NAV: 995,780.00\n",
      "  agent_6 NAV: 1,030,704.00\n",
      "  agent_7 NAV: 974,898.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 685e6f1b10dd4f96a03d8b5985b31a5e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -21826748.29999996, 'agent_1': -6175424.3999999855, 'agent_2': -29223026.899999972, 'agent_3': -7831025.550000004, 'agent_4': -4316739.700000002, 'agent_5': -15629050.050000034, 'agent_6': -30675682.949999996, 'agent_7': -4799593.549999986} id_=685e6f1b10dd4f96a03d8b5985b31a5e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 685e6f1b10dd4f96a03d8b5985b31a5e NAV Verification ====================\n",
      "  agent_0 NAV: 984,834.00\n",
      "  agent_1 NAV: 996,402.00\n",
      "  agent_2 NAV: 951,186.00\n",
      "  agent_3 NAV: 1,013,029.00\n",
      "  agent_4 NAV: 1,023,311.00\n",
      "  agent_5 NAV: 1,038,291.00\n",
      "  agent_6 NAV: 954,285.00\n",
      "  agent_7 NAV: 1,038,662.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 1df5260fecbe42eca11aa8a0ec1ddec8 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6801137.250000039, 'agent_1': -9162286.249999981, 'agent_2': -6506193.900000005, 'agent_3': -9583262.099999992, 'agent_4': -20984494.199999925, 'agent_5': -24219832.100000046, 'agent_6': -18269185.000000007, 'agent_7': -6208596.4} id_=1df5260fecbe42eca11aa8a0ec1ddec8)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 1df5260fecbe42eca11aa8a0ec1ddec8 NAV Verification ====================\n",
      "  agent_0 NAV: 1,023,883.00\n",
      "  agent_1 NAV: 1,003,144.00\n",
      "  agent_2 NAV: 1,000,977.00\n",
      "  agent_3 NAV: 1,007,798.00\n",
      "  agent_4 NAV: 1,039,750.00\n",
      "  agent_5 NAV: 960,048.00\n",
      "  agent_6 NAV: 961,055.00\n",
      "  agent_7 NAV: 1,003,345.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode cfcd0ccaaaad49899e2053a7017d2aa2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8173791.450000007, 'agent_1': -6707942.350000011, 'agent_2': -8493449.500000004, 'agent_3': -8295193.950000004, 'agent_4': -4032250.2000000053, 'agent_5': -8132653.849999986, 'agent_6': -7981479.749999988, 'agent_7': -10787547.249999972} id_=cfcd0ccaaaad49899e2053a7017d2aa2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode cfcd0ccaaaad49899e2053a7017d2aa2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,596.00\n",
      "  agent_1 NAV: 990,773.00\n",
      "  agent_2 NAV: 994,967.00\n",
      "  agent_3 NAV: 1,005,137.00\n",
      "  agent_4 NAV: 1,005,951.00\n",
      "  agent_5 NAV: 1,001,065.00\n",
      "  agent_6 NAV: 1,013,144.00\n",
      "  agent_7 NAV: 988,367.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode e2e6d66b435a4355998002f6bc8119ac Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -13282310.53 | Std: 2560495.32 | Threshold: -13026261.00\n",
      "Policy Returns: {'policy_1': -14714392.72368422, 'policy_0': -11091046.95789473, 'policy_6': -18497382.615789462, 'policy_2': -14428111.150000004, 'policy_7': -14017846.205263164, 'policy_4': -9723701.76578947, 'policy_3': -11997140.93157895, 'policy_5': -11788861.923684217}\n",
      "Best Trainable: policy_0 (-11091046.96)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -11091046.96\n",
      "Iteration: 5\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_3 created successfully!\n",
      "✓ League size now: 5 (2 trainable + 3 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -49188.4, 'agent_1': -76102.79999999997, 'agent_2': -115271.69999999998, 'agent_3': -393438.5, 'agent_4': -358324.30000000005, 'agent_5': -45675.2, 'agent_6': -61572.45, 'agent_7': -17261.05} id_=e2e6d66b435a4355998002f6bc8119ac)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e2e6d66b435a4355998002f6bc8119ac NAV Verification ====================\n",
      "  agent_0 NAV: 1,049,230.00\n",
      "  agent_1 NAV: 985,390.00\n",
      "  agent_2 NAV: 1,077,960.00\n",
      "  agent_3 NAV: 907,790.00\n",
      "  agent_4 NAV: 916,022.00\n",
      "  agent_5 NAV: 993,392.00\n",
      "  agent_6 NAV: 1,041,858.00\n",
      "  agent_7 NAV: 1,028,358.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode ecc4071c3b534c38b46b52a75d5dcf57 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7139365.349999995, 'agent_1': -7041703.949999986, 'agent_2': -5925360.650000009, 'agent_3': -5599358.949999998, 'agent_4': -28493593.099999867, 'agent_5': -9326870.349999987, 'agent_6': -13883359.000000045, 'agent_7': -3941704.3500000006} id_=ecc4071c3b534c38b46b52a75d5dcf57)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ecc4071c3b534c38b46b52a75d5dcf57 NAV Verification ====================\n",
      "  agent_0 NAV: 1,033,143.00\n",
      "  agent_1 NAV: 989,801.00\n",
      "  agent_2 NAV: 1,018,081.00\n",
      "  agent_3 NAV: 994,332.00\n",
      "  agent_4 NAV: 958,661.00\n",
      "  agent_5 NAV: 1,032,199.00\n",
      "  agent_6 NAV: 961,184.00\n",
      "  agent_7 NAV: 1,012,599.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 8c655e765f1d41da828bcc3cdead2859 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -23227799.850000072, 'agent_1': -7239735.300000024, 'agent_2': -8848988.199999973, 'agent_3': -4152330.399999999, 'agent_4': -4151248.599999995, 'agent_5': -6328257.150000003, 'agent_6': -21593929.34999996, 'agent_7': -21137732.850000054} id_=8c655e765f1d41da828bcc3cdead2859)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8c655e765f1d41da828bcc3cdead2859 NAV Verification ====================\n",
      "  agent_0 NAV: 955,245.00\n",
      "  agent_1 NAV: 990,343.00\n",
      "  agent_2 NAV: 995,341.00\n",
      "  agent_3 NAV: 1,000,617.00\n",
      "  agent_4 NAV: 1,014,610.00\n",
      "  agent_5 NAV: 1,010,857.00\n",
      "  agent_6 NAV: 1,059,221.00\n",
      "  agent_7 NAV: 973,766.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 4711990696e042fca64f1f44ab0e8239 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8732420.549999988, 'agent_1': -4845760.250000003, 'agent_2': -20546220.45000004, 'agent_3': -5609799.750000002, 'agent_4': -10439249.150000028, 'agent_5': -6702330.300000006, 'agent_6': -3152704.250000003, 'agent_7': -4843058.500000003} id_=4711990696e042fca64f1f44ab0e8239)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 4711990696e042fca64f1f44ab0e8239 NAV Verification ====================\n",
      "  agent_0 NAV: 995,585.00\n",
      "  agent_1 NAV: 991,783.00\n",
      "  agent_2 NAV: 977,170.00\n",
      "  agent_3 NAV: 1,021,498.00\n",
      "  agent_4 NAV: 996,255.00\n",
      "  agent_5 NAV: 1,010,417.00\n",
      "  agent_6 NAV: 1,007,137.00\n",
      "  agent_7 NAV: 1,000,155.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 9391aeed1285465d978fc07c31e3e8aa Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -12979707.31 | Std: 1862972.68 | Threshold: -12793410.04\n",
      "Policy Returns: {'policy_1': -13357622.378260877, 'policy_0': -11174289.74565217, 'policy_6': -17197079.76304347, 'policy_2': -13950891.969565226, 'policy_7': -13040738.026086962, 'policy_4': -11693812.436956517, 'policy_3': -12328124.034782615, 'policy_5': -11095100.136956528}\n",
      "Best Trainable: policy_0 (-11174289.75)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -51103.750000000015, 'agent_1': -387809.64999999997, 'agent_2': -86541.05, 'agent_3': -101255.3, 'agent_4': -92880.25000000001, 'agent_5': -58393.70000000001, 'agent_6': -96624.4, 'agent_7': -159817.89999999997} id_=9391aeed1285465d978fc07c31e3e8aa)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9391aeed1285465d978fc07c31e3e8aa NAV Verification ====================\n",
      "  agent_0 NAV: 1,059,928.00\n",
      "  agent_1 NAV: 930,499.00\n",
      "  agent_2 NAV: 1,000,820.00\n",
      "  agent_3 NAV: 1,003,974.00\n",
      "  agent_4 NAV: 1,053,688.00\n",
      "  agent_5 NAV: 990,656.00\n",
      "  agent_6 NAV: 990,515.00\n",
      "  agent_7 NAV: 969,920.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode f8040493e3524ca7abc1e6c37784cd90 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4399782.250000004, 'agent_1': -23742096.199999988, 'agent_2': -12727679.650000054, 'agent_3': -2210570.250000008, 'agent_4': -8523512.099999988, 'agent_5': -25743188.849999968, 'agent_6': -11142751.35, 'agent_7': -8049598.350000014} id_=f8040493e3524ca7abc1e6c37784cd90)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f8040493e3524ca7abc1e6c37784cd90 NAV Verification ====================\n",
      "  agent_0 NAV: 1,008,150.00\n",
      "  agent_1 NAV: 979,817.00\n",
      "  agent_2 NAV: 986,590.00\n",
      "  agent_3 NAV: 1,018,507.00\n",
      "  agent_4 NAV: 1,014,099.00\n",
      "  agent_5 NAV: 968,443.00\n",
      "  agent_6 NAV: 1,023,774.00\n",
      "  agent_7 NAV: 1,000,620.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode e34d7df278494ab9853c93c833754660 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7160374.900000015, 'agent_1': -53842427.299999915, 'agent_2': -5951296.6000000015, 'agent_3': -5164916.050000007, 'agent_4': -8661766.950000003, 'agent_5': -29609847.89999997, 'agent_6': -10425517.69999996, 'agent_7': -24919872.89999999} id_=e34d7df278494ab9853c93c833754660)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e34d7df278494ab9853c93c833754660 NAV Verification ====================\n",
      "  agent_0 NAV: 1,047,287.00\n",
      "  agent_1 NAV: 899,485.00\n",
      "  agent_2 NAV: 1,018,902.00\n",
      "  agent_3 NAV: 1,027,453.00\n",
      "  agent_4 NAV: 1,054,004.00\n",
      "  agent_5 NAV: 935,902.00\n",
      "  agent_6 NAV: 1,066,659.00\n",
      "  agent_7 NAV: 950,308.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode bdbb4597fa9144b7863992e0ff1cc813 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3957264.250000024, 'agent_1': -8824533.699999966, 'agent_2': -5417830.900000005, 'agent_3': -19024930.199999955, 'agent_4': -16136548.750000045, 'agent_5': -3281208.350000005, 'agent_6': -15110273.90000002, 'agent_7': -19697178.950000007} id_=bdbb4597fa9144b7863992e0ff1cc813)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode bdbb4597fa9144b7863992e0ff1cc813 NAV Verification ====================\n",
      "  agent_0 NAV: 1,009,379.00\n",
      "  agent_1 NAV: 986,681.00\n",
      "  agent_2 NAV: 1,005,565.00\n",
      "  agent_3 NAV: 1,048,678.00\n",
      "  agent_4 NAV: 979,529.00\n",
      "  agent_5 NAV: 1,015,034.00\n",
      "  agent_6 NAV: 985,095.00\n",
      "  agent_7 NAV: 970,039.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode a9a00b8378db460e852b49bd9f79577c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -13043071.48 | Std: 1961371.16 | Threshold: -12846934.36\n",
      "Policy Returns: {'policy_1': -15577611.594444443, 'policy_0': -10365701.479629628, 'policy_6': -16514187.238888886, 'policy_2': -13078331.040740745, 'policy_7': -13489661.97222223, 'policy_4': -11607540.588888885, 'policy_3': -11691214.253703706, 'policy_5': -12020323.646296296}\n",
      "Best Trainable: policy_0 (-10365701.48)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -10365701.48\n",
      "Iteration: 7\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_4 created successfully!\n",
      "✓ League size now: 6 (2 trainable + 4 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -525975.4, 'agent_1': -53695.9, 'agent_2': -327627.6, 'agent_3': -45762.950000000004, 'agent_4': -59228.95000000002, 'agent_5': -766293.0499999997, 'agent_6': -66061.15, 'agent_7': -42541.09999999999} id_=a9a00b8378db460e852b49bd9f79577c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode a9a00b8378db460e852b49bd9f79577c NAV Verification ====================\n",
      "  agent_0 NAV: 920,859.00\n",
      "  agent_1 NAV: 1,039,465.00\n",
      "  agent_2 NAV: 945,092.00\n",
      "  agent_3 NAV: 1,014,509.00\n",
      "  agent_4 NAV: 1,004,871.00\n",
      "  agent_5 NAV: 886,033.00\n",
      "  agent_6 NAV: 1,100,597.00\n",
      "  agent_7 NAV: 1,088,574.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 17db80c39d4d4ddbbad72f9fcbad7fcf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6024226.450000006, 'agent_1': -7380029.899999988, 'agent_2': -8178819.099999991, 'agent_3': -5835829.350000012, 'agent_4': -7750144.899999995, 'agent_5': -11559940.349999934, 'agent_6': -6346089.750000026, 'agent_7': -3429693.6999999937} id_=17db80c39d4d4ddbbad72f9fcbad7fcf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 17db80c39d4d4ddbbad72f9fcbad7fcf NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,354.00\n",
      "  agent_1 NAV: 995,797.00\n",
      "  agent_2 NAV: 1,015,338.00\n",
      "  agent_3 NAV: 996,415.00\n",
      "  agent_4 NAV: 989,269.00\n",
      "  agent_5 NAV: 990,097.00\n",
      "  agent_6 NAV: 988,391.00\n",
      "  agent_7 NAV: 1,020,339.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 8762cca33b4d4a3fb44653f7ad358e26 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -6619071.349999993, 'agent_1': -7199296.299999966, 'agent_2': -4625472.599999994, 'agent_3': -6788217.949999972, 'agent_4': -36347533.200000055, 'agent_5': -5813298.699999992, 'agent_6': -15474503.649999948, 'agent_7': -3077283.749999992} id_=8762cca33b4d4a3fb44653f7ad358e26)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8762cca33b4d4a3fb44653f7ad358e26 NAV Verification ====================\n",
      "  agent_0 NAV: 1,008,264.00\n",
      "  agent_1 NAV: 991,319.00\n",
      "  agent_2 NAV: 1,015,382.00\n",
      "  agent_3 NAV: 986,967.00\n",
      "  agent_4 NAV: 987,155.00\n",
      "  agent_5 NAV: 1,004,927.00\n",
      "  agent_6 NAV: 994,475.00\n",
      "  agent_7 NAV: 1,011,511.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 9348226b1a4149ab943f8c21d2fe70fb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -14610935.449999997, 'agent_1': -19454111.149999976, 'agent_2': -15924604.700000018, 'agent_3': -7181036.1000000145, 'agent_4': -26143505.39999998, 'agent_5': -9687839.149999974, 'agent_6': -13767214.649999982, 'agent_7': -12574140.20000004} id_=9348226b1a4149ab943f8c21d2fe70fb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 9348226b1a4149ab943f8c21d2fe70fb NAV Verification ====================\n",
      "  agent_0 NAV: 987,714.00\n",
      "  agent_1 NAV: 960,278.00\n",
      "  agent_2 NAV: 1,052,022.00\n",
      "  agent_3 NAV: 989,948.00\n",
      "  agent_4 NAV: 950,752.00\n",
      "  agent_5 NAV: 1,043,774.00\n",
      "  agent_6 NAV: 960,415.00\n",
      "  agent_7 NAV: 1,055,097.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode e4d9c7523cfe41709c85fa7eebba0dcb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -12963972.02 | Std: 1636891.10 | Threshold: -12800282.91\n",
      "Policy Returns: {'policy_1': -14841027.048387093, 'policy_0': -10777894.9516129, 'policy_6': -15891176.36290322, 'policy_2': -13108082.477419361, 'policy_7': -12711674.735483877, 'policy_4': -12551645.587096771, 'policy_3': -10888014.493548391, 'policy_5': -12942260.530645166}\n",
      "Best Trainable: policy_0 (-10777894.95)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -136851.05000000002, 'agent_1': -183490.30000000002, 'agent_2': -921579.4999999998, 'agent_3': -174431.19999999995, 'agent_4': -119133.90000000002, 'agent_5': -945566.3499999996, 'agent_6': -111446.94999999997, 'agent_7': -417044.45000000007} id_=e4d9c7523cfe41709c85fa7eebba0dcb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode e4d9c7523cfe41709c85fa7eebba0dcb NAV Verification ====================\n",
      "  agent_0 NAV: 999,215.00\n",
      "  agent_1 NAV: 1,051,428.00\n",
      "  agent_2 NAV: 898,793.00\n",
      "  agent_3 NAV: 1,069,691.00\n",
      "  agent_4 NAV: 1,007,314.00\n",
      "  agent_5 NAV: 902,781.00\n",
      "  agent_6 NAV: 1,026,249.00\n",
      "  agent_7 NAV: 1,044,529.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode debc1211551e4ac2963e27bbf6f4b92a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -11850546.600000013, 'agent_1': -8146820.049999991, 'agent_2': -17660924.349999994, 'agent_3': -3299559.099999988, 'agent_4': -5546810.64999999, 'agent_5': -11036579.049999932, 'agent_6': -16648209.949999996, 'agent_7': -9025788.349999983} id_=debc1211551e4ac2963e27bbf6f4b92a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode debc1211551e4ac2963e27bbf6f4b92a NAV Verification ====================\n",
      "  agent_0 NAV: 1,009,772.00\n",
      "  agent_1 NAV: 1,004,189.00\n",
      "  agent_2 NAV: 974,669.00\n",
      "  agent_3 NAV: 1,017,676.00\n",
      "  agent_4 NAV: 1,004,170.00\n",
      "  agent_5 NAV: 996,191.00\n",
      "  agent_6 NAV: 969,820.00\n",
      "  agent_7 NAV: 1,023,513.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode c13751e3b7d946879b3c370bfd9741e3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -12125868.200000003, 'agent_1': -21111685.049999993, 'agent_2': -9484915.900000043, 'agent_3': -5889327.050000004, 'agent_4': -6368350.2000000095, 'agent_5': -14492450.400000012, 'agent_6': -9889634.699999996, 'agent_7': -6474488.199999981} id_=c13751e3b7d946879b3c370bfd9741e3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode c13751e3b7d946879b3c370bfd9741e3 NAV Verification ====================\n",
      "  agent_0 NAV: 960,096.00\n",
      "  agent_1 NAV: 942,814.00\n",
      "  agent_2 NAV: 1,055,965.00\n",
      "  agent_3 NAV: 1,011,039.00\n",
      "  agent_4 NAV: 1,047,865.00\n",
      "  agent_5 NAV: 947,659.00\n",
      "  agent_6 NAV: 1,005,749.00\n",
      "  agent_7 NAV: 1,028,813.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 6335b59bca6340418c666d315d9605d6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7032800.899999999, 'agent_1': -11571134.249999968, 'agent_2': -14086210.05000001, 'agent_3': -9571497.199999988, 'agent_4': -8445806.500000028, 'agent_5': -10244653.250000026, 'agent_6': -6432236.849999987, 'agent_7': -22592932.39999995} id_=6335b59bca6340418c666d315d9605d6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6335b59bca6340418c666d315d9605d6 NAV Verification ====================\n",
      "  agent_0 NAV: 999,912.00\n",
      "  agent_1 NAV: 1,020,232.00\n",
      "  agent_2 NAV: 990,255.00\n",
      "  agent_3 NAV: 991,272.00\n",
      "  agent_4 NAV: 1,018,882.00\n",
      "  agent_5 NAV: 1,028,666.00\n",
      "  agent_6 NAV: 1,000,302.00\n",
      "  agent_7 NAV: 950,479.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode eaa737cac1384596bb16263b39997638 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -12908726.79 | Std: 1703662.95 | Threshold: -12738360.50\n",
      "Policy Returns: {'policy_1': -14637998.51285714, 'policy_0': -10579770.569999997, 'policy_6': -15257772.955714278, 'policy_2': -13976750.392857153, 'policy_7': -12851326.534285717, 'policy_4': -11927040.365714282, 'policy_3': -10346488.500000002, 'policy_5': -13692666.514285713}\n",
      "Best Trainable: policy_0 (-10579770.57)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -10579770.57\n",
      "Iteration: 9\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_5 created successfully!\n",
      "✓ League size now: 7 (2 trainable + 5 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -146782.0, 'agent_1': -74644.09999999999, 'agent_2': -403187.6, 'agent_3': -124691.74999999999, 'agent_4': -497867.24999999994, 'agent_5': -853232.15, 'agent_6': -105958.80000000002, 'agent_7': -34442.35} id_=eaa737cac1384596bb16263b39997638)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode eaa737cac1384596bb16263b39997638 NAV Verification ====================\n",
      "  agent_0 NAV: 1,022,488.00\n",
      "  agent_1 NAV: 993,018.00\n",
      "  agent_2 NAV: 1,054,964.00\n",
      "  agent_3 NAV: 989,115.00\n",
      "  agent_4 NAV: 969,033.00\n",
      "  agent_5 NAV: 932,565.00\n",
      "  agent_6 NAV: 1,029,908.00\n",
      "  agent_7 NAV: 1,008,909.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 71f4b15a6b6b448c9a9f9c517b35ea55 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> champion_5\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -9725159.699999996, 'agent_1': -19771807.400000006, 'agent_2': -18862099.74999998, 'agent_3': -4460966.499999998, 'agent_4': -8406350.95, 'agent_5': -2622590.800000003, 'agent_6': -18432918.60000004, 'agent_7': -17874953.89999998} id_=71f4b15a6b6b448c9a9f9c517b35ea55)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 71f4b15a6b6b448c9a9f9c517b35ea55 NAV Verification ====================\n",
      "  agent_0 NAV: 994,765.00\n",
      "  agent_1 NAV: 941,081.00\n",
      "  agent_2 NAV: 960,923.00\n",
      "  agent_3 NAV: 1,020,064.00\n",
      "  agent_4 NAV: 1,035,723.00\n",
      "  agent_5 NAV: 1,020,675.00\n",
      "  agent_6 NAV: 968,016.00\n",
      "  agent_7 NAV: 1,058,753.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 1f07df1830a047d1a30e99f5efaeef1f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -11584648.700000003, 'agent_1': -5268533.899999997, 'agent_2': -20660839.499999955, 'agent_3': -17284353.59999998, 'agent_4': -14738775.749999994, 'agent_5': -6801972.950000003, 'agent_6': -5976587.100000004, 'agent_7': -2632246.599999996} id_=1f07df1830a047d1a30e99f5efaeef1f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 1f07df1830a047d1a30e99f5efaeef1f NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,939.00\n",
      "  agent_1 NAV: 983,594.00\n",
      "  agent_2 NAV: 981,071.00\n",
      "  agent_3 NAV: 991,732.00\n",
      "  agent_4 NAV: 1,003,947.00\n",
      "  agent_5 NAV: 1,008,680.00\n",
      "  agent_6 NAV: 1,007,543.00\n",
      "  agent_7 NAV: 1,022,494.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 42ceba3e54a149469c6d1ec1f313b690 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8624891.400000013, 'agent_1': -6992616.650000017, 'agent_2': -8007179.150000012, 'agent_3': -7804250.149999981, 'agent_4': -5751175.450000007, 'agent_5': -5387707.450000002, 'agent_6': -25200926.549999982, 'agent_7': -2535811.5000000047} id_=42ceba3e54a149469c6d1ec1f313b690)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 42ceba3e54a149469c6d1ec1f313b690 NAV Verification ====================\n",
      "  agent_0 NAV: 991,902.00\n",
      "  agent_1 NAV: 1,032,253.00\n",
      "  agent_2 NAV: 983,846.00\n",
      "  agent_3 NAV: 1,042,587.00\n",
      "  agent_4 NAV: 1,005,917.00\n",
      "  agent_5 NAV: 993,479.00\n",
      "  agent_6 NAV: 945,863.00\n",
      "  agent_7 NAV: 1,004,153.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 934a0926d16049db9f644016f72fb5aa Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -12790804.12 | Std: 1693341.46 | Threshold: -12621469.97\n",
      "Policy Returns: {'policy_1': -14177399.525641022, 'policy_0': -10477044.06282051, 'policy_6': -15184185.330769224, 'policy_2': -14262753.346153852, 'policy_7': -12230453.024358977, 'policy_4': -12099770.788461534, 'policy_3': -10280970.25, 'policy_5': -13613856.6025641}\n",
      "Best Trainable: policy_0 (-10477044.06)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -169181.24999999994, 'agent_1': -122450.85000000003, 'agent_2': -211324.75000000003, 'agent_3': -123151.90000000004, 'agent_4': -113902.74999999999, 'agent_5': -262542.69999999995, 'agent_6': -106623.44999999997, 'agent_7': -350196.4499999999} id_=934a0926d16049db9f644016f72fb5aa)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 934a0926d16049db9f644016f72fb5aa NAV Verification ====================\n",
      "  agent_0 NAV: 999,804.00\n",
      "  agent_1 NAV: 986,442.00\n",
      "  agent_2 NAV: 992,098.00\n",
      "  agent_3 NAV: 1,001,896.00\n",
      "  agent_4 NAV: 997,492.00\n",
      "  agent_5 NAV: 1,031,668.00\n",
      "  agent_6 NAV: 1,027,087.00\n",
      "  agent_7 NAV: 963,513.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 996ef2a15e0147e096c82fdb1104e974 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_4\n",
      "  agent_4 -> policy_5\n",
      "  agent_5 -> policy_6\n",
      "  agent_6 -> policy_7\n",
      "  agent_7 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8594640.850000016, 'agent_1': -7288436.999999982, 'agent_2': -7899558.599999984, 'agent_3': -20647525.399999987, 'agent_4': -6587371.100000003, 'agent_5': -12522079.49999999, 'agent_6': -5940137.149999996, 'agent_7': -15900888.800000003} id_=996ef2a15e0147e096c82fdb1104e974)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 996ef2a15e0147e096c82fdb1104e974 NAV Verification ====================\n",
      "  agent_0 NAV: 989,816.00\n",
      "  agent_1 NAV: 992,658.00\n",
      "  agent_2 NAV: 1,001,400.00\n",
      "  agent_3 NAV: 990,031.00\n",
      "  agent_4 NAV: 1,001,310.00\n",
      "  agent_5 NAV: 1,022,106.00\n",
      "  agent_6 NAV: 1,008,119.00\n",
      "  agent_7 NAV: 994,560.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 205a8001875845afa52e69f965b18963 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -9817394.049999982, 'agent_1': -12909240.25, 'agent_2': -7466146.899999981, 'agent_3': -26904931.29999997, 'agent_4': -25875566.699999955, 'agent_5': -3416862.3000000026, 'agent_6': -8993451.999999989, 'agent_7': -12573455.39999999} id_=205a8001875845afa52e69f965b18963)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 205a8001875845afa52e69f965b18963 NAV Verification ====================\n",
      "  agent_0 NAV: 987,377.00\n",
      "  agent_1 NAV: 986,473.00\n",
      "  agent_2 NAV: 1,046,836.00\n",
      "  agent_3 NAV: 949,647.00\n",
      "  agent_4 NAV: 935,568.00\n",
      "  agent_5 NAV: 1,000,058.00\n",
      "  agent_6 NAV: 1,045,674.00\n",
      "  agent_7 NAV: 1,048,367.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 2e1aad66a10648238360d8e59282a8ff Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_4\n",
      "  agent_3 -> policy_5\n",
      "  agent_4 -> policy_6\n",
      "  agent_5 -> policy_7\n",
      "  agent_6 -> champion_1\n",
      "  agent_7 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -9236011.649999984, 'agent_1': -33765434.45000003, 'agent_2': -19854492.750000007, 'agent_3': -18299787.799999956, 'agent_4': -26431845.55, 'agent_5': -7146167.599999998, 'agent_6': -3428946.1499999976, 'agent_7': -12371860.550000004} id_=2e1aad66a10648238360d8e59282a8ff)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 2e1aad66a10648238360d8e59282a8ff NAV Verification ====================\n",
      "  agent_0 NAV: 995,851.00\n",
      "  agent_1 NAV: 958,350.00\n",
      "  agent_2 NAV: 1,039,515.00\n",
      "  agent_3 NAV: 984,327.00\n",
      "  agent_4 NAV: 956,707.00\n",
      "  agent_5 NAV: 1,014,446.00\n",
      "  agent_6 NAV: 1,010,631.00\n",
      "  agent_7 NAV: 1,040,173.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode f66330f04cc640d38d24728421ea21f9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> champion_5\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -12837374.19 | Std: 1362458.65 | Threshold: -12701128.32\n",
      "Policy Returns: {'policy_1': -14293431.129069766, 'policy_0': -10543859.40813953, 'policy_6': -14438098.411627902, 'policy_2': -14030697.97325582, 'policy_7': -12533755.194186047, 'policy_4': -12477556.806976743, 'policy_3': -11089452.50581395, 'policy_5': -13292142.087209303}\n",
      "Best Trainable: policy_0 (-10543859.41)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -10543859.41\n",
      "Iteration: 11\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_6 created successfully!\n",
      "✓ League size now: 8 (2 trainable + 6 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -125573.54999999999, 'agent_1': -131383.94999999998, 'agent_2': -48037.14999999999, 'agent_3': -216351.0, 'agent_4': -117054.25000000001, 'agent_5': -831820.6499999998, 'agent_6': -173809.05, 'agent_7': -1885845.4000000004} id_=f66330f04cc640d38d24728421ea21f9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f66330f04cc640d38d24728421ea21f9 NAV Verification ====================\n",
      "  agent_0 NAV: 1,096,030.00\n",
      "  agent_1 NAV: 1,053,585.00\n",
      "  agent_2 NAV: 1,001,839.00\n",
      "  agent_3 NAV: 994,924.00\n",
      "  agent_4 NAV: 999,718.00\n",
      "  agent_5 NAV: 922,980.00\n",
      "  agent_6 NAV: 1,119,133.00\n",
      "  agent_7 NAV: 811,791.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 0040dcdd00d9484fa193ccb562103c6c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> champion_5\n",
      "  agent_7 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3976941.0999999866, 'agent_1': -15229088.84999994, 'agent_2': -5275602.800000009, 'agent_3': -4652599.85, 'agent_4': -8203121.9999999935, 'agent_5': -5847902.899999984, 'agent_6': -11453989.349999975, 'agent_7': -20914273.649999984} id_=0040dcdd00d9484fa193ccb562103c6c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 0040dcdd00d9484fa193ccb562103c6c NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,450.00\n",
      "  agent_1 NAV: 1,011,397.00\n",
      "  agent_2 NAV: 1,001,550.00\n",
      "  agent_3 NAV: 1,008,548.00\n",
      "  agent_4 NAV: 997,037.00\n",
      "  agent_5 NAV: 1,013,969.00\n",
      "  agent_6 NAV: 994,456.00\n",
      "  agent_7 NAV: 968,593.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 8e910952f3a141c792cae74198e42bdf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5305644.700000006, 'agent_1': -12492527.700000005, 'agent_2': -14566182.85000001, 'agent_3': -13627719.099999998, 'agent_4': -14786141.04999999, 'agent_5': -10720104.599999957, 'agent_6': -20748104.549999937, 'agent_7': -8510994.55000001} id_=8e910952f3a141c792cae74198e42bdf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 8e910952f3a141c792cae74198e42bdf NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,006.00\n",
      "  agent_1 NAV: 982,627.00\n",
      "  agent_2 NAV: 1,012,300.00\n",
      "  agent_3 NAV: 983,287.00\n",
      "  agent_4 NAV: 1,030,800.00\n",
      "  agent_5 NAV: 997,525.00\n",
      "  agent_6 NAV: 971,880.00\n",
      "  agent_7 NAV: 1,008,575.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 678d6ccbf4864745885dbf4dd3c16d7b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -16779681.699999977, 'agent_1': -11923239.0, 'agent_2': -15860431.949999986, 'agent_3': -11432259.649999995, 'agent_4': -38567221.599999994, 'agent_5': -4594685.549999999, 'agent_6': -10798367.19999997, 'agent_7': -5245873.249999998} id_=678d6ccbf4864745885dbf4dd3c16d7b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 678d6ccbf4864745885dbf4dd3c16d7b NAV Verification ====================\n",
      "  agent_0 NAV: 953,621.00\n",
      "  agent_1 NAV: 1,020,259.00\n",
      "  agent_2 NAV: 933,630.00\n",
      "  agent_3 NAV: 1,098,306.00\n",
      "  agent_4 NAV: 860,646.00\n",
      "  agent_5 NAV: 1,062,952.00\n",
      "  agent_6 NAV: 1,051,159.00\n",
      "  agent_7 NAV: 1,019,427.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 3c3fc1a09ce444598f878c6a034bc909 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> champion_5\n",
      "  agent_5 -> champion_6\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -12931182.45 | Std: 1404141.63 | Threshold: -12790768.29\n",
      "Policy Returns: {'policy_1': -14214404.926595742, 'policy_0': -10413429.395744676, 'policy_6': -14446959.413829781, 'policy_2': -13689001.930851066, 'policy_7': -13753909.511702124, 'policy_4': -12834744.631914891, 'policy_3': -10892892.5393617, 'policy_5': -13204117.281914888}\n",
      "Best Trainable: policy_0 (-10413429.40)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -99915.09999999999, 'agent_1': -231495.84999999998, 'agent_2': -117462.64999999998, 'agent_3': -252735.49999999994, 'agent_4': -104873.24999999999, 'agent_5': -56530.5, 'agent_6': -113417.45000000001, 'agent_7': -209104.59999999998} id_=3c3fc1a09ce444598f878c6a034bc909)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 3c3fc1a09ce444598f878c6a034bc909 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,352.00\n",
      "  agent_1 NAV: 989,380.00\n",
      "  agent_2 NAV: 1,012,933.00\n",
      "  agent_3 NAV: 1,004,025.00\n",
      "  agent_4 NAV: 1,008,879.00\n",
      "  agent_5 NAV: 996,494.00\n",
      "  agent_6 NAV: 997,814.00\n",
      "  agent_7 NAV: 987,123.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 903903e7c7834b6893dc60a9e174b845 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5076296.500000003, 'agent_1': -16731744.249999985, 'agent_2': -5399207.74999998, 'agent_3': -4503728.65, 'agent_4': -7690875.649999999, 'agent_5': -10852073.950000035, 'agent_6': -20512318.049999975, 'agent_7': -25542047.69999997} id_=903903e7c7834b6893dc60a9e174b845)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 903903e7c7834b6893dc60a9e174b845 NAV Verification ====================\n",
      "  agent_0 NAV: 1,034,721.00\n",
      "  agent_1 NAV: 1,018,535.00\n",
      "  agent_2 NAV: 998,122.00\n",
      "  agent_3 NAV: 980,744.00\n",
      "  agent_4 NAV: 973,879.00\n",
      "  agent_5 NAV: 993,301.00\n",
      "  agent_6 NAV: 968,787.00\n",
      "  agent_7 NAV: 1,031,911.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 95b3af6a15334e7b8eaa8ed7d6293f3c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -3092052.300000009, 'agent_1': -11612365.699999994, 'agent_2': -3873002.2500000037, 'agent_3': -17954697.800000045, 'agent_4': -26153445.30000003, 'agent_5': -6928082.2499999795, 'agent_6': -9692818.699999992, 'agent_7': -16963759.799999993} id_=95b3af6a15334e7b8eaa8ed7d6293f3c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 95b3af6a15334e7b8eaa8ed7d6293f3c NAV Verification ====================\n",
      "  agent_0 NAV: 1,038,517.00\n",
      "  agent_1 NAV: 1,050,527.00\n",
      "  agent_2 NAV: 1,006,520.00\n",
      "  agent_3 NAV: 965,493.00\n",
      "  agent_4 NAV: 925,894.00\n",
      "  agent_5 NAV: 1,039,208.00\n",
      "  agent_6 NAV: 1,041,364.00\n",
      "  agent_7 NAV: 932,477.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 6a2c8ff991ae44548605c08608d15f08 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> champion_4\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -4958448.750000015, 'agent_1': -14368684.00000001, 'agent_2': -7711510.700000005, 'agent_3': -19276518.949999984, 'agent_4': -3722465.950000006, 'agent_5': -16425971.400000047, 'agent_6': -5055265.050000001, 'agent_7': -5683683.400000002} id_=6a2c8ff991ae44548605c08608d15f08)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 6a2c8ff991ae44548605c08608d15f08 NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,274.00\n",
      "  agent_1 NAV: 954,909.00\n",
      "  agent_2 NAV: 1,000,050.00\n",
      "  agent_3 NAV: 1,020,196.00\n",
      "  agent_4 NAV: 1,011,590.00\n",
      "  agent_5 NAV: 972,545.00\n",
      "  agent_6 NAV: 988,307.00\n",
      "  agent_7 NAV: 1,046,129.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode ec9742ed48f64fafb4f2a453bfcd6ebe Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_7\n",
      "  agent_3 -> champion_1\n",
      "  agent_4 -> champion_2\n",
      "  agent_5 -> champion_3\n",
      "  agent_6 -> champion_4\n",
      "  agent_7 -> champion_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -12709998.97 | Std: 1417426.39 | Threshold: -12568256.33\n",
      "Policy Returns: {'policy_1': -14159529.49509804, 'policy_0': -9951771.335294116, 'policy_6': -14130124.07941176, 'policy_2': -13007311.790196082, 'policy_7': -13853092.174509801, 'policy_4': -12651196.32745098, 'policy_3': -11005887.155882351, 'policy_5': -12921079.410784315}\n",
      "Best Trainable: policy_0 (-9951771.34)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -9951771.34\n",
      "Iteration: 13\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_7 created successfully!\n",
      "✓ League size now: 9 (2 trainable + 7 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -565780.2499999999, 'agent_1': -288648.6000000001, 'agent_2': -92396.1, 'agent_3': -506318.89999999997, 'agent_4': -92151.45, 'agent_5': -940310.7999999995, 'agent_6': -96496.15, 'agent_7': -101108.25000000001} id_=ec9742ed48f64fafb4f2a453bfcd6ebe)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode ec9742ed48f64fafb4f2a453bfcd6ebe NAV Verification ====================\n",
      "  agent_0 NAV: 967,249.00\n",
      "  agent_1 NAV: 1,053,607.00\n",
      "  agent_2 NAV: 1,024,651.00\n",
      "  agent_3 NAV: 957,827.00\n",
      "  agent_4 NAV: 993,980.00\n",
      "  agent_5 NAV: 921,638.00\n",
      "  agent_6 NAV: 1,011,104.00\n",
      "  agent_7 NAV: 1,069,944.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 52fdc87a716345c48805cb5ab35150b5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -18735661.249999993, 'agent_1': -8873127.250000024, 'agent_2': -13277688.150000025, 'agent_3': -8061267.400000009, 'agent_4': -25753432.799999982, 'agent_5': -5074734.699999995, 'agent_6': -7477414.649999997, 'agent_7': -9615133.000000024} id_=52fdc87a716345c48805cb5ab35150b5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 52fdc87a716345c48805cb5ab35150b5 NAV Verification ====================\n",
      "  agent_0 NAV: 959,639.00\n",
      "  agent_1 NAV: 1,037,247.00\n",
      "  agent_2 NAV: 996,975.00\n",
      "  agent_3 NAV: 1,042,247.00\n",
      "  agent_4 NAV: 901,610.00\n",
      "  agent_5 NAV: 1,037,879.00\n",
      "  agent_6 NAV: 1,057,692.00\n",
      "  agent_7 NAV: 966,711.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode b32364793e904f0fa13fc600cce92ac0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> champion_6\n",
      "  agent_5 -> champion_7\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -5416708.350000004, 'agent_1': -8365584.750000018, 'agent_2': -12180134.049999937, 'agent_3': -6491734.800000001, 'agent_4': -15557240.899999972, 'agent_5': -8131774.449999981, 'agent_6': -5877203.699999999, 'agent_7': -6267883.199999998} id_=b32364793e904f0fa13fc600cce92ac0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode b32364793e904f0fa13fc600cce92ac0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,006,065.00\n",
      "  agent_1 NAV: 1,008,261.00\n",
      "  agent_2 NAV: 983,890.00\n",
      "  agent_3 NAV: 1,013,548.00\n",
      "  agent_4 NAV: 983,246.00\n",
      "  agent_5 NAV: 997,640.00\n",
      "  agent_6 NAV: 1,008,038.00\n",
      "  agent_7 NAV: 999,312.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 7cb145a037e2418381102d08bafee4ab Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7715075.850000023, 'agent_1': -17597691.549999982, 'agent_2': -23264190.700000044, 'agent_3': -19867495.449999917, 'agent_4': -14395801.300000029, 'agent_5': -10462188.600000018, 'agent_6': -8535338.25, 'agent_7': -23532073.69999996} id_=7cb145a037e2418381102d08bafee4ab)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 7cb145a037e2418381102d08bafee4ab NAV Verification ====================\n",
      "  agent_0 NAV: 1,012,292.00\n",
      "  agent_1 NAV: 973,073.00\n",
      "  agent_2 NAV: 990,694.00\n",
      "  agent_3 NAV: 1,012,319.00\n",
      "  agent_4 NAV: 1,018,785.00\n",
      "  agent_5 NAV: 987,289.00\n",
      "  agent_6 NAV: 982,541.00\n",
      "  agent_7 NAV: 1,023,007.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 2a318ca3cc864353b22657da8f64dea7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_6\n",
      "  agent_3 -> policy_7\n",
      "  agent_4 -> champion_1\n",
      "  agent_5 -> champion_2\n",
      "  agent_6 -> champion_3\n",
      "  agent_7 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -12698772.89 | Std: 1197365.57 | Threshold: -12579036.33\n",
      "Policy Returns: {'policy_1': -13937853.597272728, 'policy_0': -10295681.048181815, 'policy_6': -13560451.749999996, 'policy_2': -13000622.714545459, 'policy_7': -13652729.299090905, 'policy_4': -12850176.513636362, 'policy_3': -11202309.142727269, 'policy_5': -13090359.018181818}\n",
      "Best Trainable: policy_0 (-10295681.05)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -275116.7499999999, 'agent_1': -636207.0500000005, 'agent_2': -369667.75, 'agent_3': -204140.55000000002, 'agent_4': -214369.99999999994, 'agent_5': -294215.69999999995, 'agent_6': -47040.5, 'agent_7': -240034.30000000002} id_=2a318ca3cc864353b22657da8f64dea7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 2a318ca3cc864353b22657da8f64dea7 NAV Verification ====================\n",
      "  agent_0 NAV: 999,607.00\n",
      "  agent_1 NAV: 990,200.00\n",
      "  agent_2 NAV: 979,305.00\n",
      "  agent_3 NAV: 1,000,271.00\n",
      "  agent_4 NAV: 1,004,241.00\n",
      "  agent_5 NAV: 1,002,726.00\n",
      "  agent_6 NAV: 1,003,380.00\n",
      "  agent_7 NAV: 1,020,270.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 5964f647dfc94e8fbb9e286d14eeb6bb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "  agent_4 -> champion_7\n",
      "  agent_5 -> policy_2\n",
      "  agent_6 -> policy_3\n",
      "  agent_7 -> policy_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -18937208.849999953, 'agent_1': -5929460.250000004, 'agent_2': -26993815.40000004, 'agent_3': -7708192.900000003, 'agent_4': -15464217.200000009, 'agent_5': -6439740.100000011, 'agent_6': -10414736.850000026, 'agent_7': -10348158.449999953} id_=5964f647dfc94e8fbb9e286d14eeb6bb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 5964f647dfc94e8fbb9e286d14eeb6bb NAV Verification ====================\n",
      "  agent_0 NAV: 1,073,172.00\n",
      "  agent_1 NAV: 980,436.00\n",
      "  agent_2 NAV: 943,078.00\n",
      "  agent_3 NAV: 981,350.00\n",
      "  agent_4 NAV: 987,807.00\n",
      "  agent_5 NAV: 1,009,789.00\n",
      "  agent_6 NAV: 973,130.00\n",
      "  agent_7 NAV: 1,051,238.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 40f67c29498e48fcafdfb39597b919d5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "  agent_4 -> champion_4\n",
      "  agent_5 -> champion_5\n",
      "  agent_6 -> champion_6\n",
      "  agent_7 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -7511193.150000015, 'agent_1': -13726097.30000003, 'agent_2': -17163987.34999996, 'agent_3': -12847127.200000023, 'agent_4': -6889163.350000002, 'agent_5': -8707673.849999981, 'agent_6': -3838178.450000005, 'agent_7': -10923705.150000015} id_=40f67c29498e48fcafdfb39597b919d5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 40f67c29498e48fcafdfb39597b919d5 NAV Verification ====================\n",
      "  agent_0 NAV: 995,843.00\n",
      "  agent_1 NAV: 979,099.00\n",
      "  agent_2 NAV: 987,644.00\n",
      "  agent_3 NAV: 1,000,532.00\n",
      "  agent_4 NAV: 1,001,146.00\n",
      "  agent_5 NAV: 1,006,968.00\n",
      "  agent_6 NAV: 1,007,482.00\n",
      "  agent_7 NAV: 1,021,286.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 05e9210c5d2e4f018f0c92aa03a9a9e7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "  agent_4 -> champion_6\n",
      "  agent_5 -> champion_7\n",
      "  agent_6 -> policy_2\n",
      "  agent_7 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -26221243.74999999, 'agent_1': -13699058.449999966, 'agent_2': -4180370.8500000113, 'agent_3': -7739435.899999995, 'agent_4': -6238512.449999986, 'agent_5': -11280403.64999994, 'agent_6': -23261232.1, 'agent_7': -5153778.050000006} id_=05e9210c5d2e4f018f0c92aa03a9a9e7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 05e9210c5d2e4f018f0c92aa03a9a9e7 NAV Verification ====================\n",
      "  agent_0 NAV: 960,435.00\n",
      "  agent_1 NAV: 1,048,223.00\n",
      "  agent_2 NAV: 1,012,727.00\n",
      "  agent_3 NAV: 985,352.00\n",
      "  agent_4 NAV: 1,022,602.00\n",
      "  agent_5 NAV: 986,750.00\n",
      "  agent_6 NAV: 956,333.00\n",
      "  agent_7 NAV: 1,027,578.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 67f2e6fd2c504db48a7c6a4fb6416c84 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "  agent_4 -> policy_2\n",
      "  agent_5 -> policy_3\n",
      "  agent_6 -> policy_4\n",
      "  agent_7 -> policy_5\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -12650118.75 | Std: 1063261.97 | Threshold: -12543792.55\n",
      "Policy Returns: {'policy_1': -13965185.90254237, 'policy_0': -10748080.228813557, 'policy_6': -13389329.811016943, 'policy_2': -13160768.624576276, 'policy_7': -13398385.991525419, 'policy_4': -12563599.855084745, 'policy_3': -11137759.36779661, 'policy_5': -12837840.194915254}\n",
      "Best Trainable: policy_0 (-10748080.23)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -10748080.23\n",
      "Iteration: 15\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_8 created successfully!\n",
      "✓ League size now: 10 (2 trainable + 8 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -245055.04999999996, 'agent_1': -615517.3, 'agent_2': -122593.44999999998, 'agent_3': -613854.2, 'agent_4': -460660.50000000023, 'agent_5': -198000.15, 'agent_6': -433343.7000000001, 'agent_7': -630179.25} id_=67f2e6fd2c504db48a7c6a4fb6416c84)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 67f2e6fd2c504db48a7c6a4fb6416c84 NAV Verification ====================\n",
      "  agent_0 NAV: 1,053,445.00\n",
      "  agent_1 NAV: 1,016,108.00\n",
      "  agent_2 NAV: 1,005,052.00\n",
      "  agent_3 NAV: 962,130.00\n",
      "  agent_4 NAV: 970,207.00\n",
      "  agent_5 NAV: 988,745.00\n",
      "  agent_6 NAV: 969,926.00\n",
      "  agent_7 NAV: 1,034,387.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 7fe91cf24e9a45f883852b15d0391f32 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_8\n",
      "  agent_3 -> policy_2\n",
      "  agent_4 -> policy_3\n",
      "  agent_5 -> policy_4\n",
      "  agent_6 -> policy_5\n",
      "  agent_7 -> policy_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -8624589.9, 'agent_1': -15292229.55000006, 'agent_2': -15829298.900000004, 'agent_3': -15884260.199999997, 'agent_4': -11894235.299999956, 'agent_5': -24222756.69999998, 'agent_6': -23274011.10000005, 'agent_7': -6214199.049999997} id_=7fe91cf24e9a45f883852b15d0391f32)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 7fe91cf24e9a45f883852b15d0391f32 NAV Verification ====================\n",
      "  agent_0 NAV: 992,242.00\n",
      "  agent_1 NAV: 1,032,926.00\n",
      "  agent_2 NAV: 1,008,769.00\n",
      "  agent_3 NAV: 980,782.00\n",
      "  agent_4 NAV: 997,659.00\n",
      "  agent_5 NAV: 973,629.00\n",
      "  agent_6 NAV: 1,017,072.00\n",
      "  agent_7 NAV: 996,921.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 5d93483e2bda4921ac61bba7d2830554 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "  agent_4 -> champion_5\n",
      "  agent_5 -> champion_6\n",
      "  agent_6 -> champion_7\n",
      "  agent_7 -> champion_8\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -12573837.750000011, 'agent_1': -31010876.699999936, 'agent_2': -5682945.000000025, 'agent_3': -5366599.849999986, 'agent_4': -11639617.099999987, 'agent_5': -20095094.750000026, 'agent_6': -5049159.200000001, 'agent_7': -3946689.350000011} id_=5d93483e2bda4921ac61bba7d2830554)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode 5d93483e2bda4921ac61bba7d2830554 NAV Verification ====================\n",
      "  agent_0 NAV: 981,984.00\n",
      "  agent_1 NAV: 964,348.00\n",
      "  agent_2 NAV: 1,015,547.00\n",
      "  agent_3 NAV: 1,000,342.00\n",
      "  agent_4 NAV: 1,011,694.00\n",
      "  agent_5 NAV: 988,592.00\n",
      "  agent_6 NAV: 1,013,426.00\n",
      "  agent_7 NAV: 1,024,067.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode f142580b865a42d0b12251aa1bcfc17b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "  agent_4 -> policy_4\n",
      "  agent_5 -> policy_5\n",
      "  agent_6 -> policy_6\n",
      "  agent_7 -> policy_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=4097 done=True Rs={'agent_0': -9540187.549999993, 'agent_1': -14794112.750000011, 'agent_2': -7676029.299999995, 'agent_3': -7784525.54999999, 'agent_4': -13331711.399999978, 'agent_5': -4779080.949999991, 'agent_6': -8822967.599999968, 'agent_7': -7701085.799999995} id_=f142580b865a42d0b12251aa1bcfc17b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 8\n",
      "DEBUG: total_initial_cash: 8000000.0\n",
      "\n",
      "==================== Episode f142580b865a42d0b12251aa1bcfc17b NAV Verification ====================\n",
      "  agent_0 NAV: 989,238.00\n",
      "  agent_1 NAV: 1,006,930.00\n",
      "  agent_2 NAV: 1,016,952.00\n",
      "  agent_3 NAV: 1,003,881.00\n",
      "  agent_4 NAV: 1,002,330.00\n",
      "  agent_5 NAV: 997,305.00\n",
      "  agent_6 NAV: 980,848.00\n",
      "  agent_7 NAV: 1,002,516.00\n",
      "  Total NAV: 8,000,000.00\n",
      "  Expected Total Initial Cash: 8,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode d55e042ae9af4f86843278dfecac7b15 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "  agent_4 -> champion_3\n",
      "  agent_5 -> champion_4\n",
      "  agent_6 -> champion_5\n",
      "  agent_7 -> champion_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'policy_4', 'policy_5', 'policy_6', 'policy_7', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -12637192.28 | Std: 1057317.38 | Threshold: -12531460.54\n",
      "Policy Returns: {'policy_1': -14223507.086507933, 'policy_0': -10663536.48174603, 'policy_6': -13377218.379365075, 'policy_2': -12914080.290476194, 'policy_7': -13022582.27460317, 'policy_4': -12593510.438095236, 'policy_3': -11349923.397619046, 'policy_5': -12953179.916666666}\n",
      "Best Trainable: policy_0 (-10663536.48)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ← KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-13 21:35:32\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Get current time in SGT (Singapore Time)\n",
    "sgt_time = datetime.now(ZoneInfo(\"Asia/Singapore\"))\n",
    "formatted_datetime = sgt_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
