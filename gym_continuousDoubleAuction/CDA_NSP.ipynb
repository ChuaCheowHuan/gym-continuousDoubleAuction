{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 11:23:47\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Get current time in SGT (Singapore Time)\n",
    "sgt_time = datetime.now(ZoneInfo(\"Asia/Singapore\"))\n",
    "formatted_datetime = sgt_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"❌ No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 03:23:49,837\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2026-01-11 03:23:51,706\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_3', 'agent_0', 'agent_1', 'agent_2']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 03:23:54,374\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.75gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2026-01-11 03:23:55,527\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"d3bae1e5-28fd-4e65-b9ad-8b1b1b8f517b\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 4\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x7382e86aaa70>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x7382e86aaa40>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x7382e86aaaa0>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x7382e86a90c0>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=8,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ← ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 03:23:55,869\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2026-01-11 03:23:55,871\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 4096\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2026-01-11 03:23:56,125\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2026-01-11 03:23:56,134\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2026-01-11 03:23:56,145\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2026-01-11 03:23:56,167\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2026-01-11 03:23:56,178\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2026-01-11 03:23:56,188\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2026-01-11 03:23:56,190\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2026-01-11 03:23:56,235\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,235\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,236\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,236\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,237\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,251\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,251\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2026-01-11 03:23:56,253\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32)), Dict('agent_0': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_1': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_2': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_3': Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))), 'policy_0': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_1': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_2': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_3': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(10), 'price_offset': Discrete(3), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))}\n",
      "2026-01-11 03:23:56,297\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:56,297\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:56,307\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:56,316\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:56,325\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:56,334\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:56,344\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:59,175\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2026-01-11 03:23:59,209\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 4096\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 121377d478b8411a832dddd56eb31862 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -92152904.93112509, 'agent_1': -254767835.5049366, 'agent_2': -110720453.04256678, 'agent_3': -95674775.56082979} id_=121377d478b8411a832dddd56eb31862)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 121377d478b8411a832dddd56eb31862 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,440.00\n",
      "  agent_1 NAV: 995,470.00\n",
      "  agent_2 NAV: 981,224.00\n",
      "  agent_3 NAV: 1,018,866.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 23f16d1ff5f549ec9505c761297a5ee2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -188294049.37542257, 'agent_1': -222244900.92037317, 'agent_2': -113549750.96006139, 'agent_3': -352093002.1851452} id_=23f16d1ff5f549ec9505c761297a5ee2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 23f16d1ff5f549ec9505c761297a5ee2 NAV Verification ====================\n",
      "  agent_0 NAV: 994,128.00\n",
      "  agent_1 NAV: 996,365.00\n",
      "  agent_2 NAV: 1,000,000.00\n",
      "  agent_3 NAV: 1,009,507.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 4d02129ac2664a77bf9de949947f6d3c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -221674755.2757059, 'agent_1': -58767919.737863906, 'agent_2': -42761101.93813946, 'agent_3': -187428986.48038623} id_=4d02129ac2664a77bf9de949947f6d3c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4d02129ac2664a77bf9de949947f6d3c NAV Verification ====================\n",
      "  agent_0 NAV: 1,002,310.00\n",
      "  agent_1 NAV: 997,281.00\n",
      "  agent_2 NAV: 1,013,281.00\n",
      "  agent_3 NAV: 987,128.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode d802d306ac324c569dc4a5f8e6729341 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -161677536.33 | Std: 45012727.61 | Threshold: -157176263.56\n",
      "Policy Returns: {'policy_2': -89010435.3135892, 'policy_3': -211732254.74212041, 'policy_1': -178593552.05439124, 'policy_0': -167373903.19408453}\n",
      "Best Trainable: policy_0 (-167373903.19)\n",
      "================================================================================\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': 0.0, 'agent_1': 0.0, 'agent_2': 0.0, 'agent_3': 0.0} id_=d802d306ac324c569dc4a5f8e6729341)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d802d306ac324c569dc4a5f8e6729341 NAV Verification ====================\n",
      "  agent_0 NAV: 998,084.00\n",
      "  agent_1 NAV: 990,909.00\n",
      "  agent_2 NAV: 991,803.00\n",
      "  agent_3 NAV: 1,019,204.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 82285dcc53584086883e4e5a87785b49 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -185085472.28593713, 'agent_1': -185803922.48792854, 'agent_2': -197582220.26116246, 'agent_3': -195570525.0459871} id_=82285dcc53584086883e4e5a87785b49)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 82285dcc53584086883e4e5a87785b49 NAV Verification ====================\n",
      "  agent_0 NAV: 1,009,077.00\n",
      "  agent_1 NAV: 982,142.00\n",
      "  agent_2 NAV: 1,013,879.00\n",
      "  agent_3 NAV: 994,902.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode fd59a324631644b085105ebbc82e4cce Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -22681541.71490955, 'agent_1': -42045240.436404265, 'agent_2': -89909593.83934474, 'agent_3': -66237561.87420361} id_=fd59a324631644b085105ebbc82e4cce)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fd59a324631644b085105ebbc82e4cce NAV Verification ====================\n",
      "  agent_0 NAV: 997,503.00\n",
      "  agent_1 NAV: 998,904.00\n",
      "  agent_2 NAV: 1,003,881.00\n",
      "  agent_3 NAV: 999,712.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode d3da9581e53a4367ae037aca6624ed85 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -62975614.60369481, 'agent_1': -38865721.13827246, 'agent_2': -157037668.52402815, 'agent_3': -116766338.38328502} id_=d3da9581e53a4367ae037aca6624ed85)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d3da9581e53a4367ae037aca6624ed85 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,554.00\n",
      "  agent_1 NAV: 994,494.00\n",
      "  agent_2 NAV: 1,011,284.00\n",
      "  agent_3 NAV: 993,668.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode 78f911000c26407eb7e982e69a75c823 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -139138550.05 | Std: 19936143.15 | Threshold: -137144935.74\n",
      "Policy Returns: {'policy_2': -119468923.54310408, 'policy_3': -172374770.60728174, 'policy_1': -130589974.78529945, 'policy_0': -134120531.27598825}\n",
      "Best Trainable: policy_1 (-130589974.79)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_1\n",
      "Return: -130589974.79\n",
      "Iteration: 2\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_1 created successfully!\n",
      "✓ League size now: 3 (2 trainable + 1 champions)\n",
      "✓ Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -3383976.032, 'agent_1': -190814.4649859944, 'agent_2': -2637603.905781585, 'agent_3': -992608.0790960452} id_=78f911000c26407eb7e982e69a75c823)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 78f911000c26407eb7e982e69a75c823 NAV Verification ====================\n",
      "  agent_0 NAV: 990,374.00\n",
      "  agent_1 NAV: 996,122.00\n",
      "  agent_2 NAV: 1,015,589.00\n",
      "  agent_3 NAV: 997,915.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 37fa25a7a7f645e09f499e6ad92b173d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -28828827.15538639, 'agent_1': -25342486.985809416, 'agent_2': -105860536.58901823, 'agent_3': -127504822.48690404} id_=37fa25a7a7f645e09f499e6ad92b173d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 37fa25a7a7f645e09f499e6ad92b173d NAV Verification ====================\n",
      "  agent_0 NAV: 995,500.00\n",
      "  agent_1 NAV: 995,930.00\n",
      "  agent_2 NAV: 1,000,526.00\n",
      "  agent_3 NAV: 1,008,044.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 79ef12126ac24893a8cbd96142bd9439 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -70568681.61829564, 'agent_1': -85173412.54113816, 'agent_2': -48883524.599656686, 'agent_3': -51807343.840632126} id_=79ef12126ac24893a8cbd96142bd9439)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 79ef12126ac24893a8cbd96142bd9439 NAV Verification ====================\n",
      "  agent_0 NAV: 996,802.00\n",
      "  agent_1 NAV: 997,695.00\n",
      "  agent_2 NAV: 1,001,960.00\n",
      "  agent_3 NAV: 1,003,543.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 1908ffca567d486d9360505509f8c5e5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -91605162.99373828, 'agent_1': -133148524.21068126, 'agent_2': -162168728.76729983, 'agent_3': -67584550.68965617} id_=1908ffca567d486d9360505509f8c5e5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 1908ffca567d486d9360505509f8c5e5 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,571.00\n",
      "  agent_1 NAV: 1,003,845.00\n",
      "  agent_2 NAV: 1,007,842.00\n",
      "  agent_3 NAV: 984,742.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 76f5ccd12d944974b68d259c1229e819 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -115389780.03 | Std: 10912430.34 | Threshold: -114298537.00\n",
      "Policy Returns: {'policy_2': -111984997.59747297, 'policy_3': -134034864.7427563, 'policy_1': -107077021.59579888, 'policy_0': -108462236.203588}\n",
      "Best Trainable: policy_1 (-107077021.60)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -170130.09642345988, 'agent_1': -610731.22848321, 'agent_2': -2117023.6545424755, 'agent_3': -1356433.7287587961} id_=76f5ccd12d944974b68d259c1229e819)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 76f5ccd12d944974b68d259c1229e819 NAV Verification ====================\n",
      "  agent_0 NAV: 994,998.00\n",
      "  agent_1 NAV: 1,007,813.00\n",
      "  agent_2 NAV: 1,000,357.00\n",
      "  agent_3 NAV: 996,832.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 002c021cea13402aa54f28afa117fc70 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -124918123.36851709, 'agent_1': -23506437.473554213, 'agent_2': -131312762.68943991, 'agent_3': -35691794.9471328} id_=002c021cea13402aa54f28afa117fc70)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 002c021cea13402aa54f28afa117fc70 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,362.00\n",
      "  agent_1 NAV: 998,556.00\n",
      "  agent_2 NAV: 999,200.00\n",
      "  agent_3 NAV: 998,882.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode c04a086d2d5a412c9925f629ffa434cb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -203865661.5094302, 'agent_1': -145422913.1552969, 'agent_2': -128745974.77692318, 'agent_3': -208677182.12938696} id_=c04a086d2d5a412c9925f629ffa434cb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c04a086d2d5a412c9925f629ffa434cb NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,217.00\n",
      "  agent_1 NAV: 1,008,542.00\n",
      "  agent_2 NAV: 997,018.00\n",
      "  agent_3 NAV: 994,223.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 9dbd48b9b5594ebf94739bcbc7fbfdba Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -80931402.19793747, 'agent_1': -83454395.03882729, 'agent_2': -93422069.97690128, 'agent_3': -85401746.7356357} id_=9dbd48b9b5594ebf94739bcbc7fbfdba)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9dbd48b9b5594ebf94739bcbc7fbfdba NAV Verification ====================\n",
      "  agent_0 NAV: 993,272.00\n",
      "  agent_1 NAV: 1,004,024.00\n",
      "  agent_2 NAV: 1,003,578.00\n",
      "  agent_3 NAV: 999,126.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6273e23633cd44909e64071f6b438a8f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -113079799.49 | Std: 8866324.84 | Threshold: -112193167.01\n",
      "Policy Returns: {'policy_2': -115343726.12947793, 'policy_3': -126117113.3254749, 'policy_1': -102091068.3224748, 'policy_0': -108767290.2002654}\n",
      "Best Trainable: policy_1 (-102091068.32)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_1\n",
      "Return: -102091068.32\n",
      "Iteration: 4\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_2 created successfully!\n",
      "✓ League size now: 4 (2 trainable + 2 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -912042.2976373908, 'agent_1': -2427385.087371694, 'agent_2': -2319496.861653498, 'agent_3': -2267563.634448383} id_=6273e23633cd44909e64071f6b438a8f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6273e23633cd44909e64071f6b438a8f NAV Verification ====================\n",
      "  agent_0 NAV: 996,170.00\n",
      "  agent_1 NAV: 1,010,091.00\n",
      "  agent_2 NAV: 994,190.00\n",
      "  agent_3 NAV: 999,549.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 9caa2a78eab44cdc93b5d8875ad1c9ff Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -24317222.23674933, 'agent_1': -53385040.28125784, 'agent_2': -161180591.16067383, 'agent_3': -196795341.5178956} id_=9caa2a78eab44cdc93b5d8875ad1c9ff)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9caa2a78eab44cdc93b5d8875ad1c9ff NAV Verification ====================\n",
      "  agent_0 NAV: 996,074.00\n",
      "  agent_1 NAV: 1,006,175.00\n",
      "  agent_2 NAV: 997,928.00\n",
      "  agent_3 NAV: 999,823.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode fa3db6bb0d3b4020a60fe203cf5e2b4f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -93043779.251093, 'agent_1': -426573318.2478664, 'agent_2': -143411455.72913334, 'agent_3': -607124819.1359197} id_=fa3db6bb0d3b4020a60fe203cf5e2b4f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fa3db6bb0d3b4020a60fe203cf5e2b4f NAV Verification ====================\n",
      "  agent_0 NAV: 990,791.00\n",
      "  agent_1 NAV: 995,578.00\n",
      "  agent_2 NAV: 999,658.00\n",
      "  agent_3 NAV: 1,013,973.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 595da0179a7b4763ba4d7debdd2e0121 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -24210778.281517677, 'agent_1': -51524232.587331995, 'agent_2': -26191220.68749684, 'agent_3': -28259336.78185797} id_=595da0179a7b4763ba4d7debdd2e0121)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 595da0179a7b4763ba4d7debdd2e0121 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,826.00\n",
      "  agent_1 NAV: 992,186.00\n",
      "  agent_2 NAV: 1,003,316.00\n",
      "  agent_3 NAV: 1,002,672.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode f253f99eb81f4fd2ad05062e67e9fb29 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -116600845.89 | Std: 19140869.03 | Threshold: -114686758.99\n",
      "Policy Returns: {'policy_2': -110715102.17334485, 'policy_3': -147660305.78783664, 'policy_1': -112654052.81857207, 'policy_0': -95373922.77635425}\n",
      "Best Trainable: policy_0 (-95373922.78)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -11164195.846820809, 'agent_1': -3066804.8679619003, 'agent_2': -4443787.625140406, 'agent_3': -386317.21387283236} id_=f253f99eb81f4fd2ad05062e67e9fb29)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f253f99eb81f4fd2ad05062e67e9fb29 NAV Verification ====================\n",
      "  agent_0 NAV: 996,672.00\n",
      "  agent_1 NAV: 1,004,424.00\n",
      "  agent_2 NAV: 1,002,141.00\n",
      "  agent_3 NAV: 996,763.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 327707581a9544469da3fa330c631c11 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -370893643.62603956, 'agent_1': -516046674.6817975, 'agent_2': -175984192.24059498, 'agent_3': -91962726.37410824} id_=327707581a9544469da3fa330c631c11)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 327707581a9544469da3fa330c631c11 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,319.00\n",
      "  agent_1 NAV: 1,000,211.00\n",
      "  agent_2 NAV: 1,010,662.00\n",
      "  agent_3 NAV: 985,808.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 96f5686418094597ac48279b268454e1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -337900357.1477571, 'agent_1': -82799345.62273015, 'agent_2': -64795341.694782645, 'agent_3': -285496798.0402766} id_=96f5686418094597ac48279b268454e1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 96f5686418094597ac48279b268454e1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,362.00\n",
      "  agent_1 NAV: 998,418.00\n",
      "  agent_2 NAV: 991,025.00\n",
      "  agent_3 NAV: 1,005,195.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 356ded581b574e2396a91b6d626d60db Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -40758683.09622921, 'agent_1': -29278171.70527953, 'agent_2': -22173635.20432256, 'agent_3': -57040400.82136132} id_=356ded581b574e2396a91b6d626d60db)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 356ded581b574e2396a91b6d626d60db NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,791.00\n",
      "  agent_1 NAV: 1,003,111.00\n",
      "  agent_2 NAV: 999,477.00\n",
      "  agent_3 NAV: 996,621.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 0723f13041a0438da88f60742dbafb5f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -122089188.43 | Std: 13355413.37 | Threshold: -120753647.09\n",
      "Policy Returns: {'policy_2': -105563459.42567132, 'policy_3': -142102871.8268815, 'policy_1': -124452406.76574825, 'policy_0': -116238015.68758325}\n",
      "Best Trainable: policy_0 (-116238015.69)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -116238015.69\n",
      "Iteration: 6\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_3 created successfully!\n",
      "✓ League size now: 5 (2 trainable + 3 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -3198340.0, 'agent_1': -44381.3219895288, 'agent_2': 9.427792915531334, 'agent_3': -671499.0923721377} id_=0723f13041a0438da88f60742dbafb5f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 0723f13041a0438da88f60742dbafb5f NAV Verification ====================\n",
      "  agent_0 NAV: 995,231.00\n",
      "  agent_1 NAV: 1,007,928.00\n",
      "  agent_2 NAV: 999,212.00\n",
      "  agent_3 NAV: 997,629.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 3c0f6e156f2a4fa3ae4127a4cf1b7bf7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -78923679.02941427, 'agent_1': -101750803.38275608, 'agent_2': -33681992.493582696, 'agent_3': -43421943.11727777} id_=3c0f6e156f2a4fa3ae4127a4cf1b7bf7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3c0f6e156f2a4fa3ae4127a4cf1b7bf7 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,797.00\n",
      "  agent_1 NAV: 980,210.00\n",
      "  agent_2 NAV: 1,004,307.00\n",
      "  agent_3 NAV: 1,010,686.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode aed61717359d4d70a02a4c0ae5e97f90 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -78735485.93691266, 'agent_1': -53372546.05185385, 'agent_2': -49634650.19264816, 'agent_3': -35480253.30889976} id_=aed61717359d4d70a02a4c0ae5e97f90)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode aed61717359d4d70a02a4c0ae5e97f90 NAV Verification ====================\n",
      "  agent_0 NAV: 994,620.00\n",
      "  agent_1 NAV: 1,006,686.00\n",
      "  agent_2 NAV: 1,000,525.00\n",
      "  agent_3 NAV: 998,169.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 80e66029ffa343cf8be8ca2078471461 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -101848311.12790526, 'agent_1': -42440706.44561682, 'agent_2': -34150899.57652767, 'agent_3': -56912497.79391922} id_=80e66029ffa343cf8be8ca2078471461)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 80e66029ffa343cf8be8ca2078471461 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,906.00\n",
      "  agent_1 NAV: 1,000,444.00\n",
      "  agent_2 NAV: 999,945.00\n",
      "  agent_3 NAV: 995,705.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 91a1569d5126416a942ee4cac0de8793 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -112695732.26 | Std: 11483265.67 | Threshold: -111547405.69\n",
      "Policy Returns: {'policy_2': -95471751.93372004, 'policy_3': -127307745.00437991, 'policy_1': -116635530.74324763, 'policy_0': -111367901.36435924}\n",
      "Best Trainable: policy_0 (-111367901.36)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -2212384.07467853, 'agent_1': -979780.6866542464, 'agent_2': -4493289.404251501, 'agent_3': -381867.50118819374} id_=91a1569d5126416a942ee4cac0de8793)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 91a1569d5126416a942ee4cac0de8793 NAV Verification ====================\n",
      "  agent_0 NAV: 993,748.00\n",
      "  agent_1 NAV: 999,019.00\n",
      "  agent_2 NAV: 1,000,957.00\n",
      "  agent_3 NAV: 1,006,276.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode d29c4e375ec24911acd268042c54e625 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -50722527.403142, 'agent_1': -191072764.77401188, 'agent_2': -306014172.9555131, 'agent_3': -122336801.3536695} id_=d29c4e375ec24911acd268042c54e625)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d29c4e375ec24911acd268042c54e625 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,767.00\n",
      "  agent_1 NAV: 994,582.00\n",
      "  agent_2 NAV: 1,001,192.00\n",
      "  agent_3 NAV: 1,000,459.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 7d701714de7048d2a9d97872af8e5787 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -124136649.71025042, 'agent_1': -121493173.14852141, 'agent_2': -175046487.78596234, 'agent_3': -121790638.64850962} id_=7d701714de7048d2a9d97872af8e5787)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7d701714de7048d2a9d97872af8e5787 NAV Verification ====================\n",
      "  agent_0 NAV: 1,017,253.00\n",
      "  agent_1 NAV: 986,026.00\n",
      "  agent_2 NAV: 978,420.00\n",
      "  agent_3 NAV: 1,018,301.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode a220304d41a3475faedd1222ea157fce Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -49310249.8563223, 'agent_1': -42922750.23176602, 'agent_2': -63858602.996896565, 'agent_3': -20243561.32368869} id_=a220304d41a3475faedd1222ea157fce)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a220304d41a3475faedd1222ea157fce NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,114.00\n",
      "  agent_1 NAV: 1,010,102.00\n",
      "  agent_2 NAV: 990,362.00\n",
      "  agent_3 NAV: 994,422.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 5596314b9311441f9fc73d3aefc6a543 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -110794725.25 | Std: 6944119.61 | Threshold: -110100313.29\n",
      "Policy Returns: {'policy_2': -103274700.8063931, 'policy_3': -120762045.32393935, 'policy_1': -113693596.29872333, 'policy_0': -105448558.56903881}\n",
      "Best Trainable: policy_0 (-105448558.57)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -105448558.57\n",
      "Iteration: 8\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_4 created successfully!\n",
      "✓ League size now: 6 (2 trainable + 4 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -168279.57229228568, 'agent_1': -810342.0720342576, 'agent_2': -2723590.9726516423, 'agent_3': -2734045.4831460672} id_=5596314b9311441f9fc73d3aefc6a543)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5596314b9311441f9fc73d3aefc6a543 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,509.00\n",
      "  agent_1 NAV: 998,304.00\n",
      "  agent_2 NAV: 990,826.00\n",
      "  agent_3 NAV: 1,006,361.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 89497cc07beb4258a9d55ba8a4886d7a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -26719810.368008737, 'agent_1': -74504610.26399364, 'agent_2': -142192130.3654378, 'agent_3': -216079701.6228781} id_=89497cc07beb4258a9d55ba8a4886d7a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 89497cc07beb4258a9d55ba8a4886d7a NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,361.00\n",
      "  agent_1 NAV: 1,002,301.00\n",
      "  agent_2 NAV: 1,002,479.00\n",
      "  agent_3 NAV: 989,859.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode c6d21232012d451bb78ae24b052eefd8 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -68809230.89269063, 'agent_1': -309515015.14195335, 'agent_2': -67688689.91472979, 'agent_3': -151346420.27244243} id_=c6d21232012d451bb78ae24b052eefd8)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c6d21232012d451bb78ae24b052eefd8 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,590.00\n",
      "  agent_1 NAV: 992,516.00\n",
      "  agent_2 NAV: 1,000,991.00\n",
      "  agent_3 NAV: 1,005,903.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 41217147d7644a5e8b134389e59219cb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -17289069.943220306, 'agent_1': -42300673.0533195, 'agent_2': -58164931.15251601, 'agent_3': -36682708.92176228} id_=41217147d7644a5e8b134389e59219cb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 41217147d7644a5e8b134389e59219cb NAV Verification ====================\n",
      "  agent_0 NAV: 997,933.00\n",
      "  agent_1 NAV: 1,003,538.00\n",
      "  agent_2 NAV: 998,151.00\n",
      "  agent_3 NAV: 1,000,378.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 639e673718b34e9d98f2644c82e9eb08 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -108371058.32 | Std: 9785567.31 | Threshold: -107392501.59\n",
      "Policy Returns: {'policy_2': -100295949.81002362, 'policy_3': -120557054.4733225, 'policy_1': -115284274.70290105, 'policy_0': -97346954.279996}\n",
      "Best Trainable: policy_0 (-97346954.28)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -5076691.4309251355, 'agent_1': -4995301.074225061, 'agent_2': -5317819.86933592, 'agent_3': -2030904.8129906452} id_=639e673718b34e9d98f2644c82e9eb08)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 639e673718b34e9d98f2644c82e9eb08 NAV Verification ====================\n",
      "  agent_0 NAV: 1,010,520.00\n",
      "  agent_1 NAV: 999,717.00\n",
      "  agent_2 NAV: 987,830.00\n",
      "  agent_3 NAV: 1,001,933.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 9ec4a815a6504f8eaea850914e696b81 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -76770384.96945229, 'agent_1': -33486984.724797484, 'agent_2': -25634893.2730725, 'agent_3': -63280142.30300388} id_=9ec4a815a6504f8eaea850914e696b81)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9ec4a815a6504f8eaea850914e696b81 NAV Verification ====================\n",
      "  agent_0 NAV: 1,012,791.00\n",
      "  agent_1 NAV: 1,004,975.00\n",
      "  agent_2 NAV: 996,406.00\n",
      "  agent_3 NAV: 985,828.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 627be65910724a6593a762b396828dbd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -141225227.71604785, 'agent_1': -467531819.60237443, 'agent_2': -139282979.33331648, 'agent_3': -174890792.72218832} id_=627be65910724a6593a762b396828dbd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 627be65910724a6593a762b396828dbd NAV Verification ====================\n",
      "  agent_0 NAV: 999,986.00\n",
      "  agent_1 NAV: 1,014,903.00\n",
      "  agent_2 NAV: 992,223.00\n",
      "  agent_3 NAV: 992,888.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 962a320aed11485e9f169a5919246eb7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -223507278.83914316, 'agent_1': -64100300.40578079, 'agent_2': -93014692.29841469, 'agent_3': -157658582.0860897} id_=962a320aed11485e9f169a5919246eb7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 962a320aed11485e9f169a5919246eb7 NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,488.00\n",
      "  agent_1 NAV: 996,890.00\n",
      "  agent_2 NAV: 1,000,477.00\n",
      "  agent_3 NAV: 989,145.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 69f7b57e77d7407ab0b2555d27c51cd6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -109714493.60 | Std: 9849717.00 | Threshold: -108729521.90\n",
      "Policy Returns: {'policy_2': -98781195.775447, 'policy_3': -119242560.09106323, 'policy_1': -119818154.69802867, 'policy_0': -101016063.84721562}\n",
      "Best Trainable: policy_0 (-101016063.85)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -101016063.85\n",
      "Iteration: 10\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_5 created successfully!\n",
      "✓ League size now: 7 (2 trainable + 5 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -4532040.203769843, 'agent_1': -219800.5503471258, 'agent_2': -1228224.8454582233, 'agent_3': -3114613.9825475872} id_=69f7b57e77d7407ab0b2555d27c51cd6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 69f7b57e77d7407ab0b2555d27c51cd6 NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,847.00\n",
      "  agent_1 NAV: 1,001,083.00\n",
      "  agent_2 NAV: 999,468.00\n",
      "  agent_3 NAV: 987,602.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode dbbe259d3f3f49ce90089e8bc0c3a2bd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -39049424.74097, 'agent_1': -93925092.0343616, 'agent_2': -96047882.08116236, 'agent_3': -15037261.6558112} id_=dbbe259d3f3f49ce90089e8bc0c3a2bd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode dbbe259d3f3f49ce90089e8bc0c3a2bd NAV Verification ====================\n",
      "  agent_0 NAV: 1,007,854.00\n",
      "  agent_1 NAV: 974,211.00\n",
      "  agent_2 NAV: 1,021,330.00\n",
      "  agent_3 NAV: 996,605.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 8d4132b65df345e5911fe322d610e74e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -55405676.43591268, 'agent_1': -104679980.7266994, 'agent_2': -157016950.21807867, 'agent_3': -131649094.46907842} id_=8d4132b65df345e5911fe322d610e74e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8d4132b65df345e5911fe322d610e74e NAV Verification ====================\n",
      "  agent_0 NAV: 1,008,493.00\n",
      "  agent_1 NAV: 980,014.00\n",
      "  agent_2 NAV: 1,038,550.00\n",
      "  agent_3 NAV: 972,943.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 5325afa9d85c40bb8749873c0fe48709 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -69612297.72866078, 'agent_1': -17402356.322248276, 'agent_2': -17535315.43325515, 'agent_3': -51950169.83464544} id_=5325afa9d85c40bb8749873c0fe48709)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5325afa9d85c40bb8749873c0fe48709 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,970.00\n",
      "  agent_1 NAV: 999,433.00\n",
      "  agent_2 NAV: 996,749.00\n",
      "  agent_3 NAV: 999,848.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 4a8c5e4e48dd4e64bbd3631a48f9e5b9 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -105218606.56 | Std: 8871883.30 | Threshold: -104331418.23\n",
      "Policy Returns: {'policy_2': -96151552.92399079, 'policy_3': -114099373.00641084, 'policy_1': -114079430.21632902, 'policy_0': -96544070.09124151}\n",
      "Best Trainable: policy_0 (-96544070.09)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -7531252.090484664, 'agent_1': -19269617.395081986, 'agent_2': -11988612.603301989, 'agent_3': -18994754.390418395} id_=4a8c5e4e48dd4e64bbd3631a48f9e5b9)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4a8c5e4e48dd4e64bbd3631a48f9e5b9 NAV Verification ====================\n",
      "  agent_0 NAV: 1,002,664.00\n",
      "  agent_1 NAV: 1,000,331.00\n",
      "  agent_2 NAV: 1,000,415.00\n",
      "  agent_3 NAV: 996,590.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode c43ce0a6f0c14e43bf7a4ffc915ed463 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -78283284.20950377, 'agent_1': -17503546.105937164, 'agent_2': -24495257.300141532, 'agent_3': -90471958.66285945} id_=c43ce0a6f0c14e43bf7a4ffc915ed463)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c43ce0a6f0c14e43bf7a4ffc915ed463 NAV Verification ====================\n",
      "  agent_0 NAV: 1,022,381.00\n",
      "  agent_1 NAV: 999,508.00\n",
      "  agent_2 NAV: 1,003,451.00\n",
      "  agent_3 NAV: 974,660.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 09e8aafbe64342dfaf9a28b9ee3ce141 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -32969885.677593265, 'agent_1': -40589721.95989233, 'agent_2': -52934434.59291431, 'agent_3': -72912885.82612826} id_=09e8aafbe64342dfaf9a28b9ee3ce141)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 09e8aafbe64342dfaf9a28b9ee3ce141 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,245.00\n",
      "  agent_1 NAV: 1,006,940.00\n",
      "  agent_2 NAV: 985,055.00\n",
      "  agent_3 NAV: 1,004,760.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 771f8797784c4d7a975e18c7a794da94 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -89185884.37957248, 'agent_1': -43155552.911216736, 'agent_2': -28328373.368009456, 'agent_3': -53512057.97500313} id_=771f8797784c4d7a975e18c7a794da94)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 771f8797784c4d7a975e18c7a794da94 NAV Verification ====================\n",
      "  agent_0 NAV: 1,028,723.00\n",
      "  agent_1 NAV: 983,855.00\n",
      "  agent_2 NAV: 996,759.00\n",
      "  agent_3 NAV: 990,663.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 8751e618a5004fac925d88c7e725aba5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -101797117.39 | Std: 9185689.40 | Threshold: -100878548.45\n",
      "Policy Returns: {'policy_2': -91639965.1056183, 'policy_3': -112092763.26686928, 'policy_1': -109738173.40656175, 'policy_0': -93717567.78674518}\n",
      "Best Trainable: policy_0 (-93717567.79)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -93717567.79\n",
      "Iteration: 12\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_6 created successfully!\n",
      "✓ League size now: 8 (2 trainable + 6 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -1795532.9288808699, 'agent_1': -1943747.9734201527, 'agent_2': -256442.46014366142, 'agent_3': -1073924.4997533082} id_=8751e618a5004fac925d88c7e725aba5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 8751e618a5004fac925d88c7e725aba5 NAV Verification ====================\n",
      "  agent_0 NAV: 965,333.00\n",
      "  agent_1 NAV: 1,012,463.00\n",
      "  agent_2 NAV: 1,001,256.00\n",
      "  agent_3 NAV: 1,020,948.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 25eb0df033c84792825b24cfd59297f7 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -144851549.60834563, 'agent_1': -198856064.54622424, 'agent_2': -235170879.59436518, 'agent_3': -160541911.2269756} id_=25eb0df033c84792825b24cfd59297f7)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 25eb0df033c84792825b24cfd59297f7 NAV Verification ====================\n",
      "  agent_0 NAV: 1,017,451.00\n",
      "  agent_1 NAV: 1,013,817.00\n",
      "  agent_2 NAV: 969,038.00\n",
      "  agent_3 NAV: 999,694.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode e60a9ca192f742f286714addc5ca476a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -154180398.08962458, 'agent_1': -41118577.137584664, 'agent_2': -25534699.94134123, 'agent_3': -155382232.42988306} id_=e60a9ca192f742f286714addc5ca476a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e60a9ca192f742f286714addc5ca476a NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,138.00\n",
      "  agent_1 NAV: 1,001,943.00\n",
      "  agent_2 NAV: 1,002,896.00\n",
      "  agent_3 NAV: 995,023.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 6723187c55554a0da5d1b9759fc5ada3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -229001369.89218792, 'agent_1': -308758835.8481748, 'agent_2': -138296644.027041, 'agent_3': -169368257.03525352} id_=6723187c55554a0da5d1b9759fc5ada3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6723187c55554a0da5d1b9759fc5ada3 NAV Verification ====================\n",
      "  agent_0 NAV: 1,020,741.00\n",
      "  agent_1 NAV: 980,824.00\n",
      "  agent_2 NAV: 987,480.00\n",
      "  agent_3 NAV: 1,010,955.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode e5763576dbef43d38e4756b9a610209f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -104773365.75 | Std: 9142750.32 | Threshold: -103859090.72\n",
      "Policy Returns: {'policy_2': -92664286.26112247, 'policy_3': -113865309.97107618, 'policy_1': -113371176.12810917, 'policy_0': -99192690.6292094}\n",
      "Best Trainable: policy_0 (-99192690.63)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -20058258.044205755, 'agent_1': -598634.4099204605, 'agent_2': -25698868.989083998, 'agent_3': -953506.9708846057} id_=e5763576dbef43d38e4756b9a610209f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e5763576dbef43d38e4756b9a610209f NAV Verification ====================\n",
      "  agent_0 NAV: 1,015,672.00\n",
      "  agent_1 NAV: 999,036.00\n",
      "  agent_2 NAV: 985,280.00\n",
      "  agent_3 NAV: 1,000,012.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 9efa5d8c6ea543aba3e017e1b158c5b1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -160407144.19572395, 'agent_1': -69141931.20478727, 'agent_2': -160232186.64478475, 'agent_3': -29190355.7503767} id_=9efa5d8c6ea543aba3e017e1b158c5b1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9efa5d8c6ea543aba3e017e1b158c5b1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,459.00\n",
      "  agent_1 NAV: 993,671.00\n",
      "  agent_2 NAV: 1,008,149.00\n",
      "  agent_3 NAV: 994,721.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 3471ce40933947d2babea8f78e3fffc1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -59600748.54081971, 'agent_1': -53884197.15553756, 'agent_2': -21612397.785780437, 'agent_3': -30891302.581111316} id_=3471ce40933947d2babea8f78e3fffc1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3471ce40933947d2babea8f78e3fffc1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,012,172.00\n",
      "  agent_1 NAV: 995,982.00\n",
      "  agent_2 NAV: 993,334.00\n",
      "  agent_3 NAV: 998,512.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode ee4f9243ae664ec6994d1e79c25b69f4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -41764170.60475798, 'agent_1': -19875078.14232997, 'agent_2': -32767962.960076552, 'agent_3': -49458262.65665291} id_=ee4f9243ae664ec6994d1e79c25b69f4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ee4f9243ae664ec6994d1e79c25b69f4 NAV Verification ====================\n",
      "  agent_0 NAV: 997,790.00\n",
      "  agent_1 NAV: 997,981.00\n",
      "  agent_2 NAV: 998,824.00\n",
      "  agent_3 NAV: 1,005,405.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode a2fe2d762bf64869a582e93f6784c7dd Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -101827100.21 | Std: 6638823.66 | Threshold: -101163217.85\n",
      "Policy Returns: {'policy_2': -92327220.15030904, 'policy_3': -107938599.64502792, 'policy_1': -108155792.12519321, 'policy_0': -98886788.92474204}\n",
      "Best Trainable: policy_0 (-98886788.92)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -98886788.92\n",
      "Iteration: 14\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_7 created successfully!\n",
      "✓ League size now: 9 (2 trainable + 7 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -1805848.1070781015, 'agent_1': -4301521.294354606, 'agent_2': -5979926.169159093, 'agent_3': -1324402.1441592572} id_=a2fe2d762bf64869a582e93f6784c7dd)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a2fe2d762bf64869a582e93f6784c7dd NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,503.00\n",
      "  agent_1 NAV: 997,750.00\n",
      "  agent_2 NAV: 1,001,984.00\n",
      "  agent_3 NAV: 994,763.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 01220ff03b124203872bedd140535d06 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -118949109.5032545, 'agent_1': -43376268.93444398, 'agent_2': -49552665.39055833, 'agent_3': -39929325.6824847} id_=01220ff03b124203872bedd140535d06)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 01220ff03b124203872bedd140535d06 NAV Verification ====================\n",
      "  agent_0 NAV: 982,788.00\n",
      "  agent_1 NAV: 1,002,728.00\n",
      "  agent_2 NAV: 1,008,952.00\n",
      "  agent_3 NAV: 1,005,532.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode e58274b7ac69413689362ec5e790f710 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -70850644.96015877, 'agent_1': -23870313.897113305, 'agent_2': -98506468.16029744, 'agent_3': -36655802.69414301} id_=e58274b7ac69413689362ec5e790f710)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e58274b7ac69413689362ec5e790f710 NAV Verification ====================\n",
      "  agent_0 NAV: 988,765.00\n",
      "  agent_1 NAV: 990,911.00\n",
      "  agent_2 NAV: 1,009,144.00\n",
      "  agent_3 NAV: 1,011,180.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 69c60a13620a407493f458f8cd5bce16 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -49867467.93236294, 'agent_1': -11503705.594578205, 'agent_2': -47979284.187348045, 'agent_3': -25785737.33335272} id_=69c60a13620a407493f458f8cd5bce16)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 69c60a13620a407493f458f8cd5bce16 NAV Verification ====================\n",
      "  agent_0 NAV: 1,009,469.00\n",
      "  agent_1 NAV: 1,002,640.00\n",
      "  agent_2 NAV: 989,685.00\n",
      "  agent_3 NAV: 998,206.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 7a3a20f421594660bcfdfe36bb903170 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -98112850.01 | Std: 5170686.04 | Threshold: -97595781.41\n",
      "Policy Returns: {'policy_2': -90288283.99766597, 'policy_3': -102810986.48539193, 'policy_1': -102738774.0461712, 'policy_0': -96613355.52549797}\n",
      "Best Trainable: policy_0 (-96613355.53)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -1242084.9398039384, 'agent_1': -8692939.900965888, 'agent_2': -12229792.087162856, 'agent_3': -2941856.2501247637} id_=7a3a20f421594660bcfdfe36bb903170)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7a3a20f421594660bcfdfe36bb903170 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,139.00\n",
      "  agent_1 NAV: 988,374.00\n",
      "  agent_2 NAV: 1,003,815.00\n",
      "  agent_3 NAV: 1,006,672.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode dfd5258033e341ec9b3d3d7a8aebe35c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -108938490.99533577, 'agent_1': -52072271.83380994, 'agent_2': -99760082.20844506, 'agent_3': -39519613.15828674} id_=dfd5258033e341ec9b3d3d7a8aebe35c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode dfd5258033e341ec9b3d3d7a8aebe35c NAV Verification ====================\n",
      "  agent_0 NAV: 1,022,244.00\n",
      "  agent_1 NAV: 1,000,628.00\n",
      "  agent_2 NAV: 981,122.00\n",
      "  agent_3 NAV: 996,006.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 0960cb18b2c64683ad0767bf4b342c43 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -59529104.785690896, 'agent_1': -161156690.28609654, 'agent_2': -25224040.900247473, 'agent_3': -261493012.85915312} id_=0960cb18b2c64683ad0767bf4b342c43)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 0960cb18b2c64683ad0767bf4b342c43 NAV Verification ====================\n",
      "  agent_0 NAV: 997,018.00\n",
      "  agent_1 NAV: 987,348.00\n",
      "  agent_2 NAV: 997,159.00\n",
      "  agent_3 NAV: 1,018,475.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode af4170ded83b4af896223eca199e601f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -22981701.869303398, 'agent_1': -16269700.103110198, 'agent_2': -67923817.55246155, 'agent_3': -35727333.008913025} id_=af4170ded83b4af896223eca199e601f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode af4170ded83b4af896223eca199e601f NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,074.00\n",
      "  agent_1 NAV: 1,000,834.00\n",
      "  agent_2 NAV: 988,762.00\n",
      "  agent_3 NAV: 1,007,330.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 1d99594019144a058436082f9fe940bc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -96853113.50 | Std: 5310832.24 | Threshold: -96322030.28\n",
      "Policy Returns: {'policy_2': -89652016.02404778, 'policy_3': -102326701.75815494, 'policy_1': -101558198.54570961, 'policy_0': -93875537.68257844}\n",
      "Best Trainable: policy_0 (-93875537.68)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "🏆 CREATING CHAMPION SNAPSHOT 🏆\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -93875537.68\n",
      "Iteration: 16\n",
      "********************************************************************************\n",
      "\n",
      "✓ Champion champion_8 created successfully!\n",
      "✓ League size now: 10 (2 trainable + 8 champions)\n",
      "✓ Active champions: ['champion_1', 'champion_2', 'champion_3', 'champion_4', 'champion_5', 'champion_6', 'champion_7', 'champion_8']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ← KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 11:28:46\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Get current time in SGT (Singapore Time)\n",
    "sgt_time = datetime.now(ZoneInfo(\"Asia/Singapore\"))\n",
    "formatted_datetime = sgt_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
