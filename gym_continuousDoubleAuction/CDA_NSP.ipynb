{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f05ZH97QkoJf"
   },
   "source": [
    "# Sample training script with naive competitive self-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU Diagnostics\n",
    "# import torch\n",
    "# print(\"=\"*50)\n",
    "# print(\"GPU Diagnostics:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version (built with): {torch.version.cuda}\")\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "#     print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "#     print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "# else:\n",
    "#     print(\"‚ùå No GPU detected by PyTorch!\")\n",
    "#     print(\"\\nPossible solutions:\")\n",
    "#     print(\"1. Install PyTorch with CUDA support:\")\n",
    "#     print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "#     print(\"2. Check NVIDIA drivers: nvidia-smi\")\n",
    "#     print(\"3. Verify CUDA toolkit is installed\")\n",
    "# print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcLSdJuUkTrX"
   },
   "source": [
    "### Switch directory in Google drive so as to import CDA env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756087231922,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "0roHXj0tvvLg"
   },
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "# is_colab = True\n",
    "\n",
    "# is_1st_run = False\n",
    "is_1st_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756087232001,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "PAqVG2cqjLXM"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# %cd \"/root/ray_results/\"\n",
    "# !ls -l\n",
    "# #!rm -rf PPO_continuousDoubleAuction-v0_*\n",
    "# !ls -l\n",
    "# !pwd\n",
    "\n",
    "# %cd \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/\"\n",
    "# !ls -l\n",
    "\n",
    "# #!pip install -r requirements.txt\n",
    "\n",
    "# #!pip install tensorflow==2.2.0\n",
    "# #!pip install ray[rllib]==0.8.5\n",
    "\n",
    "# #!pip show tensorflow\n",
    "# #!pip show ray\n",
    "\n",
    "# #!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232034,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_ZJO7gUwngjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if is_colab == False and is_1st_run == True:\n",
    "    !pip install sortedcontainers\n",
    "    !!pip install scikit-learn\n",
    "    !pip install tabulate\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232036,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "vgzysJOX0HZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U ipywidgets\n",
    "# !pip install pettingzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "e9q-QyPhngjt"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756087232056,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "ZtVHJhPMngju"
   },
   "outputs": [],
   "source": [
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087232069,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "CsWAV-_mngju"
   },
   "outputs": [],
   "source": [
    "# !pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756087232086,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "uZpGXbLJngju"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall continuousDoubleAuction\n",
    "# !pip uninstall continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232116,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "t8WyPN_qngju"
   },
   "outputs": [],
   "source": [
    "# !pip show continuousDoubleAuction\n",
    "# !pip show continuousDoubleAuction-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232118,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "DYuxehQengjv"
   },
   "outputs": [],
   "source": [
    "# os.chdir('gym_continuousDoubleAuction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756087232119,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "r5E-HRDDngjv"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17865,
     "status": "ok",
     "timestamp": 1756087249985,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "D9EIlrs1pFq6",
    "outputId": "1fbfa0a4-3d1a-469e-f192-ec15a35c53de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !pip install -U ray[rllib]==2.48.0\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    %cd 'gdrive/MyDrive/Colab Notebooks/MARL/gym-continuousDoubleAuction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18197,
     "status": "ok",
     "timestamp": 1756087268180,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "WavBRshypJfb",
    "outputId": "caa88e03-1469-4d4a-e271-1b3079b750e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 05:54:41,468\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-24 05:54:42,579\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.48.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib\n",
    "import ray.tune\n",
    "\n",
    "print(\"Ray version:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1756087271959,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "auFbWGSNpFyK",
    "outputId": "198343fe-c5a0-427a-faed-035053791616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gymnasium\n",
      "Version: 1.0.0\n",
      "Summary: A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym).\n",
      "Home-page: https://farama.org\n",
      "Author: \n",
      "Author-email: Farama Foundation <contact@farama.org>\n",
      "License: MIT License\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: cloudpickle, farama-notifications, numpy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7ZHcwBWkXVM"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1756087272286,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "7UW3INjDipTC",
    "outputId": "e75fd1c2-c9a3-4a6e-a19b-86c497bfd501",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports all OK.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ['RAY_DEBUG_DISABLE_MEMORY_MONITOR'] = \"True\"\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.envs.continuousDoubleAuction_env import continuousDoubleAuctionEnv\n",
    "\n",
    "from gym_continuousDoubleAuction.train.model.model_handler import CustomRLModule\n",
    "\n",
    "from gym_continuousDoubleAuction.train.policy.policy_handler import (\n",
    "    # make_RandomPolicy,\n",
    "    # gen_policy,\n",
    "    # set_agents_policies,\n",
    "    # create_train_policy_list,\n",
    "    create_multi_agent_config,\n",
    "    policy_mapping_fn,\n",
    "    # create_and_train_algorithm,\n",
    ")\n",
    "from gym_continuousDoubleAuction.train.weight.weight_handler import (\n",
    "    get_trained_policies_name, get_max_reward_ind, cp_weight)\n",
    "from gym_continuousDoubleAuction.train.storage.store_handler import storage\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.callbk.callbk_handler import store_eps_hist_data\n",
    "from gym_continuousDoubleAuction.train.callbk.league_based_self_play_callback import SelfPlayCallback\n",
    "\n",
    "\n",
    "\n",
    "from gym_continuousDoubleAuction.train.logger.log_handler import (\n",
    "    create_dir, log_g_store, load_g_store)\n",
    "from gym_continuousDoubleAuction.train.plotter.plot_handler import (\n",
    "    plot_storage, plot_LOB_subplot, plot_sum_ord_imb, plot_mid_prices)\n",
    "from gym_continuousDoubleAuction.train.helper.helper import (\n",
    "    ord_imb, sum_ord_imb, mid_price)\n",
    "\n",
    "\n",
    "print(f'Imports all OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnpi8k5kbYo"
   },
   "source": [
    "### Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9751,
     "status": "ok",
     "timestamp": 1756087282038,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "UqzjVWUsPykm",
    "outputId": "29b59972-64ec-4d61-e448-ad4b94ab11c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder creation failed or folder already exists: results/\n",
      "Folder creation failed or folder already exists: results/log_g_store/\n",
      "['agent_1', 'agent_2', 'agent_0', 'agent_3']\n",
      "Box(-inf, inf, (40,), float32)\n",
      "Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 05:54:44,473\tWARNING services.py:2142 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.76gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-12-24 05:54:45,520\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace=\"6315f8db-a0a8-4e6e-a11b-ee50309e9a4c\", ...)\n"
     ]
    }
   ],
   "source": [
    "# CDA_env args\n",
    "num_agents = 4\n",
    "num_trained_agent = 2 #\n",
    "num_policies = num_agents # Each agent is using a separate policy\n",
    "num_of_traders = num_agents\n",
    "tape_display_length = 10\n",
    "tick_size = 1\n",
    "init_cash = 1000000\n",
    "# max_step = 4096 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "max_step = 1024 # per episode, -1 in arg. (~7.2s/1000steps/iter)\n",
    "is_render = False\n",
    "\n",
    "# RLlib config\n",
    "# train_policy_list = create_train_policy_list(num_trained_agent, \"policy_\")\n",
    "#num_cpus = 0.25\n",
    "num_gpus = 0.75 #0\n",
    "num_cpus_per_worker = 0.25\n",
    "num_gpus_per_worker = 0\n",
    "num_workers = 2\n",
    "num_envs_per_worker = 4\n",
    "batch_mode = \"complete_episodes\"\n",
    "# rollout_fragment_length = 128\n",
    "num_episodes_per_iter = 4\n",
    "# agent_time_step_per_episode = max_step * num_agents\n",
    "# train_batch_size = agent_time_step_per_episode * num_episodes_per_iter\n",
    "train_batch_size = max_step * num_episodes_per_iter\n",
    "# sgd_minibatch_size = 256\n",
    "num_iters = 16\n",
    "\n",
    "# log_base_dir = \"/content/gdrive/My Drive/Colab Notebooks/gym-continuousDoubleAuction/results/\"\n",
    "log_base_dir = \"results/\"\n",
    "log_dir = log_base_dir + \"ray_results/\"\n",
    "\n",
    "# Chkpt & restore\n",
    "local_dir = log_base_dir + \"chkpt/\"\n",
    "chkpt_freq = 10\n",
    "chkpt = 320\n",
    "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
    "is_restore = True # True / False\n",
    "\n",
    "# log & load\n",
    "log_g_store_dir = log_base_dir + \"log_g_store/\"\n",
    "create_dir(log_base_dir)\n",
    "create_dir(log_g_store_dir)\n",
    "\n",
    "# Environment configuration\n",
    "env_config = {\n",
    "    \"num_of_agents\": num_agents,\n",
    "    \"init_cash\": init_cash,\n",
    "    \"tick_size\": tick_size,\n",
    "    \"tape_display_length\": tape_display_length,\n",
    "    \"max_step\": max_step,\n",
    "    \"is_render\": is_render\n",
    "}\n",
    "\n",
    "# get obs & act spaces from dummy CDA env\n",
    "# single_CDA_env = continuousDoubleAuctionEnv(\n",
    "#     num_of_traders,\n",
    "#     init_cash,\n",
    "#     tick_size,\n",
    "#     tape_display_length,\n",
    "#     max_step,\n",
    "#     is_render)\n",
    "single_CDA_env = continuousDoubleAuctionEnv(env_config)\n",
    "obs_space = single_CDA_env.get_observation_space(single_CDA_env.agents[0])\n",
    "act_space = single_CDA_env.get_action_space(single_CDA_env.agents[0])\n",
    "print(single_CDA_env.agents)  # Should be a non-empty list\n",
    "print(single_CDA_env.get_observation_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "print(single_CDA_env.get_action_space(single_CDA_env.agents[0]))  # Should return a valid gym.Space\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return continuousDoubleAuctionEnv(env_config)\n",
    "\n",
    "# Register environment with ray.tune - this is the key fix!\n",
    "tune.register_env(\"continuousDoubleAuction-v0\", env_creator)\n",
    "\n",
    "# register custom model (neural network)\n",
    "ModelCatalog.register_custom_model(\"model_disc\", CustomRLModule)\n",
    "\n",
    "ray.shutdown()\n",
    "# start ray\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=True,\n",
    "    num_cpus=2,\n",
    "    dashboard_host=\"127.0.0.1\",  # replaces webui_host\n",
    "    dashboard_port=8265,          # default port; replaces webui_port\n",
    "    # include_dashboard=True,        # default True\n",
    "    include_dashboard=False,        # default True\n",
    "\n",
    ")\n",
    "\n",
    "# Global storage, a ray actor that run on it's own process & it needs to be declared after ray.init().\n",
    "g_store = storage.options(name=\"g_store\", lifetime=\"detached\").remote(num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cknk9Cnoke_u"
   },
   "source": [
    "### Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756087282068,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "X_CVJpl4ngjw",
    "outputId": "e46188db-3568-44f0-cb04-79a9f7c342ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies: {'policy_0': <ray.rllib.policy.policy.PolicySpec object at 0x7153746d3ac0>, 'policy_1': <ray.rllib.policy.policy.PolicySpec object at 0x7153746d3af0>, 'policy_2': <ray.rllib.policy.policy.PolicySpec object at 0x7153746d3a90>, 'policy_3': <ray.rllib.policy.policy.PolicySpec object at 0x7153746d3c70>}\n",
      "policies_to_train: ['policy_0', 'policy_1']\n"
     ]
    }
   ],
   "source": [
    "policies, policies_to_train = create_multi_agent_config(\n",
    "    obs_space, act_space, num_agents, num_trained_agents=num_trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEnp5UpxkDve"
   },
   "source": [
    "### RLlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback instance with champion configuration\n",
    "callback_instance = SelfPlayCallback(\n",
    "    num_trainable_policies=num_trained_agent, \n",
    "    num_random_policies= num_agents - num_trained_agent,\n",
    "    std_dev_multiplier=0.1,      # Snapshot when return > mean + 2*std\n",
    "    max_champions=2,             # Keep last 5 champions (rolling window)\n",
    "    min_iterations_between_champions=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756087282137,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "AnniWlAwngjx"
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "def get_config():\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(\n",
    "            \"continuousDoubleAuction-v0\",\n",
    "            # continuousDoubleAuctionEnv,\n",
    "            # env_config={\n",
    "            #     \"num_of_agents\": num_of_traders,\n",
    "            #     \"init_cash\": init_cash,\n",
    "            #     \"tick_size\": tick_size,\n",
    "            #     \"tape_display_length\": tape_display_length,\n",
    "            #     \"max_step\": max_step - 1,\n",
    "            #     \"is_render\": is_render,\n",
    "            # }\n",
    "            env_config=env_config,\n",
    "            # env_config={\"disable_env_checker\": True},\n",
    "        )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            \n",
    "            # policy_mapping_fn=policy_mapping_fn,\n",
    "            policy_mapping_fn=SelfPlayCallback.get_mapping_fn(callback_instance),\n",
    "            \n",
    "            policies_to_train=policies_to_train,\n",
    "\n",
    "            count_steps_by = \"env_steps\"  # DEFAULT - but this changes everything!\n",
    "            # count_steps_by=\"agent_steps\",  # ‚Üê ADD THIS!\n",
    "        )\n",
    "        # .training(\n",
    "        #     model={\n",
    "        #         \"custom_model\": CustomLSTMRLModule,\n",
    "        #         # \"custom_model_config\": {\n",
    "        #         #     \"fcnet_hiddens\": [256, 256],  # Neural network architecture\n",
    "        #         #     \"fcnet_activation\": \"relu\",\n",
    "        #         # },\n",
    "        #     }\n",
    "        # )\n",
    "        .env_runners(\n",
    "            # num_env_runners=num_workers,\n",
    "\n",
    "            num_env_runners=0, \n",
    "            \n",
    "            # num_envs_per_env_runner=num_envs_per_worker,\n",
    "            # rollout_fragment_length=rollout_fragment_length,\n",
    "            # batch_mode=batch_mode,\n",
    "        )\n",
    "        .learners(\n",
    "            \n",
    "            # Local Learner running on the main process (driver/head node).\n",
    "            # Training runs on CPUs by default, or on a single GPU if num_gpus_per_learner > 0 is set. \n",
    "            # This is suitable for single-node training or simple, non-distributed setups.\n",
    "            num_learners=0,  # Typically 1 learner unless using distributed training\n",
    "\n",
    "            num_gpus_per_learner=num_gpus,  # Trainer GPU allocation\n",
    "            # num_cpus_per_learner=num_cpus_per_worker,\n",
    "        )\n",
    "        .training(\n",
    "            # train_batch_size_per_learner=train_batch_size / 4,\n",
    "            train_batch_size_per_learner=train_batch_size,\n",
    "            train_batch_size=train_batch_size,\n",
    "            num_epochs=4,\n",
    "        )\n",
    "        # .callbacks(SelfPlayCallback)\n",
    "        # .callbacks(lambda: SelfPlayCallback(win_rate_threshold=0.60))           \n",
    "        # .callbacks(lambda: MinimalLeagueCallback(\n",
    "        #     return_threshold=100.0,\n",
    "        #     check_every_n_iters=1,\n",
    "        # ))\n",
    "        \n",
    "        # .callbacks(lambda: SelfPlayCallback(\n",
    "        #     # win_rate_threshold=0.10,\n",
    "        #     ))\n",
    "        .callbacks(lambda: callback_instance)\n",
    "\n",
    "        # .output_dir(log_dir)\n",
    "        .framework(\"torch\")  # Explicitly set framework if needed\n",
    "        .debugging(log_level=\"DEBUG\")\n",
    "        # .api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)\n",
    "    )\n",
    "\n",
    "    # # Optional: Configure resources more granularly if needed\n",
    "    # if num_gpus_per_worker > 0:\n",
    "    #     config.env_runners(\n",
    "    #         num_gpus_per_env_runner=num_gpus_per_worker\n",
    "    #     )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKLNyViDkI9O"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163996,
     "status": "ok",
     "timestamp": 1756087446130,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "_Cq_T6fungjx",
    "outputId": "ed6c1255-2795-4496-ac2f-744d5fad9dfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 05:54:45,842\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2025-12-24 05:54:45,844\tWARNING algorithm_config.py:5033 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG: train_batch_size = 4096\n",
      "DEBUG: Expected episodes per iter = 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/usr/local/lib/python3.10/dist-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-12-24 05:54:46,069\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-24 05:54:46,078\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of EnvToModulePipeline.\n",
      "2025-12-24 05:54:46,087\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of EnvToModulePipeline.\n",
      "2025-12-24 05:54:46,103\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of EnvToModulePipeline.\n",
      "2025-12-24 05:54:46,112\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of EnvToModulePipeline.\n",
      "2025-12-24 05:54:46,121\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of EnvToModulePipeline.\n",
      "2025-12-24 05:54:46,123\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-12-24 05:54:46,133\tINFO connector_pipeline_v2.py:258 -- Added RemoveSingleTsTimeRankFromBatch to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,134\tINFO connector_pipeline_v2.py:258 -- Added ModuleToAgentUnmapping to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,134\tINFO connector_pipeline_v2.py:258 -- Added UnBatchToIndividualItems to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,135\tINFO connector_pipeline_v2.py:258 -- Added TensorToNumpy to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,135\tINFO connector_pipeline_v2.py:258 -- Added GetActions to the beginning of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,149\tINFO connector_pipeline_v2.py:272 -- Added NormalizeAndClipActions to the end of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,149\tINFO connector_pipeline_v2.py:272 -- Added ListifyDataForVectorEnv to the end of ModuleToEnvPipeline.\n",
      "2025-12-24 05:54:46,151\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'__env__': (None, None), '__env_single__': (Dict('agent_0': Box(-inf, inf, (40,), float32), 'agent_1': Box(-inf, inf, (40,), float32), 'agent_2': Box(-inf, inf, (40,), float32), 'agent_3': Box(-inf, inf, (40,), float32)), Dict('agent_0': Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_1': Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_2': Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)), 'agent_3': Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))), 'policy_0': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_1': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_2': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32))), 'policy_3': (Box(-inf, inf, (40,), float32), Dict('category': Discrete(9), 'price': Discrete(12), 'size_mean': Box(-1.0, 1.0, (1,), float32), 'size_sigma': Box(0.0, 1.0, (1,), float32)))}\n",
      "2025-12-24 05:54:46,185\tINFO connector_pipeline_v2.py:272 -- Added AddObservationsFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:46,185\tINFO connector_pipeline_v2.py:272 -- Added AddColumnsFromEpisodesToTrainBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:46,195\tINFO connector_pipeline_v2.py:272 -- Added AddTimeDimToBatchAndZeroPad to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:46,204\tINFO connector_pipeline_v2.py:272 -- Added AddStatesFromEpisodesToBatch to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:46,213\tINFO connector_pipeline_v2.py:272 -- Added AgentToModuleMapping to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:46,222\tINFO connector_pipeline_v2.py:272 -- Added BatchIndividualItems to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:46,230\tINFO connector_pipeline_v2.py:272 -- Added NumpyToTensor to the end of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:47,206\tINFO connector_pipeline_v2.py:258 -- Added AddOneTsToEpisodesAndTruncate to the beginning of LearnerConnectorPipeline.\n",
      "2025-12-24 05:54:47,239\tINFO connector_pipeline_v2.py:272 -- Added GeneralAdvantageEstimation to the end of LearnerConnectorPipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ACTUAL CONFIG train_batch_size: 4096\n",
      "ACTUAL CONFIG num_env_runners: 0\n",
      "ACTUAL CONFIG num_envs_per_env_runner: 1\n",
      "================================================================================\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode c0cb65cae2594b3aad1e3e0b57649e4e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -62891580.55721509, 'agent_1': -156953157.81648886, 'agent_2': -106311438.20820263, 'agent_3': -27957582.512301844} id_=c0cb65cae2594b3aad1e3e0b57649e4e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c0cb65cae2594b3aad1e3e0b57649e4e NAV Verification ====================\n",
      "  agent_0 NAV: 993,628.00\n",
      "  agent_1 NAV: 1,025,379.00\n",
      "  agent_2 NAV: 983,760.00\n",
      "  agent_3 NAV: 997,233.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode f763e269c829400b99954b6afd678454 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -22871166.6564979, 'agent_1': -130626972.49113445, 'agent_2': -30312794.475783676, 'agent_3': -84095399.89269681} id_=f763e269c829400b99954b6afd678454)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f763e269c829400b99954b6afd678454 NAV Verification ====================\n",
      "  agent_0 NAV: 994,486.00\n",
      "  agent_1 NAV: 999,950.00\n",
      "  agent_2 NAV: 1,000,060.00\n",
      "  agent_3 NAV: 1,005,504.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode c6ffea9302b94fbf8e4a02d3bc8cdbdb Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -35116674.76603975, 'agent_1': -113612494.65772234, 'agent_2': -118031275.90991296, 'agent_3': -70687092.75756365} id_=c6ffea9302b94fbf8e4a02d3bc8cdbdb)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c6ffea9302b94fbf8e4a02d3bc8cdbdb NAV Verification ====================\n",
      "  agent_0 NAV: 995,754.00\n",
      "  agent_1 NAV: 987,950.00\n",
      "  agent_2 NAV: 1,003,638.00\n",
      "  agent_3 NAV: 1,012,658.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "========================================\n",
      "Episode e615f7f582ea43c09104b36ea4955e69 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 1 League Stats:\n",
      "Mean: -79955635.89 | Std: 34827426.34 | Threshold: -76472893.26\n",
      "Policy Returns: {'policy_1': -133730874.98844856, 'policy_2': -84885169.53129975, 'policy_0': -40293140.659917586, 'policy_3': -60913358.38752077}\n",
      "Best Trainable: policy_0 (-40293140.66)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_1\n",
      "Source Policy: policy_0\n",
      "Return: -40293140.66\n",
      "Iteration: 1\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_1 created successfully!\n",
      "‚úì League size now: 3 (2 trainable + 1 champions)\n",
      "‚úì Active champions: ['champion_1']\n",
      "\n",
      "on_episode_end:MAEps(len=4 done=True Rs={'agent_0': 0.0, 'agent_1': 0.0, 'agent_2': 0.0, 'agent_3': 0.0} id_=e615f7f582ea43c09104b36ea4955e69)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e615f7f582ea43c09104b36ea4955e69 NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,417.00\n",
      "  agent_1 NAV: 1,005,875.00\n",
      "  agent_2 NAV: 1,025,212.00\n",
      "  agent_3 NAV: 957,496.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 40e2884b9e544cd08a3e5037b54d7729 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -25944764.5412661, 'agent_1': -105610669.35570198, 'agent_2': -97013005.0855471, 'agent_3': -194478167.88121155} id_=40e2884b9e544cd08a3e5037b54d7729)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 40e2884b9e544cd08a3e5037b54d7729 NAV Verification ====================\n",
      "  agent_0 NAV: 998,356.00\n",
      "  agent_1 NAV: 1,018,357.00\n",
      "  agent_2 NAV: 996,349.00\n",
      "  agent_3 NAV: 986,938.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 01ed5a35d441438683cf01867da84c78 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -38934504.91021699, 'agent_1': -38436945.93866681, 'agent_2': -76039362.70425232, 'agent_3': -72422076.86302805} id_=01ed5a35d441438683cf01867da84c78)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 01ed5a35d441438683cf01867da84c78 NAV Verification ====================\n",
      "  agent_0 NAV: 1,000,346.00\n",
      "  agent_1 NAV: 1,004,634.00\n",
      "  agent_2 NAV: 1,023,226.00\n",
      "  agent_3 NAV: 971,794.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6230466cf62f49a7876e9bc1efa63f80 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -115892168.3322793, 'agent_1': -104571203.95433581, 'agent_2': -308886104.36432546, 'agent_3': -137305522.67544758} id_=6230466cf62f49a7876e9bc1efa63f80)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6230466cf62f49a7876e9bc1efa63f80 NAV Verification ====================\n",
      "  agent_0 NAV: 985,999.00\n",
      "  agent_1 NAV: 994,430.00\n",
      "  agent_2 NAV: 1,040,829.00\n",
      "  agent_3 NAV: 978,742.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 6ed069e9c427492ab19c9c778bee6d9f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 2 League Stats:\n",
      "Mean: -102374671.05 | Std: 32091978.26 | Threshold: -99165473.22\n",
      "Policy Returns: {'policy_1': -103305518.01672998, 'policy_2': -130762921.480837, 'policy_0': -49747924.00638168, 'policy_3': -125682320.67887858}\n",
      "Best Trainable: policy_0 (-49747924.01)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=8 done=True Rs={'agent_0': -11029317.85444744, 'agent_1': -3409020.0228312374, 'agent_2': -1697815.2172034099, 'agent_3': -2074683.6104513064} id_=6ed069e9c427492ab19c9c778bee6d9f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6ed069e9c427492ab19c9c778bee6d9f NAV Verification ====================\n",
      "  agent_0 NAV: 951,390.00\n",
      "  agent_1 NAV: 1,014,973.00\n",
      "  agent_2 NAV: 1,039,140.00\n",
      "  agent_3 NAV: 994,497.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 762162e50b7f4732b0519b881fdcc870 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -110323764.0095387, 'agent_1': -78579750.13266753, 'agent_2': -109109585.11454837, 'agent_3': -306253659.81999046} id_=762162e50b7f4732b0519b881fdcc870)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 762162e50b7f4732b0519b881fdcc870 NAV Verification ====================\n",
      "  agent_0 NAV: 1,063,507.00\n",
      "  agent_1 NAV: 1,032,544.00\n",
      "  agent_2 NAV: 1,040,057.00\n",
      "  agent_3 NAV: 863,892.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 3b12d035ce964d439d87317eb86db3bf Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -183968359.55476093, 'agent_1': -208191832.79046178, 'agent_2': -80155956.52680111, 'agent_3': -79147514.63999695} id_=3b12d035ce964d439d87317eb86db3bf)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3b12d035ce964d439d87317eb86db3bf NAV Verification ====================\n",
      "  agent_0 NAV: 1,007,358.00\n",
      "  agent_1 NAV: 969,881.00\n",
      "  agent_2 NAV: 1,040,884.00\n",
      "  agent_3 NAV: 981,877.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode b13edd37c21541fc812cd19f0ad50eea Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -29638963.168233357, 'agent_1': -156407794.88529456, 'agent_2': -157396233.37590605, 'agent_3': -30968711.05922092} id_=b13edd37c21541fc812cd19f0ad50eea)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode b13edd37c21541fc812cd19f0ad50eea NAV Verification ====================\n",
      "  agent_0 NAV: 989,236.00\n",
      "  agent_1 NAV: 979,321.00\n",
      "  agent_2 NAV: 1,023,391.00\n",
      "  agent_3 NAV: 1,008,052.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "========================================\n",
      "Episode 9ee0eb69521b4ea393a10c9398e49bb2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 3 League Stats:\n",
      "Mean: -110668401.01 | Std: 17835285.04 | Threshold: -108884872.51\n",
      "Policy Returns: {'policy_1': -115587712.33295241, 'policy_2': -125176655.13652577, 'policy_0': -80351398.16201425, 'policy_3': -121557838.41361484}\n",
      "Best Trainable: policy_0 (-80351398.16)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_2\n",
      "Source Policy: policy_0\n",
      "Return: -80351398.16\n",
      "Iteration: 3\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_2 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_1', 'champion_2']\n",
      "\n",
      "on_episode_end:MAEps(len=12 done=True Rs={'agent_0': -1815621.8064734703, 'agent_1': -1757744.5189768279, 'agent_2': -3681044.574978127, 'agent_3': -7848592.245347365} id_=9ee0eb69521b4ea393a10c9398e49bb2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9ee0eb69521b4ea393a10c9398e49bb2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,037,971.00\n",
      "  agent_1 NAV: 1,035,761.00\n",
      "  agent_2 NAV: 951,357.00\n",
      "  agent_3 NAV: 974,911.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode bae73b3183374d9998473ae777c17d16 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -170011086.78989553, 'agent_1': -55968011.688736245, 'agent_2': -176866399.06825775, 'agent_3': -35619270.819139265} id_=bae73b3183374d9998473ae777c17d16)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bae73b3183374d9998473ae777c17d16 NAV Verification ====================\n",
      "  agent_0 NAV: 990,222.00\n",
      "  agent_1 NAV: 1,015,304.00\n",
      "  agent_2 NAV: 999,496.00\n",
      "  agent_3 NAV: 994,978.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 765af7e801c54ad5a5cf0acf127fdfd2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -97042319.26251704, 'agent_1': -159259428.44175828, 'agent_2': -48617221.59387104, 'agent_3': -94136328.87968834} id_=765af7e801c54ad5a5cf0acf127fdfd2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 765af7e801c54ad5a5cf0acf127fdfd2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,255.00\n",
      "  agent_1 NAV: 991,197.00\n",
      "  agent_2 NAV: 977,743.00\n",
      "  agent_3 NAV: 1,025,805.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 9f530ba205d548b497c525533110a63b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -85476910.96260472, 'agent_1': -457069332.9556015, 'agent_2': -123437248.28511561, 'agent_3': -382643703.13066185} id_=9f530ba205d548b497c525533110a63b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 9f530ba205d548b497c525533110a63b NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,412.00\n",
      "  agent_1 NAV: 921,729.00\n",
      "  agent_2 NAV: 1,006,804.00\n",
      "  agent_3 NAV: 1,068,055.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode e3b935f4a8e64aff99589b9f6812028a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 4 League Stats:\n",
      "Mean: -120037463.16 | Std: 18672436.58 | Threshold: -118170219.50\n",
      "Policy Returns: {'policy_1': -136971003.90165216, 'policy_2': -121269678.2191743, 'policy_0': -89259204.94440906, 'policy_3': -132649965.55919558}\n",
      "Best Trainable: policy_0 (-89259204.94)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=16 done=True Rs={'agent_0': -23057991.802253302, 'agent_1': -4267485.855297952, 'agent_2': -5780548.500219301, 'agent_3': -29468241.31904281} id_=e3b935f4a8e64aff99589b9f6812028a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e3b935f4a8e64aff99589b9f6812028a NAV Verification ====================\n",
      "  agent_0 NAV: 873,752.00\n",
      "  agent_1 NAV: 1,038,540.00\n",
      "  agent_2 NAV: 973,402.00\n",
      "  agent_3 NAV: 1,114,306.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 6876875af5a349c4b00ecceed3507b05 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_1\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -83213193.37102792, 'agent_1': -186516726.37418404, 'agent_2': -51338652.861137286, 'agent_3': -43383190.50478505} id_=6876875af5a349c4b00ecceed3507b05)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6876875af5a349c4b00ecceed3507b05 NAV Verification ====================\n",
      "  agent_0 NAV: 1,008,677.00\n",
      "  agent_1 NAV: 955,899.00\n",
      "  agent_2 NAV: 1,035,197.00\n",
      "  agent_3 NAV: 1,000,227.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 7e3b0fe8eec046e98826f2e2c1c102b0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -235173447.46906915, 'agent_1': -64859327.277756974, 'agent_2': -48038983.40797994, 'agent_3': -150615385.6116211} id_=7e3b0fe8eec046e98826f2e2c1c102b0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7e3b0fe8eec046e98826f2e2c1c102b0 NAV Verification ====================\n",
      "  agent_0 NAV: 947,617.00\n",
      "  agent_1 NAV: 1,010,540.00\n",
      "  agent_2 NAV: 1,012,494.00\n",
      "  agent_3 NAV: 1,029,349.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode a883aa45a4a7452b851651d9928c3d32 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_1\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -39645249.97136912, 'agent_1': -37299561.04609635, 'agent_2': -50723299.213805705, 'agent_3': -57619950.713576525} id_=a883aa45a4a7452b851651d9928c3d32)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a883aa45a4a7452b851651d9928c3d32 NAV Verification ====================\n",
      "  agent_0 NAV: 997,769.00\n",
      "  agent_1 NAV: 986,196.00\n",
      "  agent_2 NAV: 993,262.00\n",
      "  agent_3 NAV: 1,022,773.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "========================================\n",
      "Episode 74260bd2b9ed47048d12806991f95610 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_1', 'champion_2']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 5 League Stats:\n",
      "Mean: -116524975.22 | Std: 11672531.86 | Threshold: -115357722.04\n",
      "Policy Returns: {'policy_1': -126596773.46246727, 'policy_2': -108162720.06012772, 'policy_0': -102029047.21674359, 'policy_3': -129311360.16020423}\n",
      "Best Trainable: policy_0 (-102029047.22)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_1 (from iteration 1, return=-40293140.66)\n",
      "‚úì Champion removed. Active champions: ['champion_2']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_3\n",
      "Source Policy: policy_0\n",
      "Return: -102029047.22\n",
      "Iteration: 5\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_3 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_2', 'champion_3']\n",
      "\n",
      "on_episode_end:MAEps(len=20 done=True Rs={'agent_0': -13797993.348141493, 'agent_1': -8719049.676007528, 'agent_2': -18089471.474438585, 'agent_3': -2291739.918137706} id_=74260bd2b9ed47048d12806991f95610)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 74260bd2b9ed47048d12806991f95610 NAV Verification ====================\n",
      "  agent_0 NAV: 946,191.00\n",
      "  agent_1 NAV: 1,021,218.00\n",
      "  agent_2 NAV: 1,018,712.00\n",
      "  agent_3 NAV: 1,013,879.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode be619d1f515140569385ee9767596f5d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -36289816.009117655, 'agent_1': -66705500.75619579, 'agent_2': -149486062.64772555, 'agent_3': -172503988.58143505} id_=be619d1f515140569385ee9767596f5d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode be619d1f515140569385ee9767596f5d NAV Verification ====================\n",
      "  agent_0 NAV: 996,948.00\n",
      "  agent_1 NAV: 999,739.00\n",
      "  agent_2 NAV: 1,000,858.00\n",
      "  agent_3 NAV: 1,002,455.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode cd7b1d8278d345f9862146c45abc840a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -212010240.27989015, 'agent_1': -134421808.91869262, 'agent_2': -49670160.849077076, 'agent_3': -99098379.6315973} id_=cd7b1d8278d345f9862146c45abc840a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode cd7b1d8278d345f9862146c45abc840a NAV Verification ====================\n",
      "  agent_0 NAV: 1,058,834.00\n",
      "  agent_1 NAV: 969,319.00\n",
      "  agent_2 NAV: 991,551.00\n",
      "  agent_3 NAV: 980,296.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 5f16ae22aadb4da4b8aec0a4e860e4ae Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -65489376.6725059, 'agent_1': -119152779.14620729, 'agent_2': -234353114.31333295, 'agent_3': -97622356.41792502} id_=5f16ae22aadb4da4b8aec0a4e860e4ae)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 5f16ae22aadb4da4b8aec0a4e860e4ae NAV Verification ====================\n",
      "  agent_0 NAV: 991,015.00\n",
      "  agent_1 NAV: 1,056,604.00\n",
      "  agent_2 NAV: 906,063.00\n",
      "  agent_3 NAV: 1,046,318.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 17a44023f9f34ff6812e5efc40d2ccff Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_2\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 6 League Stats:\n",
      "Mean: -116886014.67 | Std: 6962468.28 | Threshold: -116189767.84\n",
      "Policy Returns: {'policy_1': -120575958.46905212, 'policy_2': -115906892.88139492, 'policy_0': -106158965.17942894, 'policy_3': -124902242.13534255}\n",
      "Best Trainable: policy_0 (-106158965.18)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=24 done=True Rs={'agent_0': -1234997.3018793208, 'agent_1': -4930167.274045056, 'agent_2': -3219312.294754358, 'agent_3': -8358440.042529529} id_=17a44023f9f34ff6812e5efc40d2ccff)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 17a44023f9f34ff6812e5efc40d2ccff NAV Verification ====================\n",
      "  agent_0 NAV: 980,467.00\n",
      "  agent_1 NAV: 1,027,460.00\n",
      "  agent_2 NAV: 1,018,582.00\n",
      "  agent_3 NAV: 973,491.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode 6e1b3d821f7e4e98a499b8f348643f6b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -95484763.60541104, 'agent_1': -63651790.626512766, 'agent_2': -38572468.54855101, 'agent_3': -55845700.90687132} id_=6e1b3d821f7e4e98a499b8f348643f6b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6e1b3d821f7e4e98a499b8f348643f6b NAV Verification ====================\n",
      "  agent_0 NAV: 973,924.00\n",
      "  agent_1 NAV: 1,000,134.00\n",
      "  agent_2 NAV: 1,001,140.00\n",
      "  agent_3 NAV: 1,024,802.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode f619627ad85743c9ad4705f7c5122e07 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -99063674.45161682, 'agent_1': -464935317.3827246, 'agent_2': -405660173.69344777, 'agent_3': -37934826.17487181} id_=f619627ad85743c9ad4705f7c5122e07)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f619627ad85743c9ad4705f7c5122e07 NAV Verification ====================\n",
      "  agent_0 NAV: 948,161.00\n",
      "  agent_1 NAV: 1,093,457.00\n",
      "  agent_2 NAV: 939,810.00\n",
      "  agent_3 NAV: 1,018,572.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode cc8f001f4c4941429ffa74e806f671b0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -21623780.257998463, 'agent_1': -42461341.87983278, 'agent_2': -63356708.178414166, 'agent_3': -35912548.4044263} id_=cc8f001f4c4941429ffa74e806f671b0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode cc8f001f4c4941429ffa74e806f671b0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,003,816.00\n",
      "  agent_1 NAV: 1,015,386.00\n",
      "  agent_2 NAV: 980,117.00\n",
      "  agent_3 NAV: 1,000,681.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "========================================\n",
      "Episode fd3ac75bf1ab49b8b00c35b734572a71 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_2', 'champion_3']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 7 League Stats:\n",
      "Mean: -116319441.65 | Std: 9560417.51 | Threshold: -115363399.90\n",
      "Policy Returns: {'policy_1': -127971025.53603859, 'policy_2': -120058703.0774872, 'policy_0': -101644556.64859302, 'policy_3': -115603481.33966808}\n",
      "Best Trainable: policy_0 (-101644556.65)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_2 (from iteration 3, return=-80351398.16)\n",
      "‚úì Champion removed. Active champions: ['champion_3']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_4\n",
      "Source Policy: policy_0\n",
      "Return: -101644556.65\n",
      "Iteration: 7\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_4 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_3', 'champion_4']\n",
      "\n",
      "on_episode_end:MAEps(len=28 done=True Rs={'agent_0': -6835890.83813628, 'agent_1': -8521769.795204218, 'agent_2': -11095713.249376332, 'agent_3': -1548415.6865970572} id_=fd3ac75bf1ab49b8b00c35b734572a71)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fd3ac75bf1ab49b8b00c35b734572a71 NAV Verification ====================\n",
      "  agent_0 NAV: 991,153.00\n",
      "  agent_1 NAV: 977,594.00\n",
      "  agent_2 NAV: 1,028,786.00\n",
      "  agent_3 NAV: 1,002,467.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 6d5453a5db114e4f9b1f072791ad6e85 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -77328834.26134732, 'agent_1': -89252518.77470188, 'agent_2': -70416914.86362506, 'agent_3': -68341068.18938948} id_=6d5453a5db114e4f9b1f072791ad6e85)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 6d5453a5db114e4f9b1f072791ad6e85 NAV Verification ====================\n",
      "  agent_0 NAV: 986,949.00\n",
      "  agent_1 NAV: 1,008,334.00\n",
      "  agent_2 NAV: 986,905.00\n",
      "  agent_3 NAV: 1,017,812.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode a63afa9c75d249fc86e4f1c5e120629c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -57724369.39674973, 'agent_1': -97949837.29929006, 'agent_2': -55317863.480806194, 'agent_3': -147744606.49384576} id_=a63afa9c75d249fc86e4f1c5e120629c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a63afa9c75d249fc86e4f1c5e120629c NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,645.00\n",
      "  agent_1 NAV: 937,924.00\n",
      "  agent_2 NAV: 1,025,906.00\n",
      "  agent_3 NAV: 1,031,525.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode f3d1333767374279b1459e36d6737836 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -159084364.9716405, 'agent_1': -197002311.27816454, 'agent_2': -211014355.99902654, 'agent_3': -149990434.41997048} id_=f3d1333767374279b1459e36d6737836)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode f3d1333767374279b1459e36d6737836 NAV Verification ====================\n",
      "  agent_0 NAV: 951,360.00\n",
      "  agent_1 NAV: 1,053,646.00\n",
      "  agent_2 NAV: 952,336.00\n",
      "  agent_3 NAV: 1,042,658.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 73d5a891039d4bbab8d8ab1b90853c0a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 8 League Stats:\n",
      "Mean: -117093765.40 | Std: 9657889.26 | Threshold: -116127976.47\n",
      "Policy Returns: {'policy_1': -128026430.42775728, 'policy_2': -123845372.34167723, 'policy_0': -103171019.16275956, 'policy_3': -113332239.65852223}\n",
      "Best Trainable: policy_0 (-103171019.16)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=32 done=True Rs={'agent_0': -6313636.671037666, 'agent_1': -5660893.825889351, 'agent_2': -2281787.6944993925, 'agent_3': -9194333.483629525} id_=73d5a891039d4bbab8d8ab1b90853c0a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 73d5a891039d4bbab8d8ab1b90853c0a NAV Verification ====================\n",
      "  agent_0 NAV: 975,086.00\n",
      "  agent_1 NAV: 914,637.00\n",
      "  agent_2 NAV: 982,068.00\n",
      "  agent_3 NAV: 1,128,209.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode fa695f6a83154bc7b79d5d032870ddd2 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -27368254.395216696, 'agent_1': -118172788.88815022, 'agent_2': -45077899.80310379, 'agent_3': -170661898.6947209} id_=fa695f6a83154bc7b79d5d032870ddd2)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode fa695f6a83154bc7b79d5d032870ddd2 NAV Verification ====================\n",
      "  agent_0 NAV: 1,004,770.00\n",
      "  agent_1 NAV: 985,403.00\n",
      "  agent_2 NAV: 995,287.00\n",
      "  agent_3 NAV: 1,014,540.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 1972ced1b09049c99e88362d5070317a Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -104365714.0819169, 'agent_1': -180990825.9676422, 'agent_2': -135055081.3232211, 'agent_3': -117759176.5914226} id_=1972ced1b09049c99e88362d5070317a)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 1972ced1b09049c99e88362d5070317a NAV Verification ====================\n",
      "  agent_0 NAV: 965,676.00\n",
      "  agent_1 NAV: 1,001,146.00\n",
      "  agent_2 NAV: 1,012,049.00\n",
      "  agent_3 NAV: 1,021,129.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 2f7a464caa384525944e9c22df0dab8d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -120502256.60295473, 'agent_1': -59088458.80580046, 'agent_2': -420447862.4633891, 'agent_3': -473756774.14830536} id_=2f7a464caa384525944e9c22df0dab8d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 2f7a464caa384525944e9c22df0dab8d NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,628.00\n",
      "  agent_1 NAV: 1,014,461.00\n",
      "  agent_2 NAV: 933,392.00\n",
      "  agent_3 NAV: 1,050,519.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "========================================\n",
      "Episode 56b5f9e54fe64be8b504efcbde3a28d5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_3', 'champion_4']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 9 League Stats:\n",
      "Mean: -122368065.51 | Std: 12285993.71 | Threshold: -121139466.13\n",
      "Policy Returns: {'policy_1': -129791463.03191353, 'policy_2': -127596464.77548727, 'policy_0': -101187780.64071916, 'policy_3': -130896553.57437932}\n",
      "Best Trainable: policy_0 (-101187780.64)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_3 (from iteration 5, return=-102029047.22)\n",
      "‚úì Champion removed. Active champions: ['champion_4']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_5\n",
      "Source Policy: policy_0\n",
      "Return: -101187780.64\n",
      "Iteration: 9\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_5 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_4', 'champion_5']\n",
      "\n",
      "on_episode_end:MAEps(len=36 done=True Rs={'agent_0': -7521283.928434462, 'agent_1': -891684.2385456285, 'agent_2': -9966544.014908552, 'agent_3': -9329741.95483645} id_=56b5f9e54fe64be8b504efcbde3a28d5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 56b5f9e54fe64be8b504efcbde3a28d5 NAV Verification ====================\n",
      "  agent_0 NAV: 992,432.00\n",
      "  agent_1 NAV: 996,979.00\n",
      "  agent_2 NAV: 983,955.00\n",
      "  agent_3 NAV: 1,026,634.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 585ef9009672486c9fa63096b705ef65 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -174139605.10172704, 'agent_1': -89722559.08358636, 'agent_2': -177382504.47483042, 'agent_3': -108291228.38776478} id_=585ef9009672486c9fa63096b705ef65)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 585ef9009672486c9fa63096b705ef65 NAV Verification ====================\n",
      "  agent_0 NAV: 928,026.00\n",
      "  agent_1 NAV: 1,026,891.00\n",
      "  agent_2 NAV: 1,059,395.00\n",
      "  agent_3 NAV: 985,688.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 59eb4436bf6d4160829c6faff751f297 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -102762725.14044042, 'agent_1': -113191611.07095681, 'agent_2': -193413691.92407334, 'agent_3': -352579689.8957397} id_=59eb4436bf6d4160829c6faff751f297)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 59eb4436bf6d4160829c6faff751f297 NAV Verification ====================\n",
      "  agent_0 NAV: 1,001,065.00\n",
      "  agent_1 NAV: 999,057.00\n",
      "  agent_2 NAV: 1,006,032.00\n",
      "  agent_3 NAV: 993,846.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 64398b4263034d4f9dd22c55f708ef1d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -179537376.18356928, 'agent_1': -76398749.24347702, 'agent_2': -96365040.1316958, 'agent_3': -38025907.137295224} id_=64398b4263034d4f9dd22c55f708ef1d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 64398b4263034d4f9dd22c55f708ef1d NAV Verification ====================\n",
      "  agent_0 NAV: 945,775.00\n",
      "  agent_1 NAV: 1,019,751.00\n",
      "  agent_2 NAV: 1,035,271.00\n",
      "  agent_3 NAV: 999,203.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode e7ef5b09481044bb93a5c9269e77925b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 10 League Stats:\n",
      "Mean: -123220602.53 | Std: 11178121.02 | Threshold: -122102790.43\n",
      "Policy Returns: {'policy_1': -124589503.27468608, 'policy_2': -129430749.9782956, 'policy_0': -104757279.47015943, 'policy_3': -134104877.3985983}\n",
      "Best Trainable: policy_0 (-104757279.47)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=40 done=True Rs={'agent_0': -26624278.57738901, 'agent_1': -17688050.365784187, 'agent_2': -33455979.777415052, 'agent_3': -21066444.840208404} id_=e7ef5b09481044bb93a5c9269e77925b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode e7ef5b09481044bb93a5c9269e77925b NAV Verification ====================\n",
      "  agent_0 NAV: 962,953.00\n",
      "  agent_1 NAV: 1,018,855.00\n",
      "  agent_2 NAV: 1,023,197.00\n",
      "  agent_3 NAV: 994,995.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 428d140bdf1d46138d4013f9cdafe49c Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -80464100.32826652, 'agent_1': -55526886.16091376, 'agent_2': -120423791.18488471, 'agent_3': -99292499.40008289} id_=428d140bdf1d46138d4013f9cdafe49c)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 428d140bdf1d46138d4013f9cdafe49c NAV Verification ====================\n",
      "  agent_0 NAV: 993,174.00\n",
      "  agent_1 NAV: 1,008,761.00\n",
      "  agent_2 NAV: 1,013,986.00\n",
      "  agent_3 NAV: 984,079.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode 54d0bb61086f4c7e92deef596cffe0c5 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_4\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -229326879.8843667, 'agent_1': -56673824.032302484, 'agent_2': -87669172.15353954, 'agent_3': -197105199.08933386} id_=54d0bb61086f4c7e92deef596cffe0c5)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 54d0bb61086f4c7e92deef596cffe0c5 NAV Verification ====================\n",
      "  agent_0 NAV: 1,050,353.00\n",
      "  agent_1 NAV: 996,540.00\n",
      "  agent_2 NAV: 991,596.00\n",
      "  agent_3 NAV: 961,511.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode a000e7c074164f5c914add7d3784f7cc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_4\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -196868910.46154797, 'agent_1': -443214377.706939, 'agent_2': -412261957.1181845, 'agent_3': -152482096.5905751} id_=a000e7c074164f5c914add7d3784f7cc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a000e7c074164f5c914add7d3784f7cc NAV Verification ====================\n",
      "  agent_0 NAV: 992,318.00\n",
      "  agent_1 NAV: 989,872.00\n",
      "  agent_2 NAV: 1,023,871.00\n",
      "  agent_3 NAV: 993,939.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "========================================\n",
      "Episode c0c0579eff364189899095061d5430cc Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_4', 'champion_5']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 11 League Stats:\n",
      "Mean: -126956956.59 | Std: 9506658.24 | Threshold: -126006290.77\n",
      "Policy Returns: {'policy_1': -128529784.07202257, 'policy_2': -134730646.55459183, 'policy_0': -110993802.66962196, 'policy_3': -133573593.07952373}\n",
      "Best Trainable: policy_0 (-110993802.67)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_4 (from iteration 7, return=-101644556.65)\n",
      "‚úì Champion removed. Active champions: ['champion_5']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_6\n",
      "Source Policy: policy_0\n",
      "Return: -110993802.67\n",
      "Iteration: 11\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_6 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_5', 'champion_6']\n",
      "\n",
      "on_episode_end:MAEps(len=44 done=True Rs={'agent_0': -43888414.20513572, 'agent_1': -9479235.842632752, 'agent_2': -54146186.465796076, 'agent_3': -27922815.832385108} id_=c0c0579eff364189899095061d5430cc)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c0c0579eff364189899095061d5430cc NAV Verification ====================\n",
      "  agent_0 NAV: 1,044,717.00\n",
      "  agent_1 NAV: 968,103.00\n",
      "  agent_2 NAV: 976,494.00\n",
      "  agent_3 NAV: 1,010,686.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 270e5b00eba840f0a4801407655009f0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -68527221.0499009, 'agent_1': -78351553.26782623, 'agent_2': -37199621.46926604, 'agent_3': -61532828.197651245} id_=270e5b00eba840f0a4801407655009f0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 270e5b00eba840f0a4801407655009f0 NAV Verification ====================\n",
      "  agent_0 NAV: 993,839.00\n",
      "  agent_1 NAV: 1,020,447.00\n",
      "  agent_2 NAV: 1,007,148.00\n",
      "  agent_3 NAV: 978,566.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode bc22a8bd10ce439dba50f9f854f6040e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -97544890.8251281, 'agent_1': -28721243.159862097, 'agent_2': -319962298.46845603, 'agent_3': -432774316.4750281} id_=bc22a8bd10ce439dba50f9f854f6040e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bc22a8bd10ce439dba50f9f854f6040e NAV Verification ====================\n",
      "  agent_0 NAV: 1,027,614.00\n",
      "  agent_1 NAV: 1,005,415.00\n",
      "  agent_2 NAV: 1,067,785.00\n",
      "  agent_3 NAV: 899,186.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode 4e85dd631bed421197761739842f1430 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -90939542.68569118, 'agent_1': -157780920.8818679, 'agent_2': -77501117.54285349, 'agent_3': -203832596.82224765} id_=4e85dd631bed421197761739842f1430)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 4e85dd631bed421197761739842f1430 NAV Verification ====================\n",
      "  agent_0 NAV: 976,517.00\n",
      "  agent_1 NAV: 973,808.00\n",
      "  agent_2 NAV: 1,026,945.00\n",
      "  agent_3 NAV: 1,022,730.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode b9d897e91d854534935c968fbc122c84 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 12 League Stats:\n",
      "Mean: -130248124.85 | Std: 10396335.70 | Threshold: -129208491.28\n",
      "Policy Returns: {'policy_1': -127525040.49795353, 'policy_2': -138509528.1564908, 'policy_0': -114415031.75947082, 'policy_3': -140542898.9784701}\n",
      "Best Trainable: policy_0 (-114415031.76)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=48 done=True Rs={'agent_0': -20674514.64392592, 'agent_1': -933251.4635199645, 'agent_2': -4786176.63791988, 'agent_3': -25305448.375031337} id_=b9d897e91d854534935c968fbc122c84)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode b9d897e91d854534935c968fbc122c84 NAV Verification ====================\n",
      "  agent_0 NAV: 955,090.00\n",
      "  agent_1 NAV: 1,014,746.00\n",
      "  agent_2 NAV: 978,217.00\n",
      "  agent_3 NAV: 1,051,947.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode d9e33274d52f40a7914dcdec8d66e63f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -118465540.4858294, 'agent_1': -92353628.34143256, 'agent_2': -107004904.40087396, 'agent_3': -132633548.55958974} id_=d9e33274d52f40a7914dcdec8d66e63f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode d9e33274d52f40a7914dcdec8d66e63f NAV Verification ====================\n",
      "  agent_0 NAV: 1,014,801.00\n",
      "  agent_1 NAV: 1,020,759.00\n",
      "  agent_2 NAV: 986,176.00\n",
      "  agent_3 NAV: 978,264.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode bb2c8e6d5ae3473f9f678ae9ed6ae77f Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -44741942.93247187, 'agent_1': -142747301.40939063, 'agent_2': -55315282.47864985, 'agent_3': -172668806.68393347} id_=bb2c8e6d5ae3473f9f678ae9ed6ae77f)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode bb2c8e6d5ae3473f9f678ae9ed6ae77f NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,506.00\n",
      "  agent_1 NAV: 984,565.00\n",
      "  agent_2 NAV: 982,143.00\n",
      "  agent_3 NAV: 1,019,786.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode c59a5a62f11c4072ab63a3c38b848646 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_5\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -79519429.3662101, 'agent_1': -111455562.73094323, 'agent_2': -353437700.37152576, 'agent_3': -160573525.94445372} id_=c59a5a62f11c4072ab63a3c38b848646)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode c59a5a62f11c4072ab63a3c38b848646 NAV Verification ====================\n",
      "  agent_0 NAV: 984,167.00\n",
      "  agent_1 NAV: 1,011,352.00\n",
      "  agent_2 NAV: 1,020,162.00\n",
      "  agent_3 NAV: 984,319.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "========================================\n",
      "Episode ff41557d6089445fa812e52e87e472f0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_5\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_5', 'champion_6']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 13 League Stats:\n",
      "Mean: -129824694.85 | Std: 11479008.93 | Threshold: -128676793.95\n",
      "Policy Returns: {'policy_1': -125407534.61107065, 'policy_2': -138930991.11637148, 'policy_0': -113098877.76357034, 'policy_3': -141861375.89631608}\n",
      "Best Trainable: policy_0 (-113098877.76)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_5 (from iteration 9, return=-101187780.64)\n",
      "‚úì Champion removed. Active champions: ['champion_6']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_7\n",
      "Source Policy: policy_0\n",
      "Return: -113098877.76\n",
      "Iteration: 13\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_7 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_6', 'champion_7']\n",
      "\n",
      "on_episode_end:MAEps(len=52 done=True Rs={'agent_0': -29787251.836092804, 'agent_1': -6476349.903060012, 'agent_2': -30174903.651774224, 'agent_3': -3592837.291569619} id_=ff41557d6089445fa812e52e87e472f0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode ff41557d6089445fa812e52e87e472f0 NAV Verification ====================\n",
      "  agent_0 NAV: 982,923.00\n",
      "  agent_1 NAV: 1,006,531.00\n",
      "  agent_2 NAV: 1,017,405.00\n",
      "  agent_3 NAV: 993,141.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode da6e3bd1f7de4cc79ad7134af1cfffa4 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -129069833.52805986, 'agent_1': -221396608.91691732, 'agent_2': -65154138.42358736, 'agent_3': -82955701.15145387} id_=da6e3bd1f7de4cc79ad7134af1cfffa4)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode da6e3bd1f7de4cc79ad7134af1cfffa4 NAV Verification ====================\n",
      "  agent_0 NAV: 1,035,211.00\n",
      "  agent_1 NAV: 950,547.00\n",
      "  agent_2 NAV: 1,001,887.00\n",
      "  agent_3 NAV: 1,012,355.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode a67864bf418d4a85bf2f0e925032fd63 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -210576084.31225583, 'agent_1': -151295649.92791042, 'agent_2': -565897947.0967975, 'agent_3': -220645810.4796858} id_=a67864bf418d4a85bf2f0e925032fd63)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode a67864bf418d4a85bf2f0e925032fd63 NAV Verification ====================\n",
      "  agent_0 NAV: 963,911.00\n",
      "  agent_1 NAV: 1,040,453.00\n",
      "  agent_2 NAV: 1,019,281.00\n",
      "  agent_3 NAV: 976,355.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 3cd49277c2024a279042b251ee3cb388 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -33794439.22838744, 'agent_1': -208948730.9574624, 'agent_2': -347542987.67014503, 'agent_3': -106754887.64786115} id_=3cd49277c2024a279042b251ee3cb388)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 3cd49277c2024a279042b251ee3cb388 NAV Verification ====================\n",
      "  agent_0 NAV: 1,005,572.00\n",
      "  agent_1 NAV: 976,692.00\n",
      "  agent_2 NAV: 1,010,814.00\n",
      "  agent_3 NAV: 1,006,922.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 2cfc0fdda4df4672a28b6186593162f1 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 14 League Stats:\n",
      "Mean: -134431774.93 | Std: 12999707.07 | Threshold: -133131804.22\n",
      "Policy Returns: {'policy_1': -128657993.88469684, 'policy_2': -151395003.05849436, 'policy_0': -116748213.21030764, 'policy_3': -140925889.5544868}\n",
      "Best Trainable: policy_0 (-116748213.21)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n",
      "on_episode_end:MAEps(len=56 done=True Rs={'agent_0': -32134671.84604358, 'agent_1': -27823696.2644072, 'agent_2': -3197213.0119980266, 'agent_3': -52317739.40152691} id_=2cfc0fdda4df4672a28b6186593162f1)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 2cfc0fdda4df4672a28b6186593162f1 NAV Verification ====================\n",
      "  agent_0 NAV: 1,027,032.00\n",
      "  agent_1 NAV: 1,006,970.00\n",
      "  agent_2 NAV: 1,025,995.00\n",
      "  agent_3 NAV: 940,003.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 7b746b8296574563b72d531d4e49d4e0 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -158003469.44142902, 'agent_1': -81082399.73777585, 'agent_2': -36280733.26485364, 'agent_3': -67749948.23209694} id_=7b746b8296574563b72d531d4e49d4e0)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7b746b8296574563b72d531d4e49d4e0 NAV Verification ====================\n",
      "  agent_0 NAV: 1,013,925.00\n",
      "  agent_1 NAV: 975,589.00\n",
      "  agent_2 NAV: 1,012,316.00\n",
      "  agent_3 NAV: 998,170.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 546048ca14c84d879a03c8ca5331a85b Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -136582284.84040818, 'agent_1': -61697546.16362656, 'agent_2': -195330440.78762373, 'agent_3': -251569649.15267572} id_=546048ca14c84d879a03c8ca5331a85b)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 546048ca14c84d879a03c8ca5331a85b NAV Verification ====================\n",
      "  agent_0 NAV: 1,007,037.00\n",
      "  agent_1 NAV: 1,001,959.00\n",
      "  agent_2 NAV: 1,012,232.00\n",
      "  agent_3 NAV: 978,772.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 7102f8c41a36426daf5845c6aed45521 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_6\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -123649602.93575725, 'agent_1': -283633246.9489932, 'agent_2': -68288256.11892626, 'agent_3': -68961612.89350635} id_=7102f8c41a36426daf5845c6aed45521)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 7102f8c41a36426daf5845c6aed45521 NAV Verification ====================\n",
      "  agent_0 NAV: 1,011,013.00\n",
      "  agent_1 NAV: 990,518.00\n",
      "  agent_2 NAV: 993,001.00\n",
      "  agent_3 NAV: 1,005,468.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "========================================\n",
      "Episode 56f5e6ce619f4684a16c24b2c0c015d6 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_6\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_6', 'champion_7']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 15 League Stats:\n",
      "Mean: -136333276.75 | Std: 11393579.06 | Threshold: -135193918.85\n",
      "Policy Returns: {'policy_1': -130023745.17907016, 'policy_2': -147878159.20665753, 'policy_0': -120822664.75723039, 'policy_3': -146608537.86677513}\n",
      "Best Trainable: policy_0 (-120822664.76)\n",
      "================================================================================\n",
      "\n",
      "Max champions (2) reached, will remove oldest\n",
      "\n",
      "‚ö†Ô∏è  Removing oldest champion: champion_6 (from iteration 11, return=-110993802.67)\n",
      "‚úì Champion removed. Active champions: ['champion_7']\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "üèÜ CREATING CHAMPION SNAPSHOT üèÜ\n",
      "Champion ID: champion_8\n",
      "Source Policy: policy_0\n",
      "Return: -120822664.76\n",
      "Iteration: 15\n",
      "********************************************************************************\n",
      "\n",
      "‚úì Champion champion_8 created successfully!\n",
      "‚úì League size now: 4 (2 trainable + 2 champions)\n",
      "‚úì Active champions: ['champion_7', 'champion_8']\n",
      "\n",
      "on_episode_end:MAEps(len=60 done=True Rs={'agent_0': -4030565.0182097987, 'agent_1': -4274820.098565325, 'agent_2': -18489034.000580613, 'agent_3': -10026286.617599644} id_=56f5e6ce619f4684a16c24b2c0c015d6)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 56f5e6ce619f4684a16c24b2c0c015d6 NAV Verification ====================\n",
      "  agent_0 NAV: 994,116.00\n",
      "  agent_1 NAV: 1,010,205.00\n",
      "  agent_2 NAV: 980,101.00\n",
      "  agent_3 NAV: 1,015,578.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode b182389323d94e66af024e3bc9bcfb3e Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_8\n",
      "  agent_3 -> policy_2\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -56757426.3424061, 'agent_1': -109677470.3666134, 'agent_2': -32265507.855560463, 'agent_3': -64916318.854835995} id_=b182389323d94e66af024e3bc9bcfb3e)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode b182389323d94e66af024e3bc9bcfb3e NAV Verification ====================\n",
      "  agent_0 NAV: 1,022,400.00\n",
      "  agent_1 NAV: 948,154.00\n",
      "  agent_2 NAV: 1,001,785.00\n",
      "  agent_3 NAV: 1,027,661.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 591b8ba7ed1d40a092b29603536384a3 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_2\n",
      "  agent_3 -> policy_3\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -193358328.98599637, 'agent_1': -52196590.87883206, 'agent_2': -329360990.4925642, 'agent_3': -149665144.1830415} id_=591b8ba7ed1d40a092b29603536384a3)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 591b8ba7ed1d40a092b29603536384a3 NAV Verification ====================\n",
      "  agent_0 NAV: 975,555.00\n",
      "  agent_1 NAV: 1,020,684.00\n",
      "  agent_2 NAV: 1,011,545.00\n",
      "  agent_3 NAV: 992,216.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 715f4cbbff4f4d2d9d5e0eee7095b02d Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> policy_3\n",
      "  agent_3 -> champion_7\n",
      "========================================\n",
      "\n",
      "on_episode_end:MAEps(len=1025 done=True Rs={'agent_0': -86350652.83342518, 'agent_1': -221436093.94363865, 'agent_2': -386333741.4419973, 'agent_3': -128345564.57660715} id_=715f4cbbff4f4d2d9d5e0eee7095b02d)\n",
      "DEBUG: env type: <class 'ray.rllib.env.vector.sync_vector_multi_agent_env.SyncVectorMultiAgentEnv'>\n",
      "DEBUG: env_runner type: <class 'ray.rllib.env.multi_agent_env_runner.MultiAgentEnvRunner'>\n",
      "DEBUG: init_cash derived: 1000000\n",
      "DEBUG: num_agents derived: 4\n",
      "DEBUG: total_initial_cash: 4000000.0\n",
      "\n",
      "==================== Episode 715f4cbbff4f4d2d9d5e0eee7095b02d NAV Verification ====================\n",
      "  agent_0 NAV: 1,044,856.00\n",
      "  agent_1 NAV: 1,007,412.00\n",
      "  agent_2 NAV: 937,844.00\n",
      "  agent_3 NAV: 1,009,888.00\n",
      "  Total NAV: 4,000,000.00\n",
      "  Expected Total Initial Cash: 4,000,000.00\n",
      "  Verification: SUCCESS (Total NAV matches initial cash)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "========================================\n",
      "Episode 28b22a784998418b843349a4bbad4826 Started - Policy Map:\n",
      "  agent_0 -> policy_0\n",
      "  agent_1 -> policy_1\n",
      "  agent_2 -> champion_7\n",
      "  agent_3 -> champion_8\n",
      "========================================\n",
      "\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "\n",
      "Candidates: ['policy_2', 'policy_3', 'champion_7', 'champion_8']\n",
      "Warning: policy_reward_mean not found, falling back to agent returns\n",
      "\n",
      "================================================================================\n",
      "Iteration 16 League Stats:\n",
      "Mean: -135980493.36 | Std: 12640778.07 | Threshold: -134716415.56\n",
      "Policy Returns: {'policy_1': -128962850.53484598, 'policy_2': -151892941.70778286, 'policy_0': -119344059.16097145, 'policy_3': -143722122.04472393}\n",
      "Best Trainable: policy_0 (-119344059.16)\n",
      "================================================================================\n",
      "\n",
      "Skipping champion creation: only 1 iterations since last champion (min: 2)\n"
     ]
    }
   ],
   "source": [
    "def go_train(config):\n",
    "    # trainer = ppo.PPOTrainer(config=config, env=\"continuousDoubleAuction-v0\")\n",
    "\n",
    "    # In your notebook, add this right before config.build():\n",
    "    print(\"=\" * 80)  \n",
    "    print(f\"DEBUG: train_batch_size = {train_batch_size}\")\n",
    "    print(f\"DEBUG: Expected episodes per iter = {num_episodes_per_iter}\")\n",
    "    # print(f\"DEBUG: Agent timesteps per episode = {agent_time_step_per_episode}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    algo = config.build()\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ACTUAL CONFIG train_batch_size: {algo.config.train_batch_size}\")\n",
    "    print(f\"ACTUAL CONFIG num_env_runners: {algo.config.num_env_runners}\")\n",
    "    print(f\"ACTUAL CONFIG num_envs_per_env_runner: {algo.config.num_envs_per_env_runner}\")  # ‚Üê KEY!\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # if is_restore == True:\n",
    "    #     trainer.restore(restore_path)\n",
    "\n",
    "    # g_store = ray.util.get_actor(\"g_store\")\n",
    "    # result = None\n",
    "    for i in range(num_iters):\n",
    "        result = algo.train()\n",
    "\n",
    "    #     print(pretty_print(result)) # includes result[\"custom_metrics\"]\n",
    "    #     print(\"training loop = {} of {}\".format(i + 1, num_iters))\n",
    "    #     print(\"eps sampled so far {}\".format(ray.get(g_store.get_eps_counter.remote())))\n",
    "\n",
    "    #     if i % chkpt_freq == 0:\n",
    "    #         checkpoint = algo.save(local_dir)\n",
    "    #         print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    # checkpoint = algo.save(local_dir)\n",
    "    # print(\"checkpoint saved at\", checkpoint)\n",
    "    # print(\"result['experiment_id']\", result[\"experiment_id\"])\n",
    "\n",
    "                # Print step counts\n",
    "        env_runner_results = result.get('env_runners', {})\n",
    "        \n",
    "        # print(f\"\\n=== Iteration {i+1} ===\")\n",
    "        # print(f\"num_env_steps_sampled: {env_runner_results.get('num_env_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_sampled: {env_runner_results.get('num_agent_steps_sampled', 'N/A')}\")\n",
    "        # print(f\"num_env_steps_trained: {env_runner_results.get('num_env_steps_trained', 'N/A')}\")\n",
    "        # print(f\"num_agent_steps_trained: {env_runner_results.get('num_agent_steps_trained', 'N/A')}\")\n",
    "\n",
    "    # return result[\"experiment_id\"]\n",
    "    return None\n",
    "\n",
    "# run everything\n",
    "experiment_id = go_train(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756087446179,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "BMikbPugngj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756087446266,
     "user": {
      "displayName": "Cheow Huan Chua",
      "userId": "07361709631473644347"
     },
     "user_tz": -480
    },
    "id": "MrcLYiHrngj9",
    "outputId": "9a2fee4b-538b-4286-ad42-c2fb9af8f535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-24 05:59:05\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
